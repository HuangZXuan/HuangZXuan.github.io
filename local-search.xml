<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>citeSpace</title>
    <link href="/2024/11/30/20241130_citespace/"/>
    <url>/2024/11/30/20241130_citespace/</url>
    
    <content type="html"><![CDATA[<p>l</p><img src="/2024/11/30/20241130_citespace/image-20241130003711272.png" class="" title="image-20241130003711272"><img src="/2024/11/30/20241130_citespace/image-20241130003642171.png" class="" title="image-20241130003642171"><img src="/2024/11/30/20241130_citespace/image-20241130004305973.png" class="" title="image-20241130004305973"><img src="/2024/11/30/20241130_citespace/image-20241130004350909.png" class="" title="image-20241130004350909"><img src="/2024/11/30/20241130_citespace/image-20241130004522420.png" class="" title="image-20241130004522420"><img src="/2024/11/30/20241130_citespace/image-20241130004640487.png" class="" title="image-20241130004640487"><img src="/2024/11/30/20241130_citespace/image-20241130004614850.png" class="" title="image-20241130004614850"><img src="/2024/11/30/20241130_citespace/image-20241130005240299.png" class="" title="image-20241130005240299"><img src="/2024/11/30/20241130_citespace/image-20241130005520394.png" class="" title="image-20241130005520394"><img src="/2024/11/30/20241130_citespace/image-20241130005625989.png" class="" title="image-20241130005625989"><img src="/2024/11/30/20241130_citespace/image-20241130005658351.png" class="" title="image-20241130005658351"><img src="/2024/11/30/20241130_citespace/image-20241130010147673.png" class="" title="image-20241130010147673"><img src="/2024/11/30/20241130_citespace/image-20241130010442176.png" class="" title="image-20241130010442176"><img src="/2024/11/30/20241130_citespace/image-20241130010512900.png" class="" title="image-20241130010512900"><img src="/2024/11/30/20241130_citespace/image-20241130010912963.png" class="" title="image-20241130010912963"><img src="/2024/11/30/20241130_citespace/image-20241130011312827.png" class="" title="image-20241130011312827">]]></content>
    
    
    <categories>
      
      <category>论文使用工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文工具</tag>
      
      <tag>科研</tag>
      
      <tag>制图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>循环神经网络</title>
    <link href="/2024/11/28/20241128_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2024/11/28/20241128_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><h3 id="代码功能概述"><a href="#代码功能概述" class="headerlink" title="代码功能概述"></a><strong>代码功能概述</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.matmul(torch.cat((X, H), <span class="hljs-number">1</span>), torch.cat((W_xh, W_hh), <span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><p>这段代码合并了以下两部分的计算：</p><ol><li>XWxh\mathbf{X} \mathbf{W}_{xh}：输入项与输入权重的矩阵乘法。</li><li>HWhh\mathbf{H} \mathbf{W}_{hh}：隐状态与隐状态权重的矩阵乘法。</li></ol><p>通过拼接操作，将 X\mathbf{X} 和 H\mathbf{H} 作为一个整体处理，以及将 Wxh\mathbf{W}_{xh} 和 Whh\mathbf{W}_{hh} 拼接为一个矩阵进行统一的计算。</p><hr><h3 id="逐步解析"><a href="#逐步解析" class="headerlink" title="逐步解析"></a><strong>逐步解析</strong></h3><h4 id="1-拼接输入和隐状态"><a href="#1-拼接输入和隐状态" class="headerlink" title="(1) 拼接输入和隐状态"></a><strong>(1) 拼接输入和隐状态</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.cat((X, H), <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><ul><li><p><strong><code>torch.cat</code></strong>：将张量在指定维度上拼接。</p></li><li><p>参数 </p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-name">X</span><span class="hljs-punctuation">,</span> H)<br></code></pre></td></tr></table></figure><p>：</p><ul><li>X∈R3×1\mathbf{X} \in \mathbb{R}^{3 \times 1}</li><li>H∈R3×4\mathbf{H} \in \mathbb{R}^{3 \times 4}</li></ul></li><li><p>拼接维度为 <code>1</code>（列方向），结果： 拼接结果∈R3×(1+4)=R3×5\text{拼接结果} \in \mathbb{R}^{3 \times (1 + 4)} = \mathbb{R}^{3 \times 5}</p></li></ul><h4 id="2-拼接权重矩阵"><a href="#2-拼接权重矩阵" class="headerlink" title="(2) 拼接权重矩阵"></a><strong>(2) 拼接权重矩阵</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.cat((W_xh, W_hh), <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><ul><li><p>参数 </p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-name">W_xh</span><span class="hljs-punctuation">,</span> W_hh)<br></code></pre></td></tr></table></figure><p>：</p><ul><li>Wxh∈R1×4\mathbf{W}_{xh} \in \mathbb{R}^{1 \times 4}</li><li>Whh∈R4×4\mathbf{W}_{hh} \in \mathbb{R}^{4 \times 4}</li></ul></li><li><p>拼接维度为 <code>0</code>（行方向），结果： 拼接结果∈R(1+4)×4=R5×4\text{拼接结果} \in \mathbb{R}^{(1 + 4) \times 4} = \mathbb{R}^{5 \times 4}</p></li></ul><h4 id="3-矩阵乘法"><a href="#3-矩阵乘法" class="headerlink" title="(3) 矩阵乘法"></a><strong>(3) 矩阵乘法</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.matmul(torch.cat((X, H), <span class="hljs-number">1</span>), torch.cat((W_xh, W_hh), <span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><ul><li>拼接后的矩阵：<ul><li>输入矩阵拼接结果：R3×5\mathbb{R}^{3 \times 5}</li><li>权重矩阵拼接结果：R5×4\mathbb{R}^{5 \times 4}</li></ul></li><li>矩阵乘法： R3×5×R5×4=R3×4\mathbb{R}^{3 \times 5} \times \mathbb{R}^{5 \times 4} = \mathbb{R}^{3 \times 4}</li></ul><hr><h3 id="对比：原始计算-vs-合并计算"><a href="#对比：原始计算-vs-合并计算" class="headerlink" title="对比：原始计算 vs 合并计算"></a><strong>对比：原始计算 vs 合并计算</strong></h3><h4 id="原始计算"><a href="#原始计算" class="headerlink" title="原始计算"></a><strong>原始计算</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.matmul(X, W_xh) + torch.matmul(H, W_hh)<br></code></pre></td></tr></table></figure><ul><li>计算 XWxh\mathbf{X} \mathbf{W}_{xh} 和 HWhh\mathbf{H} \mathbf{W}_{hh} 两部分，然后相加。</li><li>需要两次矩阵乘法操作。</li></ul><h4 id="合并计算"><a href="#合并计算" class="headerlink" title="合并计算"></a><strong>合并计算</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.matmul(torch.cat((X, H), <span class="hljs-number">1</span>), torch.cat((W_xh, W_hh), <span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><ul><li>拼接 X\mathbf{X} 和 H\mathbf{H}，拼接 Wxh\mathbf{W}_{xh} 和 Whh\mathbf{W}_{hh}，再执行一次矩阵乘法。</li><li>只需要一次矩阵乘法操作，逻辑上与原始计算完全等价。</li></ul><hr><h3 id="结果维度"><a href="#结果维度" class="headerlink" title="结果维度"></a><strong>结果维度</strong></h3><p>最终结果：</p><p>输出∈R3×4\text{输出} \in \mathbb{R}^{3 \times 4}</p><ul><li>批量大小 b=3b = 3。</li><li>隐状态维度 dh=4d_h = 4。</li></ul><hr><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h3><ol><li>计算效率<ul><li>合并计算只需要一次矩阵乘法，节省了计算成本。</li></ul></li><li>代码简洁性<ul><li>用一个矩阵乘法替代了两次独立的操作，简化了代码。</li></ul></li></ol><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>这段代码是对 RNN 隐状态更新公式的优化实现：</p><p>Ht=ϕ(XtWxh+Ht−1Whh+bh)\mathbf{H}_t = \phi(\mathbf{X}_t \mathbf{W}_{xh} + \mathbf{H}_{t-1} \mathbf{W}_{hh} + \mathbf{b}_h)</p><p>通过拼接操作，合并了 XWxh\mathbf{X} \mathbf{W}_{xh} 和 HWhh\mathbf{H} \mathbf{W}_{hh} 的计算，使代码更高效和紧凑，同时保留了功能上的等价性。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>语言模型和数据集</title>
    <link href="/2024/11/28/20241128_%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2024/11/28/20241128_%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h1 id="马尔可夫模型和n元语法"><a href="#马尔可夫模型和n元语法" class="headerlink" title="马尔可夫模型和n元语法"></a>马尔可夫模型和n元语法</h1><h3 id="1-背景：马尔可夫性假设"><a href="#1-背景：马尔可夫性假设" class="headerlink" title="1. 背景：马尔可夫性假设"></a><strong>1. 背景：马尔可夫性假设</strong></h3><ul><li><p>马尔可夫性假设是语言建模中的核心思想之一。</p></li><li><p>假设<strong>序列中当前状态只依赖于有限个历史状态</strong>，可以减少计算复杂性。</p></li><li><p>公式中提到的分布：</p><script type="math/tex; mode=display">P(x_{t+1} \mid x_t, x_{t-1}, \dots, x_1)</script><p>根据马尔可夫性假设简化为： </p><script type="math/tex; mode=display">P(x_{t+1} \mid x_t)</script><p>, 即，<strong>序列的下一个状态只依赖于当前状态</strong>，而与更久远的历史无关。</p></li></ul><hr><h3 id="2-公式解析与语法模型"><a href="#2-公式解析与语法模型" class="headerlink" title="2. 公式解析与语法模型"></a><strong>2. 公式解析与语法模型</strong></h3><h4 id="1-通用的链式法则"><a href="#1-通用的链式法则" class="headerlink" title="(1) 通用的链式法则"></a><strong>(1) 通用的链式法则</strong></h4><ul><li>根据链式法则，任意序列 <script type="math/tex; mode=display">P(x_1, x_2, x_3, x_4)</script>可以展开为：<script type="math/tex; mode=display">P(x_1, x_2, x_3, x_4) = P(x_1) P(x_2 \mid x_1) P(x_3 \mid x_1, x_2) P(x_4 \mid x_1, x_2, x_3)</script></li></ul><ul><li>这是最完整的公式，假设每个词都可能依赖于前面所有的词。</li></ul><h4 id="2-简化公式：马尔可夫假设"><a href="#2-简化公式：马尔可夫假设" class="headerlink" title="(2) 简化公式：马尔可夫假设"></a><strong>(2) 简化公式：马尔可夫假设</strong></h4><p>根据不同阶的马尔可夫性假设，可以逐步简化：</p><ol><li><p><strong>一元语法（unigram）模型</strong>：</p><ul><li><script type="math/tex; mode=display">假设每个词 x_t独立于其他词，即：</script><script type="math/tex; mode=display">P(x_1, x_2, x_3, x_4) = P(x_1) P(x_2) P(x_3) P(x_4)</script></li><li><p><strong>意义</strong>：忽略词与词之间的关系，适合简单统计和快速计算。</p></li><li><p><strong>缺点</strong>：不能捕捉词与词之间的语法或上下文关系。</p></li></ul></li><li><p><strong>二元语法（bigram）模型</strong>：</p><ul><li><script type="math/tex; mode=display">假设每个词 x_t 只依赖于前一个词 x_{t-1}，即： P(x_1, x_2, x_3, x_4) = P(x_1) P(x_2 \mid x_1) P(x_3 \mid x_2) P(x_4 \mid x_3)</script></li><li><p><strong>意义</strong>：只考虑词对之间的关系，比如捕捉到「deep learning」这种词对的依赖性。</p></li><li><p><strong>优点</strong>：比一元模型更能反映词之间的语法关系。</p></li><li><p><strong>缺点</strong>：无法捕捉更长的上下文依赖。</p></li></ul></li><li><p><strong>三元语法（trigram）模型</strong>：</p><ul><li><script type="math/tex; mode=display">假设每个词 x_t 只依赖于前两个词 x_{t-2}, x_{t-1}，即： P(x_1, x_2, x_3, x_4) = P(x_1) P(x_2 \mid x_1) P(x_3 \mid x_1, x_2) P(x_4 \mid x_2, x_3)</script></li><li><p><strong>意义</strong>：能够捕捉三元词组之间的依赖性，比如「state of the」。</p></li><li><p><strong>优点</strong>：能捕捉更长的依赖。</p></li><li><p><strong>缺点</strong>：当序列长度较大时，计算复杂度仍然较高，且数据稀疏性更严重。</p></li></ul></li></ol><hr><h3 id="3-示例"><a href="#3-示例" class="headerlink" title="3. 示例"></a><strong>3. 示例</strong></h3><p>假设序列为：「I love deep learning」，概率计算如下：</p><h4 id="一元语法模型："><a href="#一元语法模型：" class="headerlink" title="一元语法模型："></a><strong>一元语法模型</strong>：</h4><ul><li><script type="math/tex; mode=display">假设每个词独立： P(\text{I love deep learning}) = P(\text{I}) P(\text{love}) P(\text{deep}) P(\text{learning})</script></li></ul><h4 id="二元语法模型："><a href="#二元语法模型：" class="headerlink" title="二元语法模型："></a><strong>二元语法模型</strong>：</h4><ul><li><script type="math/tex; mode=display">假设每个词只依赖前一个词： P(\text{I love deep learning}) = P(\text{I}) P(\text{love} \mid \text{I}) P(\text{deep} \mid \text{love}) P(\text{learning} \mid \text{deep})</script></li></ul><h4 id="三元语法模型："><a href="#三元语法模型：" class="headerlink" title="三元语法模型："></a><strong>三元语法模型</strong>：</h4><ul><li><script type="math/tex; mode=display">假设每个词依赖前两个词： P(\text{I love deep learning}) = P(\text{I}) P(\text{love} \mid \text{I}) P(\text{deep} \mid \text{I, love}) P(\text{learning} \mid \text{love, deep})</script></li></ul><hr><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a><strong>4. 总结</strong></h3><ul><li>一元语法假设独立性，计算简单，但无法捕捉任何上下文信息。</li><li>二元语法假设当前词只依赖前一个词，适合捕捉词对关系，计算效率较高。</li><li>三元语法扩展了依赖范围，但面临计算复杂度和数据稀疏的问题。</li></ul><h1 id="自然语言统计"><a href="#自然语言统计" class="headerlink" title="自然语言统计"></a>自然语言统计</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>tokens = d2l.tokenize(d2l.read_time_machine())<br><span class="hljs-comment"># 因为每个文本行不一定是一个句子或一个段落，因此我们把所有文本行拼接到一起</span><br>corpus = [token <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>vocab = d2l.Vocab(corpus)<br>vocab.token_freqs[:<span class="hljs-number">10</span>]<br><br><span class="hljs-comment">######</span><br>[(<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-number">2261</span>),<br> (<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-number">1267</span>),<br> (<span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-number">1245</span>),<br> (<span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-number">1155</span>),<br> (<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-number">816</span>),<br> (<span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-number">695</span>),<br> (<span class="hljs-string">&#x27;was&#x27;</span>, <span class="hljs-number">552</span>),<br> (<span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-number">541</span>),<br> (<span class="hljs-string">&#x27;that&#x27;</span>, <span class="hljs-number">443</span>),<br> (<span class="hljs-string">&#x27;my&#x27;</span>, <span class="hljs-number">440</span>)]<br></code></pre></td></tr></table></figure><p>正如我们所看到的，最流行的词看起来很无聊， 这些词通常被称为<em>停用词</em>（stop words），因此可以被过滤掉。 尽管如此，它们本身仍然是有意义的，我们仍然会在模型中使用它们。 此外，还有个明显的问题是词频衰减的速度相当地快。 例如，最常用单词的词频对比，第10个还不到第1个的1/5。 为了更好地理解，我们可以画出的词频图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">freqs = [freq <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> vocab.token_freqs]<br>d2l.plot(freqs, xlabel=<span class="hljs-string">&#x27;token: x&#x27;</span>, ylabel=<span class="hljs-string">&#x27;frequency: n(x)&#x27;</span>,<br>         xscale=<span class="hljs-string">&#x27;log&#x27;</span>, yscale=<span class="hljs-string">&#x27;log&#x27;</span>)<br></code></pre></td></tr></table></figure><p><img src="20241128_%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/image-20241128153852275.png" alt="image-20241128153852275"></p><h3 id="齐普夫定律-Zipf’s-Law"><a href="#齐普夫定律-Zipf’s-Law" class="headerlink" title="齐普夫定律 (Zipf’s Law)"></a><strong>齐普夫定律 (Zipf’s Law)</strong></h3><p>齐普夫定律是一种描述<strong>自然语言中的词频分布规律</strong>的经验法则，它由语言学家乔治·齐普夫 (George Zipf) 提出。这一定律表明，在一段文本或语料中，单词的出现频率与其频率排名成反比。</p><h4 id="公式"><a href="#公式" class="headerlink" title="公式"></a><strong>公式</strong></h4><script type="math/tex; mode=display">f(r) \propto \frac{1}{r^s}</script><p>其中：</p><ul><li>f(r)：单词的出现频率（词频）。</li><li>r：单词的频率排名。</li><li>s：幂指数（通常在自然语言中约为 1）。</li><li>∝：表示“成正比”。</li></ul><p>可以简单表达为：</p><script type="math/tex; mode=display">f(r) \cdot r^s = \text{常数}</script><h4 id="直观解释"><a href="#直观解释" class="headerlink" title="直观解释"></a><strong>直观解释</strong></h4><ul><li>自然语言文本中的单词分布非常不均匀。</li><li><strong>高频词</strong>（如“the”、“of”、“and”）出现的次数远远多于低频词。</li><li>齐普夫定律的核心观点<ul><li>排名为第 1 的单词（最高频单词）的出现次数，约等于排名第 2 的单词的 2 倍，约等于排名第 3 的单词的 3 倍，依此类推。</li><li>例如：<ul><li>最高频单词出现 1000 次；</li><li>排名第 2 的单词出现约 500 次；</li><li>排名第 3 的单词出现约 333 次。</li></ul></li></ul></li></ul><hr><h4 id="自然语言中的应用"><a href="#自然语言中的应用" class="headerlink" title="自然语言中的应用"></a><em>自然语言中的应用</em></h4><h5 id="1-高频词与低频词"><a href="#1-高频词与低频词" class="headerlink" title="(1) 高频词与低频词"></a><strong>(1) 高频词与低频词</strong></h5><ul><li>自然语言中，大量的单词只出现过一次或几次（称为“长尾单词”）。</li><li>高频词如“the”、“is”、“of”占据了语料库的大部分词频，但信息量较少。</li><li>低频词信息丰富，但在整个语料库中数量很少。</li></ul><h5 id="2-词汇覆盖问题"><a href="#2-词汇覆盖问题" class="headerlink" title="(2) 词汇覆盖问题"></a><strong>(2) 词汇覆盖问题</strong></h5><ul><li>齐普夫定律表明，用少量的高频词可以覆盖大部分的语料。</li><li>示例：<ul><li>前 1000 个高频单词可能覆盖文本中 80% 的单词出现次数。</li></ul></li></ul><h5 id="3-数据稀疏问题"><a href="#3-数据稀疏问题" class="headerlink" title="(3) 数据稀疏问题"></a><strong>(3) 数据稀疏问题</strong></h5><ul><li>长尾单词的存在使得构建语言模型时会面临<strong>数据稀疏问题</strong>，许多低频词甚至在训练集中没有出现。</li></ul><h4 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h4><ul><li>不能解释所有语言中的词频分布规律</li><li>对长尾单词的预测能力有限</li><li>无法直接量化单词的语义贡献</li></ul><h4 id="等价于"><a href="#等价于" class="headerlink" title="等价于"></a>等价于</h4><script type="math/tex; mode=display">logn_i=−αlogi+c</script><p>其中α是刻画分布的指数，c是常数。 这告诉我们想要通过计数统计和平滑来建模单词是不可行的， 因为这样建模的结果会大大高估尾部单词的频率，也就是所谓的不常用单词。 那么其他的词元组合，比如二元语法、三元语法等等，又会如何呢？ 我们来看看二元语法的频率是否与一元语法的频率表现出相同的行为方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">bigram_tokens = [pair <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(corpus[:-<span class="hljs-number">1</span>], corpus[<span class="hljs-number">1</span>:])]<br>bigram_vocab = d2l.Vocab(bigram_tokens)<br>bigram_vocab.token_freqs[:<span class="hljs-number">10</span>]<br><br><span class="hljs-comment">######</span><br>[((<span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>), <span class="hljs-number">309</span>),<br> ((<span class="hljs-string">&#x27;in&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>), <span class="hljs-number">169</span>),<br> ((<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&#x27;had&#x27;</span>), <span class="hljs-number">130</span>),<br> ((<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&#x27;was&#x27;</span>), <span class="hljs-number">112</span>),<br> ((<span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>), <span class="hljs-number">109</span>),<br> ((<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>), <span class="hljs-number">102</span>),<br> ((<span class="hljs-string">&#x27;it&#x27;</span>, <span class="hljs-string">&#x27;was&#x27;</span>), <span class="hljs-number">99</span>),<br> ((<span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>), <span class="hljs-number">85</span>),<br> ((<span class="hljs-string">&#x27;as&#x27;</span>, <span class="hljs-string">&#x27;i&#x27;</span>), <span class="hljs-number">78</span>),<br> ((<span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>), <span class="hljs-number">73</span>)]<br></code></pre></td></tr></table></figure><p>这里值得注意：在十个最频繁的词对中，有九个是由两个停用词组成的， 只有一个与“the time”有关。 我们再进一步看看三元语法的频率是否表现出相同的行为方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">trigram_tokens = [triple <span class="hljs-keyword">for</span> triple <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>    corpus[:-<span class="hljs-number">2</span>], corpus[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>], corpus[<span class="hljs-number">2</span>:])]<br>trigram_vocab = d2l.Vocab(trigram_tokens)<br>trigram_vocab.token_freqs[:<span class="hljs-number">10</span>]<br><br><span class="hljs-comment">######</span><br>[((<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;traveller&#x27;</span>), <span class="hljs-number">59</span>),<br> ((<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;machine&#x27;</span>), <span class="hljs-number">30</span>),<br> ((<span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;medical&#x27;</span>, <span class="hljs-string">&#x27;man&#x27;</span>), <span class="hljs-number">24</span>),<br> ((<span class="hljs-string">&#x27;it&#x27;</span>, <span class="hljs-string">&#x27;seemed&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>), <span class="hljs-number">16</span>),<br> ((<span class="hljs-string">&#x27;it&#x27;</span>, <span class="hljs-string">&#x27;was&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>), <span class="hljs-number">15</span>),<br> ((<span class="hljs-string">&#x27;here&#x27;</span>, <span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-string">&#x27;there&#x27;</span>), <span class="hljs-number">15</span>),<br> ((<span class="hljs-string">&#x27;seemed&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;me&#x27;</span>), <span class="hljs-number">14</span>),<br> ((<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&#x27;did&#x27;</span>, <span class="hljs-string">&#x27;not&#x27;</span>), <span class="hljs-number">14</span>),<br> ((<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&#x27;saw&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>), <span class="hljs-number">13</span>),<br> ((<span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&#x27;began&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>), <span class="hljs-number">13</span>)]<br></code></pre></td></tr></table></figure><p>最后，我们直观地对比三种模型中的词元频率：一元语法、二元语法和三元语法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">bigram_freqs = [freq <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> bigram_vocab.token_freqs]<br>trigram_freqs = [freq <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> trigram_vocab.token_freqs]<br>d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=<span class="hljs-string">&#x27;token: x&#x27;</span>,<br>         ylabel=<span class="hljs-string">&#x27;frequency: n(x)&#x27;</span>, xscale=<span class="hljs-string">&#x27;log&#x27;</span>, yscale=<span class="hljs-string">&#x27;log&#x27;</span>,<br>         legend=[<span class="hljs-string">&#x27;unigram&#x27;</span>, <span class="hljs-string">&#x27;bigram&#x27;</span>, <span class="hljs-string">&#x27;trigram&#x27;</span>])<br></code></pre></td></tr></table></figure><p><img src="20241128_%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/image-20241128162424131.png" alt="image-20241128162424131"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ol><li>除了一元语法词，单词序列似乎也遵循齐普夫定律</li><li>词表中n元组的数量并没有那么大，这说明语言中存在相当多的结构， 这些结构给了我们应用模型的希望</li><li>很多n元组很少出现，这使得拉普拉斯平滑非常不适合语言建模。 作为代替，我们将使用基于深度学习的模型</li></ol><h2 id="读取长序列数据"><a href="#读取长序列数据" class="headerlink" title="读取长序列数据"></a>读取长序列数据</h2><p><img src="20241128_%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/image-20241128163004487.png" alt="image-20241128163004487"></p><h4 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h4><p>在随机采样中，每个样本都是在原始的长序列上任意捕获的子序列。 在迭代过程中，来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻。 对于语言建模，目标是基于到目前为止我们看到的词元来预测下一个词元， 因此标签是移位了一个词元的原始序列。</p><p>缺点：</p><ul><li>缺乏上下文连续性</li><li>数据冗余问题</li><li>训练样本分布不均匀</li><li>时间序列的顺序性丢失</li><li>不适合生成式任务</li><li>模型收敛较慢</li><li>随机性可能导致结果不稳定</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#从数据中随机生成一个小批量。 在这里，参数batch_size指定了每个小批量中子序列样本的数目， 参数num_steps是每个子序列中预定义的时间步数。</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_random</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用随机抽样生成一个小批量子序列&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1</span><br>    corpus = corpus[random.randint(<span class="hljs-number">0</span>, num_steps - <span class="hljs-number">1</span>):]<br>    <span class="hljs-comment"># 减去1，是因为我们需要考虑标签</span><br>    num_subseqs = (<span class="hljs-built_in">len</span>(corpus) - <span class="hljs-number">1</span>) // num_steps<br>    <span class="hljs-comment"># 长度为num_steps的子序列的起始索引</span><br>    initial_indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_subseqs * num_steps, num_steps))<br>    <span class="hljs-comment"># 在随机抽样的迭代过程中，</span><br>    <span class="hljs-comment"># 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻</span><br>    random.shuffle(initial_indices)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">data</span>(<span class="hljs-params">pos</span>):<br>        <span class="hljs-comment"># 返回从pos位置开始的长度为num_steps的序列</span><br>        <span class="hljs-keyword">return</span> corpus[pos: pos + num_steps]<br><br>    num_batches = num_subseqs // batch_size<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, batch_size * num_batches, batch_size):<br>        <span class="hljs-comment"># 在这里，initial_indices包含子序列的随机起始索引</span><br>        initial_indices_per_batch = initial_indices[i: i + batch_size]<br>        X = [data(j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        Y = [data(j + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        <span class="hljs-keyword">yield</span> torch.tensor(X), torch.tensor(Y)<br>        <br>        <br>my_seq = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">35</span>))<br><span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> seq_data_iter_random(my_seq, batch_size=<span class="hljs-number">2</span>, num_steps=<span class="hljs-number">5</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;X: &#x27;</span>, X, <span class="hljs-string">&#x27;\nY:&#x27;</span>, Y)<br>    <br><span class="hljs-comment">######</span><br>X:  tensor([[<span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>],<br>        [<span class="hljs-number">28</span>, <span class="hljs-number">29</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">32</span>]])<br>Y: tensor([[<span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>],<br>        [<span class="hljs-number">29</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">32</span>, <span class="hljs-number">33</span>]])<br>X:  tensor([[ <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>],<br>        [<span class="hljs-number">18</span>, <span class="hljs-number">19</span>, <span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>]])<br>Y: tensor([[ <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],<br>        [<span class="hljs-number">19</span>, <span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]])<br>X:  tensor([[ <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>],<br>        [<span class="hljs-number">23</span>, <span class="hljs-number">24</span>, <span class="hljs-number">25</span>, <span class="hljs-number">26</span>, <span class="hljs-number">27</span>]])<br>Y: tensor([[ <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>],<br>        [<span class="hljs-number">24</span>, <span class="hljs-number">25</span>, <span class="hljs-number">26</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>]])<br></code></pre></td></tr></table></figure><h5 id="封装类"><a href="#封装类" class="headerlink" title="封装类"></a>封装类</h5><p><strong>随机采样</strong>：用于需要数据多样性、上下文依赖性较低的任务。</p><p><strong>顺序采样</strong>：用于需要捕获序列上下文的任务，例如语言建模或时间序列预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#提供一个统一接口，用于加载和生成序列数据。</span><br><span class="hljs-comment">#支持随机采样和顺序采样两种数据生成方式。</span><br><span class="hljs-comment">#自动处理语料的加载、预处理和子序列划分</span><br><span class="hljs-comment">#可以通过扩展 data_iter_fn 来支持更多类型的采样策略，例如带权重的随机采样或滑动窗口采样。</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br></code></pre></td></tr></table></figure><h5 id="封装类-1"><a href="#封装类-1" class="headerlink" title="封装类"></a>封装类</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#返回值：数据迭代器：生成训练用的小批量数据。词汇表：用于词元和索引的映射。</span><br><span class="hljs-comment">#提供统一接口，加载语料并生成数据迭代器。</span><br><span class="hljs-comment">#支持随机采样和顺序采样两种方式。</span><br><span class="hljs-comment">#随机采样适合多样性较高的任务，顺序采样适合上下文依赖性较强的任务。</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data_time_machine</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回时光机器数据集的迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数据处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>文本预处理</title>
    <link href="/2024/11/28/20241128_%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <url>/2024/11/28/20241128_%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h1><p>我们将解析文本的常见预处理步骤。 这些步骤通常包括：</p><ul><li>```python<br>import collections<br>import re<br>from d2l import torch as d2l<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><br><span class="hljs-number">1.</span> 将文本作为字符串加载到内存中。<br><br>   - ```python<br>     <span class="hljs-comment">#下面的函数将数据集读取到由多条文本行组成的列表中，其中每条文本行都是一个字符串。 为简单起见，我们在这里忽略了标点符号和字母大写。</span><br>     <span class="hljs-comment">#@save</span><br>     d2l.DATA_HUB[<span class="hljs-string">&#x27;time_machine&#x27;</span>] = (d2l.DATA_URL + <span class="hljs-string">&#x27;timemachine.txt&#x27;</span>,<br>                                     <span class="hljs-string">&#x27;090b5e7e70c295757f55df93cb0a180b9691891a&#x27;</span>)<br>     <br>     def read_time_machine():  <span class="hljs-comment">#@save</span><br>         <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;将时间机器数据集加载到文本行的列表中&quot;</span><span class="hljs-string">&quot;&quot;</span><br>         <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(d2l.download(<span class="hljs-string">&#x27;time_machine&#x27;</span>), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>             <span class="hljs-keyword">lines</span> = f.readlines()<br>         <span class="hljs-literal">return</span> [re.sub(<span class="hljs-string">&#x27;[^A-Za-z]+&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-built_in">line</span>).strip().<span class="hljs-built_in">lower</span>() <span class="hljs-keyword">for</span> <span class="hljs-built_in">line</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">lines</span>]<br>     <br>     <span class="hljs-keyword">lines</span> = read_time_machine()<br>     print(f<span class="hljs-string">&#x27;# 文本总行数: &#123;len(lines)&#125;&#x27;</span>)<br>     print(<span class="hljs-keyword">lines</span>[<span class="hljs-number">0</span>])<br>     print(<span class="hljs-keyword">lines</span>[<span class="hljs-number">10</span>])<br>     <br>     <span class="hljs-comment">######</span><br>     Downloading ../data/timemachine.txt <span class="hljs-built_in">from</span> <span class="hljs-keyword">http</span>://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt...<br>     <span class="hljs-comment"># 文本总行数: 3221</span><br>     <span class="hljs-keyword">the</span> <span class="hljs-built_in">time</span> machine <span class="hljs-keyword">by</span> h g wells<br>     twinkled <span class="hljs-keyword">and</span> his usually pale face was flushed <span class="hljs-keyword">and</span> animated <span class="hljs-keyword">the</span><br></code></pre></td></tr></table></figure></li></ul><ol><li><p>将字符串拆分为词元（如单词和字符）。</p><ul><li><p>```python</p><h1 id="下面的tokenize函数将文本行列表（lines）作为输入，-列表中的每个元素是一个文本序列（如一条文本行）。-每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。-最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）。"><a href="#下面的tokenize函数将文本行列表（lines）作为输入，-列表中的每个元素是一个文本序列（如一条文本行）。-每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。-最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）。" class="headerlink" title="下面的tokenize函数将文本行列表（lines）作为输入， 列表中的每个元素是一个文本序列（如一条文本行）。 每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。 最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）。"></a>下面的tokenize函数将文本行列表（lines）作为输入， 列表中的每个元素是一个文本序列（如一条文本行）。 每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。 最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）。</h1><p>def tokenize(lines, token=’word’):  #@save</p><pre><code class="hljs">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;if token == &#39;word&#39;:    return [line.split() for line in lines]elif token == &#39;char&#39;:    return [list(line) for line in lines]else:    print(&#39;错误：未知词元类型：&#39; + token)</code></pre><p>tokens = tokenize(lines)<br>for i in range(11):</p><pre><code class="hljs">print(tokens[i])</code></pre><h5 id=""><a href="#" class="headerlink" title="#"></a>#</h5><p>[‘the’, ‘time’, ‘machine’, ‘by’, ‘h’, ‘g’, ‘wells’]<br>[]<br>[]<br>[]<br>[]<br>[‘i’]<br>[]<br>[]<br>[‘the’, ‘time’, ‘traveller’, ‘for’, ‘so’, ‘it’, ‘will’, ‘be’, ‘convenient’, ‘to’, ‘speak’, ‘of’, ‘him’]<br>[‘was’, ‘expounding’, ‘a’, ‘recondite’, ‘matter’, ‘to’, ‘us’, ‘his’, ‘grey’, ‘eyes’, ‘shone’, ‘and’]<br>[‘twinkled’, ‘and’, ‘his’, ‘usually’, ‘pale’, ‘face’, ‘was’, ‘flushed’, ‘and’, ‘animated’, ‘the’]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-number">3.</span> 建立一个词表，将拆分的词元映射到数字索引。<br><br>   - ```python<br>     <span class="hljs-comment">#词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，通常也叫做词表（vocabulary）， 用来将字符串类型的词元映射到从开始的数字索引中。 我们先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为语料（corpus）。 然后根据每个唯一词元的出现频率，为其分配一个数字索引。 很少出现的词元通常被移除，这可以降低复杂性。 另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元“&lt;unk&gt;”。 我们可以选择增加一个列表，用于保存那些被保留的词元， 例如：填充词元（“&lt;pad&gt;”）； 序列开始词元（“&lt;bos&gt;”）； 序列结束词元（“&lt;eos&gt;”）。</span><br>     <br>     <span class="hljs-keyword">class</span> <span class="hljs-title class_">Vocab</span>:  <span class="hljs-comment">#@save</span><br>         <span class="hljs-string">&quot;&quot;&quot;文本词表&quot;&quot;&quot;</span><br>         <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, tokens=<span class="hljs-literal">None</span>, min_freq=<span class="hljs-number">0</span>, reserved_tokens=<span class="hljs-literal">None</span></span>):<br>             <span class="hljs-keyword">if</span> tokens <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                 tokens = []<br>             <span class="hljs-keyword">if</span> reserved_tokens <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                 reserved_tokens = []<br>             <span class="hljs-comment"># 按出现频率排序</span><br>             counter = count_corpus(tokens)<br>             self._token_freqs = <span class="hljs-built_in">sorted</span>(counter.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>],<br>                                        reverse=<span class="hljs-literal">True</span>)<br>             <span class="hljs-comment"># 未知词元的索引为0</span><br>             self.idx_to_token = [<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>] + reserved_tokens<br>             self.token_to_idx = &#123;token: idx<br>                                  <span class="hljs-keyword">for</span> idx, token <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.idx_to_token)&#125;<br>             <span class="hljs-keyword">for</span> token, freq <span class="hljs-keyword">in</span> self._token_freqs:<br>                 <span class="hljs-keyword">if</span> freq &lt; min_freq:<br>                     <span class="hljs-keyword">break</span><br>                 <span class="hljs-keyword">if</span> token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.token_to_idx:<br>                     self.idx_to_token.append(token)<br>                     self.token_to_idx[token] = <span class="hljs-built_in">len</span>(self.idx_to_token) - <span class="hljs-number">1</span><br>     <br>         <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>             <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.idx_to_token)<br>     <br>         <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, tokens</span>):<br>             <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(tokens, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>                 <span class="hljs-keyword">return</span> self.token_to_idx.get(tokens, self.unk)<br>             <span class="hljs-keyword">return</span> [self.__getitem__(token) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens]<br>     <br>         <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_tokens</span>(<span class="hljs-params">self, indices</span>):<br>             <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(indices, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>                 <span class="hljs-keyword">return</span> self.idx_to_token[indices]<br>             <span class="hljs-keyword">return</span> [self.idx_to_token[index] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indices]<br>     <br><span class="hljs-meta">         @property</span><br>         <span class="hljs-keyword">def</span> <span class="hljs-title function_">unk</span>(<span class="hljs-params">self</span>):  <span class="hljs-comment"># 未知词元的索引为0</span><br>             <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>     <br><span class="hljs-meta">         @property</span><br>         <span class="hljs-keyword">def</span> <span class="hljs-title function_">token_freqs</span>(<span class="hljs-params">self</span>):<br>             <span class="hljs-keyword">return</span> self._token_freqs<br>     <br>     <span class="hljs-keyword">def</span> <span class="hljs-title function_">count_corpus</span>(<span class="hljs-params">tokens</span>):  <span class="hljs-comment">#@save</span><br>         <span class="hljs-string">&quot;&quot;&quot;统计词元的频率&quot;&quot;&quot;</span><br>         <span class="hljs-comment"># 这里的tokens是1D列表或2D列表</span><br>         <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(tokens) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">isinstance</span>(tokens[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>):<br>             <span class="hljs-comment"># 将词元列表展平成一个列表</span><br>             tokens = [token <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>         <span class="hljs-keyword">return</span> collections.Counter(tokens)<br></code></pre></td></tr></table></figure></li></ul></li><li><p>将文本转换为数字索引序列，方便模型操作。</p><ul><li><pre><code class="lang-python">vocab = Vocab(tokens)print(list(vocab.token_to_idx.items())[:10])for i in [0, 10]:    print(&#39;文本:&#39;, tokens[i])    print(&#39;索引:&#39;, vocab[tokens[i]])</code></pre></li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数据处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>序列模型</title>
    <link href="/2024/11/27/20241127_%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <url>/2024/11/27/20241127_%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h1><h2 id="自回归模型"><a href="#自回归模型" class="headerlink" title="自回归模型"></a>自回归模型</h2><p><img src="20241127_%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/image-20241127205828111.png" alt="image-20241127205828111"></p><ol><li><strong>时间步 1：初始概率</strong><ul><li>P(x1)：表示序列的第一个元素 x1 的概率，没有依赖其他事件（条件为空）。</li><li>这是序列生成的起点。</li></ul></li><li><strong>时间步 2：条件概率</strong><ul><li>P(x2∣x1)：在 x1已经发生的条件下，x2发生的概率。</li><li>这里体现了序列数据的依赖性，x2的出现依赖于 x1。</li></ul></li><li><strong>时间步 3：条件概率</strong><ul><li>P(x3∣x2,x1)：在 x1和 x2已经发生的条件下，x3发生的概率。</li></ul></li><li><em>*一般情况：时间步 tt</em><ul><li>P(xt∣xt−1,…,x1)：表示第 t 个时间步的值 xt 发生的概率，条件是之前的所有时间步值 xt−1,…,x1 都已经发生。</li></ul></li><li><strong>递归性质：乘积展开</strong><ul><li>联合概率 P(x1,x2,…,xT) 是从起点到终点，每一步条件概率的累积，公式通过乘法累积这种依赖关系。</li></ul></li></ol><h2 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h2><p>求</p><script type="math/tex; mode=display">P(x_t∣x_{t−1})P(x_{t+1} \mid x_{t-1}) = \sum_{x_t} P(x_{t+1} \mid x_t) P(x_t \mid x_{t-1})</script><hr><h3 id="分解的核心思想"><a href="#分解的核心思想" class="headerlink" title="分解的核心思想"></a><strong>分解的核心思想</strong></h3><ol><li><strong>条件概率的链式法则</strong>：<script type="math/tex; mode=display">P(x_{t+1}, x_t \mid x_{t-1}) = P(x_{t+1} \mid x_t, x_{t-1}) P(x_t \mid x_{t-1})</script></li></ol><ul><li><script type="math/tex; mode=display">P(x_{t+1} \mid x_{t-1}) = \sum_{x_t} P(x_{t+1}, x_t \mid x_{t-1})</script></li></ul><ol><li><strong>马尔可夫性假设</strong>：<script type="math/tex; mode=display">P(x_{t+1} \mid x_t, x_{t-1}) = P(x_{t+1} \mid x_t)</script></li></ol><ol><li><strong>条件独立性简化</strong>：<script type="math/tex; mode=display">P(x_{t+1} \mid x_{t-1}) = \sum_{x_t} P(x_{t+1} \mid x_t) P(x_t \mid x_{t-1})</script></li></ol><hr><h3 id="分解步骤解释"><a href="#分解步骤解释" class="headerlink" title="分解步骤解释"></a><strong>分解步骤解释</strong></h3><h4 id="原始公式："><a href="#原始公式：" class="headerlink" title="原始公式："></a>原始公式：</h4><script type="math/tex; mode=display">P(x_{t+1} \mid x_{t-1}) = \frac{\sum_{x_t} P(x_{t+1}, x_t, x_{t-1})}{P(x_{t-1})}</script><ol><li><strong>分解联合概率</strong>：<script type="math/tex; mode=display">P(x_{t+1}, x_t, x_{t-1}) = P(x_{t+1} \mid x_t, x_{t-1}) P(x_t \mid x_{t-1}) P(x_{t-1})</script>代入公式并消去分母 <script type="math/tex; mode=display">P(x_{t-1})</script>，得：<script type="math/tex; mode=display">P(x_{t+1} \mid x_{t-1}) = \sum_{x_t} P(x_{t+1} \mid x_t, x_{t-1}) P(x_t \mid x_{t-1})</script></li></ol><ol><li><p><strong>马尔可夫性假设</strong>：</p><p>假设 </p><script type="math/tex; mode=display">P(x_{t+1} \mid x_t, x_{t-1}) = P(x_{t+1} \mid x_t)</script><p>公式简化为： </p><script type="math/tex; mode=display">P(x_{t+1} \mid x_{t-1}) = \sum_{x_t} P(x_{t+1} \mid x_t) P(x_t \mid x_{t-1})</script></li></ol><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>是的，从你的描述来看，这可以理解为<strong>超过滞后窗口大小 n 的 n-步预测通常效果会显著下降</strong></p><hr><h3 id="1-为什么超过-n-的-n-步预测效果会显著下降？"><a href="#1-为什么超过-n-的-n-步预测效果会显著下降？" class="headerlink" title="1. 为什么超过 n 的 n-步预测效果会显著下降？"></a><strong>1. 为什么超过 n 的 n-步预测效果会显著下降？</strong></h3><p>假设滞后窗口长度 n 表示模型输入特征的时间步数量（如 [xt−n+1,xt−n+2,…,xt][x_{t-n+1}, x_{t-n+2}, \dots, x_t]），那么：</p><ol><li><strong>窗口长度的限制</strong>：<ul><li>模型只能基于滞后窗口提供的 n 个历史点进行预测。</li><li>如果时间序列存在远期依赖（例如 x_t 与 x_{t-k} 相关，k &gt; n），模型无法感知这些长时间依赖，导致预测不准确。</li></ul></li><li><strong>递归预测的误差累积</strong>：<ul><li>n-步预测需要递归使用模型的输出作为下一步的输入。</li><li>每次递归预测都会引入小误差，误差在多次递归后迅速放大，使得长时间步预测的效果几乎失去参考价值。</li></ul></li><li><strong>时间序列的特性</strong>：<ul><li>如果时间序列具有强随机性或复杂的长期依赖（例如金融市场、天气变化），模型难以捕获这些模式，超过 n的预测值会趋于偏离真实分布。</li></ul></li></ol><hr><h3 id="2-滞后窗口-n-和预测步长-k-的关系"><a href="#2-滞后窗口-n-和预测步长-k-的关系" class="headerlink" title="2. 滞后窗口 n 和预测步长 k 的关系"></a><strong>2. 滞后窗口 n 和预测步长 k 的关系</strong></h3><p>从滞后窗口 n 的角度分析，预测步长 k 的效果可分为以下几种情况：</p><h4 id="1-k≤n：短步预测"><a href="#1-k≤n：短步预测" class="headerlink" title="(1) k≤n：短步预测"></a><strong>(1) k≤n：短步预测</strong></h4><ul><li><strong>效果</strong>：预测效果通常较好，因为模型能够利用窗口内的所有信息，捕获当前点 x_t 和未来点 xt+kx_{t+k} 的相关性。</li><li><strong>原因</strong>：模型的输入窗口长度 n 足够涵盖预测目标的依赖关系。</li></ul><h4 id="2-k-gt-n：长步预测"><a href="#2-k-gt-n：长步预测" class="headerlink" title="(2) k &gt; n：长步预测"></a><strong>(2) k &gt; n：长步预测</strong></h4><ul><li><p><strong>效果</strong>：预测效果显著下降，可能完全偏离真实趋势。</p></li><li><p>原因</p><p>：</p><ul><li><strong>窗口信息不足</strong>：模型输入只包含最近 n 个点的信息，缺乏对更远依赖关系的感知。</li><li><strong>误差累积</strong>：长步预测需要递归使用预测值作为输入，每一步都会放大误差。</li></ul></li></ul><hr><h3 id="3-为什么会有这种现象？（理论原因）"><a href="#3-为什么会有这种现象？（理论原因）" class="headerlink" title="3. 为什么会有这种现象？（理论原因）"></a><strong>3. 为什么会有这种现象？（理论原因）</strong></h3><h4 id="1-马尔可夫性假设的局限性"><a href="#1-马尔可夫性假设的局限性" class="headerlink" title="(1) 马尔可夫性假设的局限性"></a><strong>(1) 马尔可夫性假设的局限性</strong></h4><ul><li>在滞后窗口 n 的基础上，模型通常假设序列满足“有限阶马尔可夫性”，即未来 x_{t+k} 的分布仅与最近的 n个点相关：<script type="math/tex; mode=display">P(x_{t+k} \mid x_t, x_{t-1}, \dots, x_{t-n+1})</script></li></ul><ul><li>如果时间序列的真实依赖关系超出了窗口 nn，模型将无法准确捕获这些远期关系。</li></ul><h4 id="2-递归误差放大"><a href="#2-递归误差放大" class="headerlink" title="(2) 递归误差放大"></a><strong>(2) 递归误差放大</strong></h4><p>递归预测中，每一步预测都依赖于之前的预测值作为输入：</p><script type="math/tex; mode=display">\hat{x}_{t+k} = f(\hat{x}_{t+k-1}, \hat{x}_{t+k-2}, \dots, \hat{x}_{t+k-n})</script><ul><li>当 k&gt;nk &gt; n 时，所有输入可能完全是预测值。</li><li>如果预测值中存在小误差，每次递归会将误差累积并放大。</li></ul><hr><h3 id="4-长步预测是否完全无用？"><a href="#4-长步预测是否完全无用？" class="headerlink" title="4. 长步预测是否完全无用？"></a><strong>4. 长步预测是否完全无用？</strong></h3><p>虽然k &gt; n 的预测效果通常较差，但是否“无用”取决于以下几个因素：</p><h4 id="1-时间序列的特性"><a href="#1-时间序列的特性" class="headerlink" title="(1) 时间序列的特性"></a><strong>(1) 时间序列的特性</strong></h4><ul><li>如果时间序列中存在明显的长期趋势或周期性，长步预测可能仍有意义。例如：<ul><li><strong>气候数据</strong>：长期温度的趋势通常稳定，可以通过模型捕获。</li><li><strong>经济数据</strong>：季度 GDP 或消费指数可能呈现周期性。</li></ul></li></ul><h4 id="2-模型的复杂性"><a href="#2-模型的复杂性" class="headerlink" title="(2) 模型的复杂性"></a><strong>(2) 模型的复杂性</strong></h4><ul><li>简单的滞后窗口可能无法捕获远期依赖，但复杂的模型（如 RNN、LSTM、Transformer）可以更好地学习长时间依赖，提高 k &gt; n 的预测效果。</li></ul><h4 id="3-预测的目的"><a href="#3-预测的目的" class="headerlink" title="(3) 预测的目的"></a><strong>(3) 预测的目的</strong></h4><ul><li>如果长步预测仅用于捕获整体趋势或方向，而不是精确值，那么即使误差较大，也可能在某些场景中具有参考价值。</li></ul><hr><h3 id="5-如何改进长步预测？"><a href="#5-如何改进长步预测？" class="headerlink" title="5. 如何改进长步预测？"></a><strong>5. 如何改进长步预测？</strong></h3><ol><li><p><strong>引入更复杂的模型</strong></p><ul><li>使用能捕获长时间依赖的序列模型，如 RNN、LSTM、GRU 或 Transformer。</li><li>这些模型通过循环或注意力机制记住更多历史信息，超越简单的滞后窗口。</li></ul></li><li><p><strong>减少递归误差</strong></p><ul><li><p><strong>直接预测</strong>：让模型直接输出未来 kk-步的值，而不是逐步递归生成：</p><script type="math/tex; mode=display">[\hat{x}_{t+1}, \hat{x}_{t+2}, \dots, \hat{x}_{t+k}] = f(x_{t-n+1}, \dots, x_t)</script></li><li><p><strong>混合策略</strong>：结合真实值和预测值作为输入（如 Teacher Forcing）。</p></li></ul></li><li><p><strong>调整损失函数</strong></p><ul><li>设计针对长步预测的损失函数，鼓励模型更准确地拟合远期目标。</li></ul></li></ol><hr><h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a><strong>6. 总结</strong></h3><ul><li>超过滞后窗口 n 的预测步长 k &gt; n，通常由于信息不足和误差累积而变得不可靠。</li><li>在简单模型中，这种现象尤其明显，因此需要合理选择窗口大小 n 和预测步长 k。</li><li>长步预测是否“无用”取决于时间序列的特性、模型能力以及预测任务的具体需求。复杂模型（如 LSTM、Transformer）可以部分缓解这种问题。</li></ul>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1124组会</title>
    <link href="/2024/11/22/20241122_%E7%BB%84%E4%BC%9A/"/>
    <url>/2024/11/22/20241122_%E7%BB%84%E4%BC%9A/</url>
    
    <content type="html"><![CDATA[<p>数值分析的思想</p><p>地震观测实践学习</p><p>深度神经卷积网络的学习</p><p>CNN的经典论文</p><p>（MLP）MULTILAYER FEEDFORWARD NETWORKS ARE UNIVERSAL APPROXIMATORS</p><p>为什么提出：为了解决感知器只能处理线性可分问题的局限，增加了隐藏层，通过非线性激活函数，使得网络能够逼近任意复杂的函数。</p><p>优点：通用性比较强，可以用于分类、回归等多种任务</p><p>缺点：参数量大，对高维输入（如图像）的处理效率低。无法捕获输入数据的局部结构和空间信息。</p><p>（LeNet）</p><p>为什么提出：设计用于手写数字识别的专用架构，克服 MLP 在处理图像任务时的参数膨胀问题。</p><p>解决的问题：提出了卷积操作，通过局部连接和权值共享，减少了参数数量。增加了池化操作，增强了平移不变性。</p><p>优点：有效处理图像数据。引入卷积神经网络（CNN）的基础结构。</p><p>缺点：网络较浅，特征提取能力有限。计算能力依赖于硬件受限于但是的技术水平。</p><p>（AlexNet）ImageNet Classification with deep convolutional neural networks</p><p>为什么提出：通过深度卷积网络和 GPU 加速，在 ImageNet 数据集上实现突破性性能。</p><p>解决的问题：使用ReLU激活函数加速收敛。引入<strong>Dropout</strong> 解决过拟合问题。使用 GPU 提高计算效率。</p><p>优点：网络较大，参数量和计算量仍然较高。过于依赖硬件资源。</p><p>创新点：ReLU、Dropout、重叠池化、数据增强等技术。</p><p>（NiN）</p><p>为什么提出：用更灵活的模型代替传统卷积层，解决 CNN 中特征提取的局限性。</p><p>解决的问题：引入 <strong>1x1 卷积</strong> 以增加网络的表达能力。每个卷积操作后加一个小型 MLP（即“网络中的网络”）进行特征学习。</p><p>优点：大幅度减少参数量。增强特征提取的非线性能力。</p><p>缺点：网络深度较浅，在更复杂任务中表现受限。</p><p>（VGG）</p><p>为什么提出：探索网络速度对性能的影响。</p><p>解决的问题：通过堆叠多个3*3卷积核，保持感受野不变的同时提高网络的深度。</p><p>优点：结构简单，易于实现。深度增加后性能显著提升。</p><p>创新点：全部使用小卷积核，控制参数量同时增加深度。</p><p>（GoogleNet）</p><p>为什么提出：提升深度网络的计算效率，减少计算量和参数量。</p><p>解决的问题：引入 <strong>Inception 模块</strong>，结合多种卷积核（1x1, 3x3, 5x5）和池化操作，提取多尺度特征。使用 <strong>1x1 卷积</strong> 进行降维，减少计算量。</p><p>优点：参数量少，计算效率高。更适合大规模图像分类任务。</p><p>缺点：模块设计较为复杂。手动调参难度较高。</p><p>创新点：Inception 模块的模块化设计，适合扩展。</p><p>（ResNet）Deep Residual Learning for image recognition</p><p>为什么提出：解决深度网络的 <strong>梯度消失/爆炸</strong> 问题。</p><p>解决的问题：引入 <strong>残差连接（Residual Connections）</strong>，通过恒等映射缓解深度网络的训练难度。深度增加后网络性能不再下降。</p><p>优点：支持超深网络（如 152 层）训练。大幅提高网络的表达能力。</p><p>缺点：计算量较大。对硬件资源要求较高。</p><p>创新：残差连接使深度网络训练更加稳定。</p><p>深度学习的综述文章</p><p>CNN&amp;分布式光纤结合的论文</p><p>关键词：光纤传感、模式识别</p><p>来源：EI、北核等</p><p>引用：三四百</p><p>关键词：fiber optical&amp;deep learning</p><p>来源：SCI、EI</p><p>引用：170</p><p>分布式光纤&amp;机器学习的综述文章，有关算法有哪些，谁提出的，解决了什么问题</p><h1 id="检索条件"><a href="#检索条件" class="headerlink" title="检索条件"></a>检索条件</h1><h2 id="CNKI"><a href="#CNKI" class="headerlink" title="CNKI"></a>CNKI</h2><p>光纤传感&amp;机器学习</p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122145145250.png" alt="image-20241122145145250"></p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122145348189.png" alt="image-20241122145348189"></p><p>光纤传感&amp;深度学习</p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122145639393.png" alt="image-20241122145639393"></p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122145718922.png" alt="image-20241122145718922"></p><p>光纤传感&amp;模式识别</p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122145922999.png" alt="image-20241122145922999"></p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122145955707.png" alt="image-20241122145955707"></p><p>光纤传感&amp;CNN</p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122150207336.png" alt="image-20241122150207336"></p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122150220638.png" alt="image-20241122150220638"></p><p>光纤传感&amp;神经网络</p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122150347479.png" alt="image-20241122150347479"></p><p><img src="20241122_%E7%BB%84%E4%BC%9A/image-20241122150408931.png" alt="image-20241122150408931"></p><p>房价预测。</p><p>好的，对于图像处理来说，我们可以把每一个像素看成一个输入。图像识别中，图像特征相对位置不固定。</p><p>对于一些情况来说，并不总是线性的，简化图像，我们不能通过对某几个像素简单的线性组合就来确定一个图像是否是一只猫狗，识别一个物品是需要综合多种特征考虑的。这个时候我们可以把输出看出某种特征的判定。</p>]]></content>
    
    
    <categories>
      
      <category>前沿信息</category>
      
      <category>学习进度</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>整合tif图与geojson数据</title>
    <link href="/2024/11/19/20241119_%E6%95%B4%E5%90%88tif%E5%9B%BE%E4%B8%8Egeojson%E6%95%B0%E6%8D%AE/"/>
    <url>/2024/11/19/20241119_%E6%95%B4%E5%90%88tif%E5%9B%BE%E4%B8%8Egeojson%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> rasterio<br><span class="hljs-keyword">import</span> rasterio.plot<br><span class="hljs-keyword">from</span> rasterio.mask <span class="hljs-keyword">import</span> mask<br><span class="hljs-keyword">from</span> rasterio.warp <span class="hljs-keyword">import</span> reproject, calculate_default_transform, Resampling <span class="hljs-keyword">as</span> WarpResampling<br><span class="hljs-keyword">import</span> geopandas <span class="hljs-keyword">as</span> gpd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> matplotlib.colors <span class="hljs-keyword">import</span> ListedColormap<br><span class="hljs-keyword">from</span> shapely.geometry <span class="hljs-keyword">import</span> box<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib<br><br><span class="hljs-comment"># 设置中文字体（需要系统中有相应的字体）</span><br>matplotlib.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 使用黑体</span><br>matplotlib.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>    <span class="hljs-comment"># 正常显示负号</span><br><br><span class="hljs-comment"># 1. 定义函数1：读取 base.tif 文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_base_tif</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(file_path) <span class="hljs-keyword">as</span> src:<br>        data = src.read(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 读取第一波段</span><br>        profile = src.profile.copy()  <span class="hljs-comment"># 获取元数据</span><br>        transform = src.transform  <span class="hljs-comment"># 地理变换信息</span><br>        crs = src.crs  <span class="hljs-comment"># 坐标参考系</span><br>        bounds = src.bounds  <span class="hljs-comment"># 图像范围</span><br>    <span class="hljs-keyword">return</span> data, profile, transform, crs, bounds<br><br><span class="hljs-comment"># 2. 定义函数2：读取 intensity.tif 文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_intensity_tif</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(file_path) <span class="hljs-keyword">as</span> src:<br>        data = src.read(<span class="hljs-number">1</span>)<br>        profile = src.profile.copy()<br>        transform = src.transform<br>        crs = src.crs<br>        bounds = src.bounds<br>    <span class="hljs-keyword">return</span> data, profile, transform, crs, bounds<br><br><span class="hljs-comment"># 3. 读取并合并 GeoJSON 文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_geojson_files</span>(<span class="hljs-params">file_list</span>):<br>    gdf_list = []<br>    <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> file_list:<br>        gdf = gpd.read_file(file)<br>        gdf_list.append(gdf)<br>    combined_gdf = pd.concat(gdf_list, ignore_index=<span class="hljs-literal">True</span>)<br>    combined_gdf = gpd.GeoDataFrame(combined_gdf)<br>    <span class="hljs-keyword">return</span> combined_gdf<br><br><span class="hljs-comment"># 5. 截取 base.tif 与 intensity.tif 重叠的部分</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_overlapping_region</span>(<span class="hljs-params">base_data, base_transform, base_crs, base_bounds,</span><br><span class="hljs-params">                               intensity_data, intensity_transform, intensity_crs, intensity_bounds</span>):<br>    <span class="hljs-comment"># 确保坐标参考系一致</span><br>    <span class="hljs-keyword">if</span> base_crs != intensity_crs:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;base.tif 和 intensity.tif 的坐标参考系不一致，请进行坐标转换。&quot;</span>)<br><br>    <span class="hljs-comment"># 计算重叠区域</span><br>    base_geom = box(*base_bounds)<br>    intensity_geom = box(*intensity_bounds)<br>    overlap_geom = base_geom.intersection(intensity_geom)<br><br>    <span class="hljs-keyword">if</span> overlap_geom.is_empty:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;base.tif 和 intensity.tif 没有重叠区域。&quot;</span>)<br><br>    <span class="hljs-comment"># 将重叠区域转换为 GeoJSON 格式</span><br>    overlap_geojson = [overlap_geom.__geo_interface__]<br><br>    <span class="hljs-comment"># 裁剪 base_data</span><br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;base.tif&#x27;</span>) <span class="hljs-keyword">as</span> src:<br>        base_overlap_data, base_overlap_transform = mask(src, overlap_geojson, crop=<span class="hljs-literal">True</span>)<br>        base_overlap_meta = src.meta.copy()<br>        base_overlap_meta.update(&#123;<br>            <span class="hljs-string">&quot;height&quot;</span>: base_overlap_data.shape[<span class="hljs-number">1</span>],<br>            <span class="hljs-string">&quot;width&quot;</span>: base_overlap_data.shape[<span class="hljs-number">2</span>],<br>            <span class="hljs-string">&quot;transform&quot;</span>: base_overlap_transform<br>        &#125;)<br><br>    <span class="hljs-comment"># 裁剪 intensity_data</span><br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;intensity.tif&#x27;</span>) <span class="hljs-keyword">as</span> src:<br>        intensity_overlap_data, intensity_overlap_transform = mask(src, overlap_geojson, crop=<span class="hljs-literal">True</span>)<br>        intensity_overlap_meta = src.meta.copy()<br>        intensity_overlap_meta.update(&#123;<br>            <span class="hljs-string">&quot;height&quot;</span>: intensity_overlap_data.shape[<span class="hljs-number">1</span>],<br>            <span class="hljs-string">&quot;width&quot;</span>: intensity_overlap_data.shape[<span class="hljs-number">2</span>],<br>            <span class="hljs-string">&quot;transform&quot;</span>: intensity_overlap_transform<br>        &#125;)<br><br>    <span class="hljs-comment"># 重采样 base_overlap_data 以匹配 intensity_overlap_data</span><br>    base_overlap_resampled = np.empty_like(intensity_overlap_data, dtype=base_overlap_data.dtype)<br><br>    reproject(<br>        source=base_overlap_data,<br>        destination=base_overlap_resampled,<br>        src_transform=base_overlap_transform,<br>        src_crs=base_crs,<br>        dst_transform=intensity_overlap_transform,<br>        dst_crs=intensity_crs,<br>        resampling=WarpResampling.nearest<br>    )<br><br>    <span class="hljs-keyword">return</span> base_overlap_resampled[<span class="hljs-number">0</span>], intensity_overlap_data[<span class="hljs-number">0</span>], intensity_overlap_transform, intensity_crs<br><br><span class="hljs-comment"># 6. 根据给定公式计算风险概率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_risk_probability</span>(<span class="hljs-params">intensity, base</span>):<br>    <span class="hljs-comment"># intensity 是仪器烈度，如 6、7、8 等</span><br>    <span class="hljs-comment"># base 是底图层</span><br>    <span class="hljs-comment"># 计算 A = 0.00250165038535077 * e^(0.6931 * intensity)</span><br>    A = <span class="hljs-number">0.00250165038535077</span> * np.exp(<span class="hljs-number">0.6931</span> * intensity)<br><br>    <span class="hljs-comment"># 计算指数 exponent = - (A + base)</span><br>    exponent = - (A + base)<br><br>    <span class="hljs-comment"># 计算风险概率 result = 1 / (1 + e^(exponent))</span><br>    <span class="hljs-keyword">with</span> np.errstate(over=<span class="hljs-string">&#x27;ignore&#x27;</span>, invalid=<span class="hljs-string">&#x27;ignore&#x27;</span>):<br>        result = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(exponent))<br><br>    result = np.nan_to_num(result, nan=<span class="hljs-number">0.0</span>, posinf=<span class="hljs-number">0.0</span>, neginf=<span class="hljs-number">0.0</span>)<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-comment"># 7. 根据概率值对风险级别进行分类</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">classify_risk_levels</span>(<span class="hljs-params">probability</span>):<br>    risk_levels = np.zeros_like(probability, dtype=np.uint8)<br><br>    <span class="hljs-comment"># 风险级别从 1 到 5，对应五种颜色，1 表示低风险</span><br>    risk_levels[probability &gt;= <span class="hljs-number">0.1</span>] = <span class="hljs-number">5</span>  <span class="hljs-comment"># 高风险（红色）</span><br>    risk_levels[(probability &gt;= <span class="hljs-number">0.01</span>) &amp; (probability &lt; <span class="hljs-number">0.1</span>)] = <span class="hljs-number">4</span>  <span class="hljs-comment"># 中高风险（橙色）</span><br>    risk_levels[(probability &gt;= <span class="hljs-number">0.001</span>) &amp; (probability &lt; <span class="hljs-number">0.01</span>)] = <span class="hljs-number">3</span>  <span class="hljs-comment"># 中风险（黄色）</span><br>    risk_levels[(probability &gt;= <span class="hljs-number">0.0001</span>) &amp; (probability &lt; <span class="hljs-number">0.001</span>)] = <span class="hljs-number">2</span>  <span class="hljs-comment"># 中低风险（蓝色）</span><br>    risk_levels[probability &lt; <span class="hljs-number">0.0001</span>] = <span class="hljs-number">1</span>  <span class="hljs-comment"># 低风险（白色）</span><br><br>    <span class="hljs-keyword">return</span> risk_levels<br><br><span class="hljs-comment"># 8. 叠加区县信息并可视化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">visualize_risk</span>(<span class="hljs-params">risk_levels, transform, crs, combined_gdf</span>):<br>    <span class="hljs-comment"># 生成颜色映射</span><br>    colors = [<span class="hljs-string">&#x27;white&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>, <span class="hljs-string">&#x27;yellow&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>, <span class="hljs-string">&#x27;red&#x27;</span>]<br>    cmap = ListedColormap(colors)<br><br>    fig, ax = plt.subplots(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br><br>    <span class="hljs-comment"># 显示风险等级图</span><br>    rasterio.plot.show(risk_levels, transform=transform, cmap=cmap, ax=ax)<br>    ax.set_title(<span class="hljs-string">&quot;次生地质灾害风险概率图&quot;</span>)<br>    ax.set_xlabel(<span class="hljs-string">&#x27;经度&#x27;</span>)<br>    ax.set_ylabel(<span class="hljs-string">&#x27;纬度&#x27;</span>)<br><br>    <span class="hljs-comment"># 添加图例</span><br>    labels = [<span class="hljs-string">&#x27;低风险&#x27;</span>, <span class="hljs-string">&#x27;中低风险&#x27;</span>, <span class="hljs-string">&#x27;中风险&#x27;</span>, <span class="hljs-string">&#x27;中高风险&#x27;</span>, <span class="hljs-string">&#x27;高风险&#x27;</span>]<br>    patches = [plt.plot([], [], marker=<span class="hljs-string">&quot;s&quot;</span>, ms=<span class="hljs-number">10</span>, ls=<span class="hljs-string">&quot;&quot;</span>, mec=<span class="hljs-literal">None</span>, color=colors[i], label=<span class="hljs-string">&quot;&#123;:s&#125;&quot;</span>.<span class="hljs-built_in">format</span>(labels[i]))[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(colors))]<br>    ax.legend(handles=patches, bbox_to_anchor=(<span class="hljs-number">1.05</span>, <span class="hljs-number">1</span>), loc=<span class="hljs-string">&#x27;upper left&#x27;</span>)<br><br>    <span class="hljs-comment"># 确保坐标参考系一致</span><br>    <span class="hljs-keyword">if</span> combined_gdf.crs != crs:<br>        combined_gdf = combined_gdf.to_crs(crs)<br><br>    <span class="hljs-comment"># 裁剪区县数据到重叠区域</span><br>    width = risk_levels.shape[<span class="hljs-number">1</span>]<br>    height = risk_levels.shape[<span class="hljs-number">0</span>]<br>    left, top = transform * (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>    right, bottom = transform * (width, height)<br>    overlap_geom = box(left, bottom, right, top)<br>    overlap_gdf = gpd.GeoDataFrame(geometry=[overlap_geom], crs=crs)<br>    clipped_gdf = gpd.overlay(combined_gdf, overlap_gdf, how=<span class="hljs-string">&#x27;intersection&#x27;</span>)<br><br>    <span class="hljs-comment"># 绘制区县边界</span><br>    clipped_gdf.boundary.plot(ax=ax, edgecolor=<span class="hljs-string">&#x27;black&#x27;</span>, linewidth=<span class="hljs-number">0.5</span>)<br><br>    <span class="hljs-comment"># 添加区县名称标签</span><br>    <span class="hljs-keyword">for</span> idx, row <span class="hljs-keyword">in</span> clipped_gdf.iterrows():<br>        centroid = row[<span class="hljs-string">&#x27;geometry&#x27;</span>].centroid<br>        ax.text(centroid.x, centroid.y, row.get(<span class="hljs-string">&#x27;name&#x27;</span>, <span class="hljs-string">&#x27;未知&#x27;</span>), fontsize=<span class="hljs-number">6</span>, ha=<span class="hljs-string">&#x27;center&#x27;</span>, va=<span class="hljs-string">&#x27;center&#x27;</span>, color=<span class="hljs-string">&#x27;black&#x27;</span>)<br><br>    plt.show()<br><br>    <span class="hljs-comment"># 保存结果为 TIFF 文件</span><br>    plt.savefig(<span class="hljs-string">&#x27;final_result.tif&#x27;</span>, dpi=<span class="hljs-number">300</span>, bbox_inches=<span class="hljs-string">&#x27;tight&#x27;</span>, <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;tif&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;风险概率图已成功保存为 &#x27;final_result.tif&#x27;。&quot;</span>)<br><br><br><br><span class="hljs-comment"># 9. 主程序</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># 读取 base.tif 文件</span><br>    base_data, base_profile, base_transform, base_crs, base_bounds = read_base_tif(<span class="hljs-string">&#x27;base.tif&#x27;</span>)<br><br>    <span class="hljs-comment"># 读取 intensity.tif 文件</span><br>    intensity_data, intensity_profile, intensity_transform, intensity_crs, intensity_bounds = read_intensity_tif(<span class="hljs-string">&#x27;intensity.tif&#x27;</span>)<br><br>    <span class="hljs-comment"># 读取 GeoJSON 文件</span><br>    sichuan_json_files = [<span class="hljs-string">&#x27;阿坝藏族羌族自治州.json&#x27;</span>, <span class="hljs-string">&#x27;成都市.json&#x27;</span>, <span class="hljs-string">&#x27;德阳市.json&#x27;</span>, <span class="hljs-string">&#x27;甘孜藏族自治州.json&#x27;</span>,<br>                          <span class="hljs-string">&#x27;乐山市.json&#x27;</span>, <span class="hljs-string">&#x27;凉山彝族自治州.json&#x27;</span>, <span class="hljs-string">&#x27;眉山市.json&#x27;</span>, <span class="hljs-string">&#x27;绵阳市.json&#x27;</span>,<br>                          <span class="hljs-string">&#x27;内江市.json&#x27;</span>, <span class="hljs-string">&#x27;遂宁市.json&#x27;</span>, <span class="hljs-string">&#x27;雅安市.json&#x27;</span>, <span class="hljs-string">&#x27;宜宾市.json&#x27;</span>,<br>                          <span class="hljs-string">&#x27;资阳市.json&#x27;</span>, <span class="hljs-string">&#x27;自贡市.json&#x27;</span>]<br>    xizang_json_files = [<span class="hljs-string">&#x27;昌都市.json&#x27;</span>, <span class="hljs-string">&#x27;那曲市.json&#x27;</span>, <span class="hljs-string">&#x27;日喀则市.json&#x27;</span>, <span class="hljs-string">&#x27;山南市.json&#x27;</span>, <span class="hljs-string">&#x27;林芝市.json&#x27;</span>]<br>    all_json_files = sichuan_json_files + xizang_json_files<br><br>    combined_gdf = read_geojson_files(all_json_files)<br><br>    <span class="hljs-comment"># 截取重叠区域</span><br>    base_overlap_data, intensity_overlap_data, overlap_transform, overlap_crs = extract_overlapping_region(<br>        base_data, base_transform, base_crs, base_bounds,<br>        intensity_data, intensity_transform, intensity_crs, intensity_bounds<br>    )<br><br>    <span class="hljs-comment"># 计算风险概率</span><br>    risk_probability = calculate_risk_probability(intensity_overlap_data, base_overlap_data)<br><br>    <span class="hljs-comment"># 对结果进行分级</span><br>    risk_levels = classify_risk_levels(risk_probability)<br><br>    <span class="hljs-comment"># 保存风险等级为 TIFF 文件</span><br>    out_meta = base_profile.copy()<br>    out_meta.update(&#123;<br>        <span class="hljs-string">&quot;driver&quot;</span>: <span class="hljs-string">&quot;GTiff&quot;</span>,<br>        <span class="hljs-string">&quot;height&quot;</span>: risk_levels.shape[<span class="hljs-number">0</span>],<br>        <span class="hljs-string">&quot;width&quot;</span>: risk_levels.shape[<span class="hljs-number">1</span>],<br>        <span class="hljs-string">&quot;transform&quot;</span>: overlap_transform,<br>        <span class="hljs-string">&quot;crs&quot;</span>: overlap_crs,<br>        <span class="hljs-string">&quot;count&quot;</span>: <span class="hljs-number">1</span>,<br>        <span class="hljs-string">&quot;dtype&quot;</span>: <span class="hljs-string">&#x27;uint8&#x27;</span>,<br>        <span class="hljs-string">&quot;nodata&quot;</span>: <span class="hljs-number">0</span><br>    &#125;)<br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;risk_level.tif&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, **out_meta) <span class="hljs-keyword">as</span> dest:<br>        dest.write(risk_levels, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 可视化结果并叠加区县信息</span><br>    visualize_risk(risk_levels, overlap_transform, overlap_crs, combined_gdf)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>地理信息处理</category>
      
      <category>图片处理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pyton</tag>
      
      <tag>地理信息绘图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>插值法</title>
    <link href="/2024/11/12/20241112_%E6%8F%92%E5%80%BC%E6%B3%95/"/>
    <url>/2024/11/12/20241112_%E6%8F%92%E5%80%BC%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>b</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>引入插值法的原因主要是为了解决以下问题：</p><ol><li><p><strong>数据的缺失和间断</strong>：在许多实际问题中，我们往往只能获取到离散的数值数据（如实验测量值、观测数据等），而这些数据并不一定在我们需要的所有点上提供值。插值法通过构造插值多项式或函数，帮助我们在已知数据之间估计出未知点的函数值，从而填补数据的空白。</p></li><li><p><strong>函数逼近的需要</strong>：在一些场景下，我们可能无法直接用简单的数学表达式描述某个函数，但可以利用插值法构建一个近似的插值函数来逼近该函数的行为，从而简化计算和分析。</p></li><li><p><strong>计算精度的提高</strong>：插值法在解决实际问题时，能够提高计算的精度，特别是在数值计算和模拟中。通过插值方法，可以更好地模拟复杂曲线或表面，减少误差。</p></li><li><p><strong>计算效率的提升</strong>：在许多工程和科学领域的应用中，直接计算可能涉及复杂的数学运算或昂贵的数值模拟。插值法可以通过构建简单的插值模型，减少计算成本并提高效率。</p></li><li><p><strong>平滑和连续性需求</strong>：在物理建模、工程设计、计算机图形学等领域，常常需要构造平滑且连续的曲线和表面。插值法特别是高阶插值（如样条插值）能够提供光滑、连续的解决方案，满足实际应用中的要求。</p></li></ol><h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p>插值法主要有以下几种分类：</p><ol><li><p><strong>多项式插值</strong>：使用单个多项式来逼近函数值，包括以下常见方法：</p><ul><li><strong>拉格朗日插值</strong>：通过构造拉格朗日插值多项式，使其在插值节点上精确匹配给定的函数值。</li><li><strong>牛顿插值</strong>：基于差商表构造的插值方法，可以更方便地在已有节点的基础上添加新的插值点。包括前向差分和后向差分形式。</li></ul></li><li><p><strong>分段插值</strong>：将区间划分为多个子区间，在每个子区间上使用简单的插值函数来逼近原函数，常见类型包括：</p><ul><li><strong>分段线性插值</strong>：在每两个相邻点之间用直线段来插值。</li><li><strong>分段多项式插值</strong>：可以使用高阶多项式，但更常见的是低次插值函数，如二次或三次多项式。</li><li><strong>样条插值（Spline）</strong>：利用分段三次多项式构成，具有较好的平滑性和连续性，如三次样条插值要求一阶和二阶导数在节点上连续。</li></ul></li><li><p><strong>埃尔米特插值</strong>：与普通插值不同，埃尔米特插值不仅要求插值函数在节点上函数值匹配，还要求其在节点上的导数值（甚至更高阶导数值）也匹配。适用于需要控制导数信息的场景。</p></li><li><p><strong>均差插值</strong>：利用均差的性质构建插值多项式，结合牛顿插值公式，提供灵活的插值构建方式。</p></li><li><p><strong>高阶插值与特殊插值方法</strong>：</p><ul><li><strong>高次多项式插值</strong>：尽管在某些场景中可能会导致“龙格现象”（高阶插值曲线的震荡现象），但仍用于特定需求中。</li><li><strong>特殊函数插值</strong>：如基于傅里叶级数的插值、B样条插值等方法，适用于特殊应用场景。</li></ul></li></ol><h1 id="拉格朗日插值"><a href="#拉格朗日插值" class="headerlink" title="拉格朗日插值"></a>拉格朗日插值</h1><p><strong>拉格朗日插值</strong>是一种常见的多项式插值方法，其目的是通过构建一个唯一的多项式，使其在给定的一组插值节点上精确地通过已知的函数值。拉格朗日插值适用于插值点较少的情形，能够在无需重新计算的情况下扩展为多项式形式。</p><h3 id="拉格朗日插值多项式的定义"><a href="#拉格朗日插值多项式的定义" class="headerlink" title="拉格朗日插值多项式的定义"></a>拉格朗日插值多项式的定义</h3><p>给定 ( n+1 ) 个不同的插值点 </p><script type="math/tex; mode=display">(x_0, y_0), (x_1, y_1), \ldots, (x_n, y_n)</script><p>，拉格朗日插值多项式 ( P(x) ) 表示为：</p><script type="math/tex; mode=display">P(x) = \sum_{i=0}^{n} y_i \cdot L_i(x)</script><p>其中  L_i(x) 是拉格朗日基函数，定义为：</p><script type="math/tex; mode=display">L_i(x) = \prod_{\substack{0 \leq j \leq n \\ j \neq i}} \frac{x - x_j}{x_i - x_j}</script><h3 id="拉格朗日基函数的作用"><a href="#拉格朗日基函数的作用" class="headerlink" title="拉格朗日基函数的作用"></a>拉格朗日基函数的作用</h3><p>每个  L_i(x) 是一个多项式，当 x = x_i  时，L_i(x_i) = 1 ，而对其他所有 </p><script type="math/tex; mode=display">x_j ( j \neq i )</script><p>的点则满足  L_i(x_j) = 0 。因此，在构建插值多项式时，每个  y_i 的系数仅在对应的插值点 x_i 处有效，而在其他插值点上为零，从而确保插值多项式精确通过所有给定的点。</p><h3 id="拉格朗日插值的优点"><a href="#拉格朗日插值的优点" class="headerlink" title="拉格朗日插值的优点"></a>拉格朗日插值的优点</h3><ol><li><strong>直接性</strong>：插值多项式可以通过插值点直接构造，不需要求解线性方程组。</li><li><strong>形式统一</strong>：所有插值点一次性加入到多项式中，无需增量计算。</li></ol><h3 id="拉格朗日插值的缺点"><a href="#拉格朗日插值的缺点" class="headerlink" title="拉格朗日插值的缺点"></a>拉格朗日插值的缺点</h3><ol><li><strong>计算复杂度较高</strong>：当插值点数量较多时，计算 L_i(x) 的成本会增加。</li><li><strong>稳定性差</strong>：在某些情况下，如插值点分布不均匀时，可能会引发数值不稳定（如龙格现象）。</li><li><strong>适合插值点较少的情况</strong>：对于大量插值点的情况，使用其他方法（如分段插值或样条插值）通常更优。</li></ol><h2 id="余项"><a href="#余项" class="headerlink" title="余项"></a>余项</h2><p>在拉格朗日插值中，插值余项用于衡量拉格朗日插值多项式与实际函数之间的误差。它描述了插值多项式 ( P(x) ) 与被插值函数 ( f(x) ) 的差异大小。拉格朗日插值的余项公式提供了一个误差的上界，表示为：</p><h3 id="插值余项公式"><a href="#插值余项公式" class="headerlink" title="插值余项公式"></a>插值余项公式</h3><p>设 ( f(x) ) 是一个在区间上具有 ( n+1 ) 阶连续导数的函数，并且我们有 ( n+1 ) 个插值点 ( x_0, x_1, \ldots, x_n )。对于任意点 ( x )（通常 ( x ) 不等于插值点），拉格朗日插值多项式 ( P_n(x) ) 与函数 ( f(x) ) 之间的插值误差由以下余项表示：</p><p>[<br>R_n(x) = f(x) - P_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{i=0}^{n} (x - x_i)<br>]</p><p>其中：</p><ul><li>( \xi ) 是位于插值点 ( x_0, x_1, \ldots, x_n ) 之间的某个未知点。</li><li>( f^{(n+1)}(\xi) ) 表示 ( f ) 的 ( n+1 ) 阶导数在点 ( \xi ) 处的值。</li></ul><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><ol><li><strong>误差依赖于导数值</strong>：余项中包含了 ( f ) 在 ( (n+1) ) 阶导数的值 ( f^{(n+1)}(\xi) )，说明函数在更高阶导数上的变化对误差的影响较大。</li><li><strong>节点位置影响</strong>：余项中的乘积项 ( \prod_{i=0}^{n} (x - x_i) ) 表示 ( x ) 相对于插值节点的位置关系。如果 ( x ) 靠近插值点，误差较小；如果远离插值点，则误差可能会增大。</li><li><strong>阶数的影响</strong>：随着 ( n ) 的增大（即插值点的数量增加），插值多项式的阶数也增加，可能引发不稳定性（如高次多项式插值中的龙格现象），导致误差增大。</li></ol><h3 id="重要结论"><a href="#重要结论" class="headerlink" title="重要结论"></a>重要结论</h3><ul><li>拉格朗日插值在插值点上精确，通过所有已知点，所以在插值点上 ( R_n(x_i) = 0 )。</li><li>误差的大小不仅取决于插值点的数量和分布，还与函数的高阶导数变化相关。因此，在实际应用中，应注意合理选择插值点并尽可能减少插值多项式的阶数以降低误差。</li></ul>]]></content>
    
    
    <categories>
      
      <category>数学模型</category>
      
      <category>数值分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ResNet</title>
    <link href="/2024/11/11/20241111_%E6%AE%8B%E5%B7%AE%E5%9D%97/"/>
    <url>/2024/11/11/20241111_%E6%AE%8B%E5%B7%AE%E5%9D%97/</url>
    
    <content type="html"><![CDATA[<p>残差块（Residual Block）是ResNet（Residual Network）的核心思想之一，主要通过引入<strong>跳跃连接</strong>（skip connection）来帮助训练更深的神经网络。以下是对残差块的详细解释：</p><h3 id="1-残差块的基本结构"><a href="#1-残差块的基本结构" class="headerlink" title="1. 残差块的基本结构"></a>1. <strong>残差块的基本结构</strong></h3><p>残差块的基本结构包括以下部分：</p><ul><li><strong>常规的卷积层</strong>：这部分与普通的卷积神经网络（CNN）结构相似，通常包含卷积层、激活函数（如ReLU）以及可能的批量归一化层。</li><li><strong>跳跃连接（Shortcut Connection）</strong>：这是残差块的关键。跳跃连接将输入信号直接传递到输出端，绕过中间的卷积层。跳跃连接的输出会与卷积层的输出进行相加（通常是元素-wise加法）。</li></ul><p>图示结构：<br><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gauss">Input → [<span class="hljs-built_in">Conv</span> → ReLU → <span class="hljs-built_in">Conv</span>] → <span class="hljs-keyword">Output</span><br>              ↑            ↓<br>            Shortcut → Add<br></code></pre></td></tr></table></figure></p><h3 id="2-残差块的核心思想"><a href="#2-残差块的核心思想" class="headerlink" title="2. 残差块的核心思想"></a>2. <strong>残差块的核心思想</strong></h3><p>残差块的核心思想是学习“残差”（residual），而不是学习直接的映射。残差块的目标是通过学习输入和输出之间的差异来简化网络的学习过程。数学上，残差块的输出可以表示为：</p><p>[<br>y = F(x, \{W_i\}) + x<br>]</p><p>其中：</p><ul><li>(x) 是输入信号，</li><li>(F(x, \{W_i\})) 是通过卷积层和激活函数等得到的特征变换（即残差部分），</li><li>(y) 是最终的输出信号，</li><li>(W_i) 是卷积层的权重。</li></ul><p>简而言之，残差块并不是学习直接的输出 (y)，而是学习输入和输出之间的“差异”或“残差”。通过这种方式，网络可以更容易地优化，因为它不再需要学习每一层的完整映射。</p><h3 id="3-为什么残差连接有效？"><a href="#3-为什么残差连接有效？" class="headerlink" title="3. 为什么残差连接有效？"></a>3. <strong>为什么残差连接有效？</strong></h3><p>残差连接的引入带来了一些显著的好处：</p><ul><li><strong>缓解梯度消失问题</strong>：在传统的深度网络中，随着网络的加深，梯度会在反向传播过程中逐渐变小（梯度消失），导致网络难以训练。通过残差连接，梯度可以直接沿着跳跃连接传播，避免了梯度消失。</li><li><strong>简化优化过程</strong>：直接学习残差比学习完整的映射更容易。对于浅层网络，学习的映射可能较简单；而对于深层网络，学习的残差较容易得到优化。</li><li><strong>改善信息流</strong>：通过跳跃连接，输入信息可以绕过一些层传递到后面的层，这有助于缓解层间的“信息瓶颈”，使得深层网络能够更好地传播特征。</li></ul><h3 id="4-残差块的不同类型"><a href="#4-残差块的不同类型" class="headerlink" title="4. 残差块的不同类型"></a>4. <strong>残差块的不同类型</strong></h3><p>根据任务和结构的不同，残差块可以有所变化，主要有以下几种常见类型：</p><ul><li><strong>基础残差块</strong>：包括两个卷积层，每个卷积层后都有一个ReLU激活函数。输入信号通过跳跃连接直接加到输出。</li><li><strong>瓶颈残差块</strong>：为减少计算量，引入了1x1卷积层，在高维特征空间和低维特征空间之间进行映射，从而减少计算量。这种结构常见于更深的ResNet版本（如ResNet-50及以上）。</li></ul><h3 id="5-残差块的优势"><a href="#5-残差块的优势" class="headerlink" title="5. 残差块的优势"></a>5. <strong>残差块的优势</strong></h3><ul><li><strong>训练深层网络</strong>：通过残差块，可以训练非常深的神经网络（例如，ResNet-152），并且避免了深度网络在训练时遇到的退化问题。</li><li><strong>提高精度</strong>：ResNet凭借其残差连接，能够在多种图像分类、物体检测等任务中取得显著更好的性能。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>残差块的创新点在于引入了<strong>跳跃连接</strong>，使得网络可以学习输入和输出之间的“残差”而非直接的映射。这不仅解决了深度网络训练中的梯度消失和退化问题，也使得深层网络的训练更加高效，取得了更高的性能。在ResNet等模型中，残差块成为了深度神经网络训练中的一个关键组成部分。</p><h1 id="数学角度"><a href="#数学角度" class="headerlink" title="数学角度"></a>数学角度</h1><p>从数学角度理解ResNet（Residual Network）主要涉及其创新的<strong>残差学习</strong>（Residual Learning）理念，这一概念是通过引入<strong>跳跃连接（skip connections）</strong>来减少深度神经网络训练中的一些问题，特别是<strong>梯度消失</strong>和<strong>梯度爆炸</strong>问题。以下是对ResNet从数学角度的深入解释：</p><h3 id="1-传统神经网络的计算过程"><a href="#1-传统神经网络的计算过程" class="headerlink" title="1. 传统神经网络的计算过程"></a>1. <strong>传统神经网络的计算过程</strong></h3><p>对于传统的深度神经网络（DNN），假设我们有一个输入 ( x )，通过多个层（每一层的输出为 ( f )）进行处理，最终得到输出 ( y )，整个网络的过程可以表示为：</p><p>[<br>y = f_n(f_{n-1}(\dots f_2(f_1(x))\dots))<br>]</p><p>其中，( f_i ) 表示网络的每一层（比如卷积层、全连接层等），每一层会根据输入进行某种变换。</p><h3 id="2-ResNet的核心思想：残差学习"><a href="#2-ResNet的核心思想：残差学习" class="headerlink" title="2. ResNet的核心思想：残差学习"></a>2. <strong>ResNet的核心思想：残差学习</strong></h3><p>ResNet的核心想法是通过学习输入和输出之间的<strong>残差</strong>，而不是直接学习映射。假设我们希望通过一个深度网络计算一个映射 ( H(x) )，而不是直接学习 ( H(x) )，ResNet引入了残差映射 ( F(x) )，并且将它们的输出相加。</p><p>残差学习的核心公式是：</p><p>[<br>y = F(x, \{W_i\}) + x<br>]</p><p>其中：</p><ul><li>( F(x, \{W_i\}) ) 是网络的残差部分，表示层与层之间的变换（例如卷积、非线性激活等）。</li><li>( x ) 是输入信号（即跳跃连接传递的信号）。</li><li>( y ) 是输出。</li></ul><h3 id="3-残差块的数学表达"><a href="#3-残差块的数学表达" class="headerlink" title="3. 残差块的数学表达"></a>3. <strong>残差块的数学表达</strong></h3><p>在实际实现中，ResNet通过引入<strong>残差块</strong>（Residual Block），其结构在数学上可以表示为：</p><p>[<br>y = \mathcal{H}(x) + x<br>]</p><p>其中，( \mathcal{H}(x) ) 是网络希望学习的<strong>残差</strong>，而 ( x ) 是输入。即，ResNet不直接学习输入到输出的映射，而是学习输入到输出之间的差异。</p><h3 id="4-为什么这样做有效？"><a href="#4-为什么这样做有效？" class="headerlink" title="4. 为什么这样做有效？"></a>4. <strong>为什么这样做有效？</strong></h3><h4 id="4-1-缓解梯度消失-梯度爆炸问题"><a href="#4-1-缓解梯度消失-梯度爆炸问题" class="headerlink" title="4.1 缓解梯度消失/梯度爆炸问题"></a>4.1 <strong>缓解梯度消失/梯度爆炸问题</strong></h4><p>在传统的深度网络中，当网络层数增加时，梯度消失或梯度爆炸问题常常导致网络无法训练。而残差连接可以有效地缓解这个问题，因为它允许梯度直接通过跳跃连接向前传播。这意味着在反向传播时，梯度可以更容易地流过网络的较深层，而不至于在传递过程中变得过小或过大。</p><p>在数学上，通过引入残差块，梯度反向传播时能够更容易地传播回输入层，因为输入 ( x ) 会直接影响输出 ( y )，而不仅仅是通过中间的层（( F(x, \{W_i\}) )）进行间接影响。</p><h4 id="4-2-加速收敛"><a href="#4-2-加速收敛" class="headerlink" title="4.2 加速收敛"></a>4.2 <strong>加速收敛</strong></h4><p>由于网络学习的是“残差”而非直接映射，这通常意味着学习任务变得更加容易。例如，在一些情况下，直接学习映射 ( H(x) ) 可能非常复杂，而学习残差 ( F(x) ) 会使得学习变得简单，因为残差通常比直接映射更加接近零，学习起来更容易。</p><h4 id="4-3-退化问题（Degradation-Problem）"><a href="#4-3-退化问题（Degradation-Problem）" class="headerlink" title="4.3 退化问题（Degradation Problem）"></a>4.3 <strong>退化问题（Degradation Problem）</strong></h4><p>在传统深度网络中，随着层数的增加，网络的性能往往会下降。这是因为随着网络加深，优化变得更加困难，反向传播的梯度会越来越小，导致训练不收敛，称为“退化问题”。通过残差块，ResNet使得网络的深度与性能不再呈现负相关关系。事实上，ResNet的深度增加时，性能并不会恶化，反而因为残差学习的引入，网络变得更容易训练。</p><h4 id="4-4-简化优化问题"><a href="#4-4-简化优化问题" class="headerlink" title="4.4 简化优化问题"></a>4.4 <strong>简化优化问题</strong></h4><p>残差块通过直接加上输入 ( x ) 和输出 ( F(x) ) 来定义一个新函数 ( \mathcal{H}(x) )。这样做的好处在于，网络不必学习一个完全不同的目标，而是学习输入和目标之间的“差异”。这使得网络能够通过更少的训练步骤来收敛，并且在很多情况下，训练过程变得更加稳定。</p><h3 id="5-数学推导：ResNet的梯度传播"><a href="#5-数学推导：ResNet的梯度传播" class="headerlink" title="5. 数学推导：ResNet的梯度传播"></a>5. <strong>数学推导：ResNet的梯度传播</strong></h3><p>对于残差块，假设我们对每一层进行梯度计算：</p><p>[<br>\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial x} = \frac{\partial L}{\partial y} \cdot \left( 1 + \frac{\partial F(x)}{\partial x} \right)<br>]</p><p>由于 ( 1 + \frac{\partial F(x)}{\partial x} ) 保证了梯度的稳定传递（即不容易消失或爆炸），因此，网络训练时的梯度更容易传递回较早的层。</p><h3 id="6-Residual-Learning-的本质"><a href="#6-Residual-Learning-的本质" class="headerlink" title="6. Residual Learning 的本质"></a>6. <strong>Residual Learning 的本质</strong></h3><p>从数学角度来看，ResNet通过学习输入和目标之间的“差异”（残差），使得每一层的学习任务变得更加简单。它允许网络学习目标输出和输入之间的偏差，从而有效地解决了深度神经网络训练中的梯度问题，并且使得网络能够更容易地进行深度扩展而不影响性能。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>ResNet通过引入残差连接来解决深度网络训练中的退化问题、梯度消失和梯度爆炸问题。从数学上看，残差块通过学习“差异”而不是直接学习映射，使得深层神经网络变得更容易训练。数学上，残差连接的引入不仅改善了梯度传播，还使得深度网络能够在更高的层数下依然保持良好的训练效果，从而提升了模型的性能和稳定性。</p><h1 id="梯度公式"><a href="#梯度公式" class="headerlink" title="梯度公式"></a>梯度公式</h1><p>这段梯度计算公式：</p><p>[<br>\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial x} = \frac{\partial L}{\partial y} \cdot \left( 1 + \frac{\partial F(x)}{\partial x} \right)<br>]</p><h3 id="逐步解释："><a href="#逐步解释：" class="headerlink" title="逐步解释："></a>逐步解释：</h3><ol><li><p><strong>反向传播和链式法则</strong>：</p><ul><li>这个公式使用了<strong>链式法则</strong>（Chain Rule），它是深度学习中反向传播的核心原理。链式法则允许我们通过将复杂的导数拆解成多个简单的部分，来计算损失函数 ( L ) 对输入 ( x ) 的导数。</li></ul></li><li><p><strong>公式拆解</strong>：</p><ul><li>公式的左侧是 ( \frac{\partial L}{\partial x} )，表示损失函数 ( L ) 对输入 ( x ) 的梯度。</li><li>根据链式法则，梯度可以分解为：<br>[<br>\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial x}<br>]<br>其中：<ul><li>( \frac{\partial L}{\partial y} ) 是损失函数 ( L ) 对中间变量 ( y ) 的梯度（通常 ( y ) 是网络的输出）。</li><li>( \frac{\partial y}{\partial x} ) 是 ( y ) 对 ( x ) 的导数，表示输出 ( y ) 如何随着输入 ( x ) 的变化而变化。</li></ul></li></ul></li><li><p><strong>残差函数的作用</strong>：</p><ul><li>这个公式特指<strong>残差块</strong>（Residual Block）。在残差网络（ResNet）中，输出 ( y ) 不仅仅是 ( x ) 的某个函数，还包括了一个残差部分：<br>[<br>y = F(x) + x<br>]<br>所以，( y ) 对 ( x ) 的导数是：<br>[<br>\frac{\partial y}{\partial x} = 1 + \frac{\partial F(x)}{\partial x}<br>]<br>这里的 ( 1 ) 来自于直接的输入 ( x )，而 ( \frac{\partial F(x)}{\partial x} ) 来自于残差函数 ( F(x) ) 的导数。</li></ul></li><li><p><strong>最终的梯度计算</strong>：</p><ul><li>将上述部分组合在一起，我们得到：<br>[<br>\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \cdot \left( 1 + \frac{\partial F(x)}{\partial x} \right)<br>]<br>这意味着损失函数 ( L ) 对输入 ( x ) 的梯度是由以下两部分组成的：<ul><li>损失对 ( y ) 的梯度 ( \frac{\partial L}{\partial y} )；</li><li>输出 ( y ) 对输入 ( x ) 的梯度（即包括直接传递的 ( x ) 的影响以及残差部分 ( F(x) ) 的影响）。</li></ul></li></ul></li></ol><h3 id="为什么这样做有效？"><a href="#为什么这样做有效？" class="headerlink" title="为什么这样做有效？"></a>为什么这样做有效？</h3><p>在<strong>ResNet（残差网络）</strong>中，( 1 + \frac{\partial F(x)}{\partial x} ) 这一项意味着梯度可以通过跳跃连接直接传递，避免了深层网络中常见的<strong>梯度消失</strong>问题。由于输入 ( x ) 直接参与了输出 ( y ) 的计算，梯度能够更容易地在网络中传播，这使得深度网络的训练变得更加容易。</p><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>该公式展示了在残差网络中，如何通过“跳跃连接”学习残差来简化网络训练。残差连接帮助梯度在反向传播过程中更容易地传递，从而避免了深度神经网络中常见的梯度消失问题，使得更深的网络能够稳定训练并提高性能。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>批量规范化</title>
    <link href="/2024/11/11/20241112_%E6%89%B9%E9%87%8F%E8%A7%84%E8%8C%83%E5%8C%96/"/>
    <url>/2024/11/11/20241112_%E6%89%B9%E9%87%8F%E8%A7%84%E8%8C%83%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>在应用批量规范化时，<strong>批量大小的选择</strong>可能<strong>比没有批量规范化时更重要</strong>。</p><h1 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a><strong>momentum</strong></h1><p>在批量归一化（Batch Normalization，BN）中，<strong>momentum</strong>（动量）是一个重要的超参数，它决定了如何更新和调整移动均值（<code>moving_mean</code>）和移动方差（<code>moving_var</code>）的速度。动量的作用在于平滑训练过程中计算的均值和方差，从而使得模型在推理阶段（预测阶段）能够更加稳定地进行标准化。</p><h3 id="momentum的具体作用"><a href="#momentum的具体作用" class="headerlink" title="momentum的具体作用"></a><strong>momentum的具体作用</strong></h3><p>在批量归一化中，每次使用当前批次的数据计算均值和方差。但是，网络的每一层通常会在训练过程中看到不同的批次数据，这意味着计算出的均值和方差在每次训练时都可能会有所不同。为了应对这种不稳定，Batch Normalization引入了<strong>移动均值和方差</strong>，它们的更新不仅依赖于当前批次的均值和方差，还依赖于之前批次的统计数据。这样可以避免单个批次数据带来的波动。</p><h4 id="公式"><a href="#公式" class="headerlink" title="公式"></a><strong>公式</strong></h4><p>在训练过程中，移动均值和移动方差的更新公式如下：</p><p>[<br>\text{moving_mean} = \text{momentum} \times \text{moving_mean} + (1 - \text{momentum}) \times \text{mean}<br>]<br>[<br>\text{moving_var} = \text{momentum} \times \text{moving_var} + (1 - \text{momentum}) \times \text{var}<br>]</p><ul><li><strong>momentum</strong>: 动量系数，控制历史均值和方差对当前批次计算的影响程度。通常取值范围是 [0, 1]，它表示历史信息的权重。</li><li><strong>mean</strong> 和 <strong>var</strong>: 当前批次的均值和方差。</li></ul><h4 id="momentum的作用："><a href="#momentum的作用：" class="headerlink" title="momentum的作用："></a><strong>momentum的作用</strong>：</h4><ul><li><strong>平滑更新</strong>：通过使用动量，移动均值和方差的更新变得更加平滑，不会因为单个批次的波动而产生较大的变化。</li><li><strong>减少训练波动</strong>：动量可以减少由于小批量数据而带来的训练波动，避免在推理阶段因批次差异造成的较大差异。</li><li><strong>稳定预测</strong>：在推理阶段（即测试和验证阶段），批量归一化不再使用当前批次的均值和方差，而是使用训练过程中计算的<strong>移动均值和方差</strong>。这可以确保在推理时的标准化操作是基于整个训练集的数据特征，而不是依赖单个批次的数据。</li></ul><h3 id="动量参数的选择："><a href="#动量参数的选择：" class="headerlink" title="动量参数的选择："></a><strong>动量参数的选择</strong>：</h3><ul><li><strong>较高的momentum（接近1）</strong>：如果momentum接近1，那么移动均值和方差的更新将主要依赖于历史信息，当前批次的影响较小。这样会使得更新更加平稳，但可能会导致对当前批次信息的反应较慢。</li><li><strong>较低的momentum（接近0）</strong>：如果momentum接近0，那么更新过程会更多地依赖当前批次的数据，而历史数据的影响会较小。这意味着模型会更灵活地适应当前批次的数据，但可能会导致预测时的不稳定性。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><ul><li><strong>momentum</strong>是一个超参数，控制历史批次均值和方差对当前批次更新的影响程度。</li><li>在训练过程中，动量帮助平滑均值和方差的更新，避免由单一批次造成的不稳定，并确保模型在预测阶段使用稳定的统计量。</li><li>通常，<strong>momentum</strong>值设定为接近1（例如0.9或0.99），以便提供稳定的学习过程。</li></ul>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NiN</title>
    <link href="/2024/11/10/20241110_NiN/"/>
    <url>/2024/11/10/20241110_NiN/</url>
    
    <content type="html"><![CDATA[<p>网络中的网络（Network in Network，NiN）提出的主要目的是通过使用“网络”的方式提升卷积层的特征学习能力，从而有效解决卷积神经网络（CNN）在特征表达上的局限性。</p><h1 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h1><ol><li><p><strong>增强非线性表达能力</strong>：传统卷积层是通过卷积核提取局部特征，但在每次卷积后只是单一的线性组合，非线性表达能力有限。NiN通过在卷积层后引入了多层感知机（MLP）结构，即在卷积操作后加上1x1卷积，这个1x1卷积充当了小型全连接层。这种方式能让每一个卷积输出的通道通过更深的层次学习不同的特征组合，提高了模型的非线性表达能力。</p></li><li><p><strong>减少全连接层的依赖</strong>：传统的CNN在特征提取之后往往依赖于全连接层进行特征整合，但全连接层参数量大，容易导致过拟合并增加计算负担。NiN通过1x1卷积层代替传统的全连接层结构，从而在保持高效特征融合的同时减少参数量，避免过拟合问题。</p></li><li><p><strong>提升模型的泛化能力</strong>：NiN的架构设计更加轻量且参数相对较少，因此模型的泛化能力得到提升。同时，由于减少了全连接层的依赖，网络对输入尺寸的限制也降低了。</p></li><li><p><strong>提高特征的局部响应能力</strong>：通过1x1卷积，NiN可以更精细地控制每个通道的特征，这种局部响应能力使模型在特征提取时能更有效地表达复杂模式，提高了对图像细节的捕获能力。</p></li></ol><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><ol><li><strong>计算开销较大</strong>：NiN引入了大量的1x1卷积核。虽然1x1卷积的参数较少，但堆叠多个1x1卷积仍然会增加计算量，尤其在通道数较多的情况下，会显著增加运算开销，从而影响网络的推理速度。</li><li><strong>不适合过深的网络结构</strong>：NiN的设计特点使其适合浅层网络，层数过多可能导致梯度消失或梯度爆炸的问题，影响模型训练的稳定性。因此，在构建较深层的网络时，NiN结构的效果可能不如后来的ResNet等深度网络。</li><li><strong>缺乏全局特征的感知</strong>：NiN网络的设计初衷是增强局部特征的提取，但在全局特征的捕获方面有所不足。1x1卷积主要用于整合局部通道的信息，无法在空间维度上获得长距离的依赖关系，因而对全局信息的捕捉能力较弱。</li><li><strong>对数据量依赖较大，容易过拟合</strong>：虽然NiN减少了全连接层的依赖，但仍然存在较多的1x1卷积层，这些层数的叠加容易导致网络参数量较大，尤其在训练数据量不足的情况下容易发生过拟合，需要借助数据增强、正则化等手段进行缓解。</li><li><strong>难以适应更复杂的任务</strong>：NiN的架构在简单分类任务上效果较好，但在更复杂的任务（如目标检测、语义分割等）中表现不佳，难以适应任务所需的特征层次。后来的一些更复杂的网络架构（如ResNet、Inception等）提供了更好的模块化设计和特征学习能力，逐渐取代了NiN。</li></ol><h1 id="缺乏全局特征的感知"><a href="#缺乏全局特征的感知" class="headerlink" title="缺乏全局特征的感知"></a>缺乏全局特征的感知</h1><p><strong>1. 感受野的限制</strong></p><ul><li><p><strong>局部感受野</strong>：在卷积神经网络中，感受野（Receptive Field）指的是网络中某个神经元在输入空间上“看到”的区域。NiN网络主要使用小尺寸的卷积核（如1x1卷积），这些卷积核只能感知到局部的空间信息，无法直接覆盖整个输入图像。</p></li><li><p><strong>感受野的扩大受限</strong>：虽然通过堆叠多个卷积层，感受野可以逐渐扩大，但这种增长是线性的，且效率较低。在NiN中，没有使用诸如空洞卷积（Dilated Convolution）或较大尺寸的卷积核来显著扩大感受野，因此对于全局信息的捕获能力有限。</p></li></ul><p><strong>2. 1x1卷积的局限性</strong></p><ul><li><p><strong>空间信息的缺失</strong>：1x1卷积实际上是在每个空间位置上对通道进行非线性组合，相当于对每个像素位置独立地进行操作，缺乏对空间邻域的考虑。</p></li><li><p><strong>无法建模空间依赖</strong>：由于1x1卷积不涉及空间维度上的交互，无法捕获像素之间的空间关系，特别是远距离的依赖关系。这限制了网络对全局结构和模式的感知。</p></li></ul><p><strong>3. 缺乏全局信息融合机制</strong></p><ul><li><p><strong>没有全局池化层</strong>：全局平均池化（Global Average Pooling）或全局最大池化能够将整个特征图的信息浓缩到一个向量中，帮助网络理解全局特征。NiN网络没有引入这样的层，导致全局信息没有被有效地整合。</p></li><li><p><strong>缺少注意力机制</strong>：现代网络常常使用注意力机制来捕获全局依赖，增强特征表示的全局性。NiN没有采用这些机制，进一步限制了其对全局特征的感知。</p></li></ul><p><strong>4. 深度和层次结构的限制</strong></p><ul><li><p><strong>网络深度不足</strong>：NiN的层数相对较少，无法通过加深网络来扩大感受野。而更深的网络（如ResNet）能够通过多层的堆叠，使得高层次的特征包含更多的全局信息。</p></li><li><p><strong>层次化特征提取不足</strong>：NiN主要侧重于在每个卷积层后进行非线性变换，但缺乏对特征的层次化抽象，无法有效地从低级特征逐步提取高级的全局特征。</p></li></ul><p><strong>5. 举例说明</strong></p><p>假设有一张图像，需要识别其中的某种全局模式（例如，对称性、整体形状）。NiN网络由于其感受野限制和缺乏全局信息融合的机制，可能只能捕获局部的纹理或边缘信息，而无法识别整个图像的全局模式，导致在这类任务上表现不佳。</p><p><strong>6. 数学层面的解释</strong></p><ul><li><p><strong>感受野计算</strong>：对于一个卷积神经网络，感受野的大小与卷积核尺寸、层数、池化等操作相关。NiN网络中，多数卷积核尺寸较小，且缺乏池化层来缩小特征图尺寸，导致感受野增长缓慢。</p></li><li><p><strong>信息瓶颈</strong>：由于每个1x1卷积只在局部进行通道混合，没有空间上的信息汇聚，无法通过网络结构将全局的信息传递到后续层。</p></li></ul><p><strong>7. 对比其他网络</strong></p><ul><li><p><strong>Inception网络</strong>：通过并行使用不同尺寸的卷积核（如1x1、3x3、5x5），能够同时捕获不同尺度的特征，包括全局信息。</p></li><li><p><strong>ResNet和DenseNet</strong>：通过增加网络深度和引入跳跃连接（Skip Connections），扩大感受野并缓解梯度消失问题，使得网络能够学习到更高级别的全局特征。</p></li><li><p><strong>注意力模型（如Transformer）</strong>：使用自注意力机制，直接建模全局范围内的特征关系，弥补卷积操作在全局信息捕获上的不足。</p></li></ul><p><strong>8. 总结</strong></p><p>NiN网络缺乏全局特征的感知，主要原因在于：</p><ul><li><strong>感受野受限</strong>：无法通过网络结构有效扩大感受野，导致对全局信息的覆盖不足。</li><li><strong>1x1卷积的空间局限</strong>：仅在通道维度上混合特征，缺乏对空间维度上像素关系的建模。</li><li><strong>缺乏全局信息融合机制</strong>：没有使用全局池化或注意力机制来整合全局特征。</li><li><strong>网络深度和层次不足</strong>：无法通过深度和层次化的特征提取来捕获全局模式。</li></ul><p>因此，尽管NiN在局部特征的非线性表达上有优势，但在需要全局特征感知的任务中，其性能可能不如那些专门设计用于捕获全局信息的网络架构。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VGG</title>
    <link href="/2024/11/10/20241110_VGG/"/>
    <url>/2024/11/10/20241110_VGG/</url>
    
    <content type="html"><![CDATA[<p>LeNet</p><ul><li>2卷积+池化层</li><li>2全连接层</li></ul><p>AlexNet</p><ul><li>更大更深</li><li>ReLu，Dropout，数据增强</li></ul><p>VGG</p><ul><li>更大更深的AlexNet（重复的VGG块）</li></ul><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><p>尽管VGG（Visual Geometry Group）网络有许多优点，但它也存在一些显著的缺点，主要体现在计算资源消耗、模型规模和训练效率等方面。以下是VGG的主要缺点：</p><h3 id="1-计算资源消耗大"><a href="#1-计算资源消耗大" class="headerlink" title="1. 计算资源消耗大"></a>1. <strong>计算资源消耗大</strong></h3><ul><li><strong>参数量巨大</strong>：VGG 网络的卷积层使用多个 3x3 的卷积核，并且通过堆叠多层卷积来加深网络。这导致了模型的 <strong>参数量非常庞大</strong>。尤其是在 VGG16 和 VGG19 这样的版本中，全连接层的参数数量更是非常庞大。<ul><li>例如，VGG16 中有 138百万个参数，这意味着需要大量的内存和计算资源来训练和存储模型。</li></ul></li><li>由于参数量庞大，训练 VGG 网络需要 <strong>大量的 GPU 内存</strong> 和 <strong>长时间的训练时间</strong>，对计算资源的要求非常高。</li></ul><h3 id="2-推理速度慢"><a href="#2-推理速度慢" class="headerlink" title="2. 推理速度慢"></a>2. <strong>推理速度慢</strong></h3><ul><li>由于网络层数较多且参数众多，VGG 网络的 <strong>推理速度较慢</strong>。在实时应用（例如视频分析、自动驾驶等）中，这种网络的速度可能无法满足低延迟的要求，特别是在边缘设备或资源受限的设备上。</li><li>由于大量的计算量，VGG 在推理时可能需要较多的时间，尤其是在输入图像较大时。</li></ul><h3 id="3-内存消耗高"><a href="#3-内存消耗高" class="headerlink" title="3. 内存消耗高"></a>3. <strong>内存消耗高</strong></h3><ul><li>训练深度网络时，VGG 的 <strong>内存消耗较高</strong>。尤其是存储梯度、激活值和中间层输出时，网络的深度和参数量会导致显著的内存占用。</li><li>对于资源有限的环境，尤其是嵌入式设备和移动设备，这可能导致无法运行或者需要大量的内存优化技巧。</li></ul><h3 id="4-缺乏创新性"><a href="#4-缺乏创新性" class="headerlink" title="4. 缺乏创新性"></a>4. <strong>缺乏创新性</strong></h3><ul><li>VGG 网络采用的是一种 <strong>相对简单的架构</strong>，虽然它在深度上取得了成功，但其本质上并没有提出一些创新性的结构或新型的训练技巧。相比之下，像 ResNet、Inception 等后续的网络提出了更加创新和高效的设计。</li><li><strong>ResNet</strong> 引入了残差连接，极大地缓解了深层网络训练中的梯度消失问题，而 <strong>Inception</strong> 通过引入不同大小的卷积核和层次化设计，提高了模型的计算效率。VGG 在这些方面相对缺乏创新。</li></ul><h3 id="5-容易过拟合"><a href="#5-容易过拟合" class="headerlink" title="5. 容易过拟合"></a>5. <strong>容易过拟合</strong></h3><ul><li>由于参数量巨大且没有加入像 Batch Normalization（批量归一化）等正则化技术，VGG 网络更容易出现 <strong>过拟合</strong>，特别是在数据集较小的情况下。虽然 VGG 通过加入 Dropout 和数据增强来缓解过拟合问题，但仍然需要更多的训练数据和更精细的调参。</li><li>过拟合通常会导致网络在训练集上表现良好，但在测试集上表现较差，影响其泛化能力。</li></ul><h3 id="6-不适合小型设备"><a href="#6-不适合小型设备" class="headerlink" title="6. 不适合小型设备"></a>6. <strong>不适合小型设备</strong></h3><ul><li>由于模型的深度和参数量较大，VGG 网络不适合在 <strong>计算能力较弱</strong> 或 <strong>内存较小的设备</strong> 上运行。例如，智能手机、嵌入式设备和物联网设备通常无法高效运行如此庞大的模型。</li><li>对于这些设备，通常需要更小、更高效的网络，如 MobileNet、SqueezeNet 等。</li></ul><h3 id="7-对计算力依赖强"><a href="#7-对计算力依赖强" class="headerlink" title="7. 对计算力依赖强"></a>7. <strong>对计算力依赖强</strong></h3><ul><li>VGG 的训练和推理过程对 <strong>计算能力的依赖非常强</strong>，特别是在没有 GPU 的情况下，训练 VGG 网络可能非常耗时。即便使用 GPU，训练时间也可能非常长，特别是在使用大规模数据集（如 ImageNet）时。</li></ul><h3 id="8-没有充分利用并行性"><a href="#8-没有充分利用并行性" class="headerlink" title="8. 没有充分利用并行性"></a>8. <strong>没有充分利用并行性</strong></h3><ul><li>相比后来的网络架构（如 Inception 或者 EfficientNet），VGG 的设计没有充分利用卷积操作的 <strong>并行性</strong>。例如，Inception 网络通过使用不同大小的卷积核并行计算特征，减少了计算开销；而 VGG 采用了较多的相同大小的卷积核和多层结构，这种设计虽然效果好，但并没有优化计算效率。</li></ul><h1 id="相较于AlexNet的几个主要进步"><a href="#相较于AlexNet的几个主要进步" class="headerlink" title="相较于AlexNet的几个主要进步"></a>相较于AlexNet的几个主要进步</h1><h3 id="1-更深的网络结构"><a href="#1-更深的网络结构" class="headerlink" title="1. 更深的网络结构"></a>1. <strong>更深的网络结构</strong></h3><ul><li><strong>AlexNet</strong>：AlexNet包含8层，其中5层是卷积层，3层是全连接层。AlexNet是深度学习网络中早期的成功应用，但其深度在当时较浅。</li><li><strong>VGG</strong>：VGG网络进一步加深了网络结构，设计了16层（VGG-16）和19层（VGG-19）的深度网络。这种深度使网络可以学习到更复杂、更高层次的特征表示，从而提升了分类精度。</li></ul><h3 id="2-统一的小卷积核（3x3）"><a href="#2-统一的小卷积核（3x3）" class="headerlink" title="2. 统一的小卷积核（3x3）"></a>2. <strong>统一的小卷积核（3x3）</strong></h3><ul><li><strong>AlexNet</strong>：AlexNet的卷积层使用多种卷积核大小（11x11、5x5和3x3），以捕捉不同的特征尺度。但大的卷积核（如11x11）会引入大量参数，增加了计算量。</li><li><strong>VGG</strong>：VGG则统一使用3x3的卷积核，通过多个3x3卷积堆叠来代替更大的卷积核。这样设计的优点是可以在保持参数数量较少的情况下，增加网络的深度和非线性能力，提取到更细致的特征。</li></ul><h3 id="3-更稳定的特征表示"><a href="#3-更稳定的特征表示" class="headerlink" title="3. 更稳定的特征表示"></a>3. <strong>更稳定的特征表示</strong></h3><ul><li>VGG采用多个小卷积核堆叠，相较于单层大卷积核能够引入更多的非线性激活函数。这种方式在理论上增加了模型的非线性表达能力，也增强了特征的稳定性。</li><li>同时，VGG网络中的池化操作也很规则，卷积层后通常跟随2x2的最大池化层，从而逐步减少特征图的大小并压缩信息。</li></ul><h3 id="4-更简洁的网络设计"><a href="#4-更简洁的网络设计" class="headerlink" title="4. 更简洁的网络设计"></a>4. <strong>更简洁的网络设计</strong></h3><ul><li><strong>AlexNet</strong>：AlexNet的设计相对复杂，包含不同尺寸的卷积核、局部响应归一化（LRN）层等。</li><li><strong>VGG</strong>：VGG去掉了复杂的结构，舍弃了LRN层，依靠深度和小卷积核来提升性能。这种简洁的设计更具通用性，也方便网络的迁移和复用，成为了后续许多深度学习架构的基础。</li></ul><h3 id="5-性能的提升"><a href="#5-性能的提升" class="headerlink" title="5. 性能的提升"></a>5. <strong>性能的提升</strong></h3><ul><li><strong>AlexNet</strong>：在2012年ImageNet比赛中取得了显著的成功，但其错误率约为16.4%。</li><li><strong>VGG</strong>：在2014年的ImageNet比赛中，VGG-16将Top-5错误率降到了7.3%，相比AlexNet在准确性上有了显著提升。</li></ul><h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><p>VGG（Visual Geometry Group）网络的优点主要体现在其简单而有效的架构设计上，尤其在图像分类任务中表现出色。以下是VGG网络的主要优点：</p><h3 id="1-简单且统一的网络架构"><a href="#1-简单且统一的网络架构" class="headerlink" title="1. 简单且统一的网络架构"></a>1. <strong>简单且统一的网络架构</strong></h3><ul><li>VGG 网络的一个突出特点是其 <strong>统一且简单的架构设计</strong>。所有的卷积层都使用了相同的卷积核大小（3x3）和步幅（1），池化层使用 2x2 的最大池化，步幅为 2。这使得网络的结构非常规律，易于理解和实现。</li><li>相比其他网络（如 AlexNet），VGG 网络避免了复杂的结构设计，采用了简单且一致的方式堆叠卷积层。</li></ul><h3 id="2-更深的网络结构"><a href="#2-更深的网络结构" class="headerlink" title="2. 更深的网络结构"></a>2. <strong>更深的网络结构</strong></h3><ul><li>VGG 网络通过 <strong>增加层数</strong>（通常为16层或19层）来提高网络的表达能力。更深的网络可以捕捉到更丰富的特征，使得模型在图像识别等任务中具有更高的性能。</li><li>更深的网络相比较浅的网络有更强的抽象能力，能够识别更复杂的图像模式。</li></ul><h3 id="3-更小的卷积核"><a href="#3-更小的卷积核" class="headerlink" title="3. 更小的卷积核"></a>3. <strong>更小的卷积核</strong></h3><ul><li>VGG 网络使用了 <strong>3x3</strong> 的卷积核代替较大的卷积核（例如 5x5 或 7x7）。小卷积核具有两个优势：<ol><li><strong>减少参数数量</strong>：使用多个小卷积核的组合可以达到与一个大卷积核相同的感受野，同时减少计算量和参数数量。</li><li><strong>增加非线性</strong>：通过堆叠多个小卷积核，网络可以引入更多的非线性，使得模型能够捕捉到更多的复杂模式。</li></ol></li></ul><h3 id="4-较好的性能"><a href="#4-较好的性能" class="headerlink" title="4. 较好的性能"></a>4. <strong>较好的性能</strong></h3><ul><li>VGG 网络在许多视觉任务上表现出了 <strong>优秀的性能</strong>，特别是在图像分类任务中，VGG16 和 VGG19 这两个常见版本在 ImageNet 上都取得了优异的结果。</li><li>通过增加网络的深度，VGG 能够更好地处理复杂的视觉问题，取得比浅层网络更高的准确率。</li></ul><h3 id="5-易于迁移学习"><a href="#5-易于迁移学习" class="headerlink" title="5. 易于迁移学习"></a>5. <strong>易于迁移学习</strong></h3><ul><li>VGG 网络由于其结构的简洁性和广泛的应用，已经成为 <strong>迁移学习</strong> 中的经典模型之一。许多预训练的 VGG 模型被广泛使用，并且能够在新的任务中取得很好的效果，尤其是在数据较少的情况下。</li><li>在迁移学习中，VGG 模型的卷积层特征可以作为其他任务的强大特征提取器。</li></ul><h3 id="6-更强的特征提取能力"><a href="#6-更强的特征提取能力" class="headerlink" title="6. 更强的特征提取能力"></a>6. <strong>更强的特征提取能力</strong></h3><ul><li>VGG 网络由于其深层结构，能够从输入图像中提取出更加丰富和层次化的特征。随着网络的加深，网络能够从低级别的边缘和纹理特征逐渐构建到高级的物体部件和语义特征。</li></ul><h3 id="7-可扩展性"><a href="#7-可扩展性" class="headerlink" title="7. 可扩展性"></a>7. <strong>可扩展性</strong></h3><ul><li>VGG 网络的设计原则非常简单，使得网络结构容易进行 <strong>扩展</strong>。例如，可以通过增加卷积层的数量或通道数，或者修改全连接层的结构来适应特定任务的需求。</li><li>由于设计的简单性，它能够较容易地与其他类型的网络（如全卷积网络）进行结合，或用于生成更加复杂的架构。</li></ul><h3 id="8-广泛的应用"><a href="#8-广泛的应用" class="headerlink" title="8. 广泛的应用"></a>8. <strong>广泛的应用</strong></h3><ul><li>VGG 网络被广泛应用于各类视觉任务，不仅限于图像分类，还被用于目标检测、图像分割、风格迁移、视频处理等多种领域。</li></ul>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet</title>
    <link href="/2024/11/07/20241107_AlexNet/"/>
    <url>/2024/11/07/20241107_AlexNet/</url>
    
    <content type="html"><![CDATA[<p>AlexNet的提出解决了当时在计算机视觉领域中的大规模图像识别问题，尤其是深层卷积神经网络在大数据集上的训练效率和效果问题。以下是AlexNet解决的问题和其创新点：</p><h1 id="问题解决方向"><a href="#问题解决方向" class="headerlink" title="问题解决方向"></a>问题解决方向</h1><ol><li><strong>处理大规模数据集的能力</strong>：在AlexNet之前，模型在小数据集上训练时通常表现良好，但在大型数据集上（如ImageNet）效果不佳。AlexNet通过设计更深层次和更宽的网络结构，使其能够学习到丰富的特征，成功应对大规模图像数据。</li><li><strong>计算资源限制</strong>：深层网络通常需要大量计算资源，AlexNet利用GPU并行加速训练，有效减少了计算时间，使得在大规模数据上训练深层神经网络成为可能。</li></ol><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><p>AlexNet在当时的深度学习领域发挥了开创性作用，但其参数量大、计算成本高、过拟合风险、缺乏跨通道融合和灵活性等缺点，限制了其在现代应用中的效率和扩展性。随着技术的进步，许多后续网络（如VGG、GoogLeNet和ResNet）在AlexNet的基础上进一步优化，解决了这些不足。</p><h3 id="1-参数量大，计算资源需求高"><a href="#1-参数量大，计算资源需求高" class="headerlink" title="1. 参数量大，计算资源需求高"></a>1. <strong>参数量大，计算资源需求高</strong></h3><ul><li><strong>缺点</strong>：AlexNet包含约6000万个参数，这对计算资源的需求非常高，在当时只能依赖多GPU并行训练，这样的计算要求不适用于资源受限的设备。</li><li><strong>影响</strong>：模型训练和推理速度较慢，导致存储和计算成本高，在实际应用中难以部署在内存有限的设备（如移动端）上。</li></ul><h3 id="2-容易出现过拟合"><a href="#2-容易出现过拟合" class="headerlink" title="2. 容易出现过拟合"></a>2. <strong>容易出现过拟合</strong></h3><ul><li><strong>缺点</strong>：尽管AlexNet引入了Dropout正则化来减少过拟合，但在特定情况下，特别是当训练数据不足时，过拟合问题依然明显。</li><li><strong>影响</strong>：模型泛化能力可能不足，在实际应用中可能无法很好地处理训练数据外的新样本。</li></ul><h3 id="3-卷积层和全连接层设计不够灵活"><a href="#3-卷积层和全连接层设计不够灵活" class="headerlink" title="3. 卷积层和全连接层设计不够灵活"></a>3. <strong>卷积层和全连接层设计不够灵活</strong></h3><ul><li><strong>缺点</strong>：AlexNet使用了大尺寸的卷积核（如第一个卷积层为 (11 \times 11)），在后续的网络设计中被证明不够灵活且计算开销大。此外，AlexNet的全连接层参数量过大，也限制了网络的灵活性。</li><li><strong>影响</strong>：使得模型在提取多尺度特征时能力较弱，且计算开销不必要地增大；此外，在处理较小图像时不够有效率。</li></ul><h3 id="4-缺少跨通道的信息融合"><a href="#4-缺少跨通道的信息融合" class="headerlink" title="4. 缺少跨通道的信息融合"></a>4. <strong>缺少跨通道的信息融合</strong></h3><ul><li><strong>缺点</strong>：AlexNet主要依赖传统的卷积层来提取特征，没有有效融合不同通道之间的信息。相比之下，后来的模型（如GoogLeNet、ResNet）设计了更加复杂的模块来跨通道融合特征。</li><li><strong>影响</strong>：可能会限制模型在处理具有不同特征类型或复杂结构的图像时的表现。</li></ul><h3 id="5-不具备残差连接，训练深层网络有困难"><a href="#5-不具备残差连接，训练深层网络有困难" class="headerlink" title="5. 不具备残差连接，训练深层网络有困难"></a>5. <strong>不具备残差连接，训练深层网络有困难</strong></h3><ul><li><strong>缺点</strong>：AlexNet没有采用残差连接或其他跳跃连接来辅助梯度传递，而后来的网络（如ResNet）通过这种连接显著改善了深层网络的训练效果。</li><li><strong>影响</strong>：AlexNet在进一步加深时容易面临梯度消失问题，不容易训练更深层的网络，难以在更复杂的任务上进行扩展。</li></ul><h3 id="6-卷积层和池化层排列方式的局限性"><a href="#6-卷积层和池化层排列方式的局限性" class="headerlink" title="6. 卷积层和池化层排列方式的局限性"></a>6. <strong>卷积层和池化层排列方式的局限性</strong></h3><ul><li><strong>缺点</strong>：AlexNet中固定的卷积层和池化层的组合方式相对简单，无法在多尺度特征提取上有良好的表现。</li><li><strong>影响</strong>：无法提取到一些高层、细致的图像特征，对复杂场景的适应能力较弱。</li></ul><h1 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h1><ol><li><p><strong>ReLU激活函数</strong>：AlexNet引入了ReLU（Rectified Linear Unit）激活函数代替传统的Sigmoid或Tanh函数。这种激活函数计算简单，可以有效减少梯度消失问题，加快网络的收敛速度。</p></li><li><p><strong>Dropout正则化</strong>：为减轻过拟合问题，AlexNet引入了Dropout正则化层。Dropout在训练时随机丢弃部分神经元，使网络不依赖特定的神经元，提升了模型的泛化能力。</p></li><li><p><strong>重叠池化层</strong>：AlexNet在池化层中引入重叠池化（Overlapping Pooling），即池化窗口之间存在重叠。这种设计可以保留更多细节信息，同时避免下采样带来的信息损失，提高模型性能。</p></li><li><p><strong>数据增强</strong>：为了增强数据集的多样性并避免过拟合，AlexNet在训练时采用数据增强方法，如随机裁剪、翻转和RGB通道变化。这一策略帮助网络更好地适应不同的图像变化，提高了泛化能力。</p></li><li><p><strong>多GPU并行训练</strong>：AlexNet是首个利用多GPU并行训练的网络，通过将模型分布到两个GPU上，减小了每个GPU的计算负担，从而使得深层网络的训练更加可行。</p></li></ol><h1 id="AlexNet的优点"><a href="#AlexNet的优点" class="headerlink" title="AlexNet的优点"></a>AlexNet的优点</h1><ol><li><strong>强大的特征提取能力</strong>：通过更深的层次结构和更宽的网络设计，AlexNet能够捕捉更加丰富和复杂的图像特征，使其在识别复杂图像内容上有更高的精度。</li><li><strong>解决了梯度消失问题</strong>：使用ReLU激活函数，AlexNet有效地缓解了梯度消失问题，加快了网络的训练速度，使得深层网络在大规模数据集上变得更加可行。</li><li><strong>高效的正则化方法</strong>：AlexNet引入了Dropout正则化，降低了过拟合风险，显著提高了模型的泛化能力。</li><li><strong>并行化计算</strong>：AlexNet通过利用多GPU并行训练，加速了训练过程，为之后的深度学习模型开创了多GPU加速的先河。</li><li><strong>数据增强技术</strong>：数据增强（如随机裁剪、翻转和颜色通道扰动）使得模型对不同环境的图像更具鲁棒性，有效增强了模型的泛化能力。</li></ol>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeNet</title>
    <link href="/2024/11/06/20241106_LeNet/"/>
    <url>/2024/11/06/20241106_LeNet/</url>
    
    <content type="html"><![CDATA[<p>LeNet 是由 Yann LeCun 等人于 1989 年提出的卷积神经网络 (CNN) 架构，主要目的是解决手写数字识别问题，尤其是在 <strong>MNIST</strong> 数据集上的数字分类。LeNet 的提出是在当时深度学习和卷积神经网络技术尚未成熟的背景下，提出了一种有效的网络结构来处理图像分类任务。</p><h1 id="LeNet-解决的问题："><a href="#LeNet-解决的问题：" class="headerlink" title="LeNet 解决的问题："></a>LeNet 解决的问题：</h1><ol><li><strong>手写数字识别</strong>：LeNet 最初的设计目标是进行手写数字的识别，尤其是用于银行支票的数字识别。</li><li><strong>提高图像分类的效率</strong>：它通过卷积层来提取图像中的空间特征，避免了传统的手工特征提取方法，显著提高了图像分类的性能。</li></ol><h1 id="LeNet的缺点："><a href="#LeNet的缺点：" class="headerlink" title="LeNet的缺点："></a>LeNet的缺点：</h1><p>LeNet在深度学习发展初期具有重要的突破性，但随着技术的进步和应用的复杂化，其缺点逐渐显现，主要包括以下几点：</p><h4 id="1-对复杂任务的局限性"><a href="#1-对复杂任务的局限性" class="headerlink" title="1. 对复杂任务的局限性"></a>1. <strong>对复杂任务的局限性</strong></h4><ul><li><strong>有限的层数和参数</strong>：LeNet的层数较少，参数量较小，适用于简单任务（如手写数字识别），但对于复杂的任务（如自然图像分类、物体检测）则表现不佳。</li><li><strong>提取特征有限</strong>：由于特征提取的层数较少，LeNet对复杂图像中的高层次特征（如多物体、复杂背景）提取能力不足，导致在处理复杂视觉任务时表现欠佳。</li></ul><h4 id="2-缺少深度和宽度，模型容量不足"><a href="#2-缺少深度和宽度，模型容量不足" class="headerlink" title="2. 缺少深度和宽度，模型容量不足"></a>2. <strong>缺少深度和宽度，模型容量不足</strong></h4><ul><li>LeNet的网络深度和宽度（通道数）都有限，导致模型容量较小，不足以捕捉大规模数据集中的丰富模式。</li><li>随着数据量的增加和任务的复杂化，模型需要更深层次和更宽通道的设计来容纳更多的参数，以学习更丰富的特征表示。</li></ul><h4 id="3-池化操作简单"><a href="#3-池化操作简单" class="headerlink" title="3. 池化操作简单"></a>3. <strong>池化操作简单</strong></h4><ul><li><strong>使用平均池化</strong>：LeNet采用平均池化（Average Pooling），容易导致信息的平均化和丢失。后来的模型多用最大池化（Max Pooling），更擅长保留图像的显著特征和边缘信息，使模型更具识别能力。</li><li><strong>缺少全局信息聚合</strong>：LeNet的池化操作只聚合了局部信息，而没有全局特征的聚合。对更复杂的视觉任务来说，全局信息的缺乏会限制模型的表现。</li></ul><h4 id="4-过于依赖手工设计的特征"><a href="#4-过于依赖手工设计的特征" class="headerlink" title="4. 过于依赖手工设计的特征"></a>4. <strong>过于依赖手工设计的特征</strong></h4><ul><li>LeNet的设计过程需要手工调节卷积核大小、通道数等，缺少自动化的调整手段。这些设计并非对所有任务都有效，而现代深度学习框架中更趋向于自动化搜索最佳结构（如AutoML）。</li></ul><h4 id="5-没有标准化和正则化措施"><a href="#5-没有标准化和正则化措施" class="headerlink" title="5. 没有标准化和正则化措施"></a>5. <strong>没有标准化和正则化措施</strong></h4><ul><li><strong>没有批量归一化（Batch Normalization）</strong>：LeNet没有采用批量归一化，这会导致训练过程中的梯度消失或爆炸问题，训练速度较慢，效果欠佳。</li><li><strong>缺少正则化</strong>：LeNet缺少后来的Dropout、L2正则等防止过拟合的手段，容易在大数据集上过拟合。</li></ul><h4 id="6-无法很好地利用现代硬件的并行计算能力"><a href="#6-无法很好地利用现代硬件的并行计算能力" class="headerlink" title="6. 无法很好地利用现代硬件的并行计算能力"></a>6. <strong>无法很好地利用现代硬件的并行计算能力</strong></h4><ul><li>LeNet在设计时的硬件环境较为有限，没有考虑到现代硬件（如GPU、TPU）的并行计算能力，因此其结构在大型并行计算时的表现不如后来设计的网络高效。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>LeNet的缺点主要体现在模型容量不足、缺乏正则化手段、特征提取能力有限、以及对复杂任务的适应性较差等方面。尽管LeNet在手写数字识别上表现出色，但其结构不适用于处理大规模和复杂的视觉任务。现代卷积神经网络（如AlexNet、VGG、ResNet）在LeNet的基础上，通过增加深度、使用更强的正则化手段和更高效的特征提取方法，克服了这些缺点，推动了深度学习在视觉领域的广泛应用。</p><h1 id="LeNet-的优点："><a href="#LeNet-的优点：" class="headerlink" title="LeNet 的优点："></a>LeNet 的优点：</h1><ol><li><strong>局部连接</strong>：LeNet 引入了卷积操作，将图像中的局部特征映射到更高层次的抽象特征，极大地减少了计算量和参数数量。</li><li><strong>权重共享</strong>：卷积层中的权重共享大大减少了模型的参数，使得网络更加高效，降低了过拟合的风险。</li><li><strong>池化操作</strong>：LeNet 中使用了池化层（如平均池化），进一步减少了特征的尺寸，降低了计算复杂度。</li><li><strong>端到端学习</strong>：LeNet 使得神经网络能够从原始图像像素直接学习特征，而不依赖于手工特征提取，开创了深度学习端到端训练的先河。</li><li><strong>深度结构</strong>：LeNet 通过多个卷积层和池化层的堆叠，能够逐渐提取图像的高层次抽象特征，有效地提高了图像识别的准确度。</li></ol><p>LeNet的卷积核大小和结构设计是基于一些基本的设计原则和当时的计算资源限制来确定的。Yann LeCun在发明LeNet时主要参考了以下几点：</p><h1 id="参数设置原因："><a href="#参数设置原因：" class="headerlink" title="参数设置原因："></a>参数设置原因：</h1><ul><li><strong>小卷积核</strong>：LeNet使用了 (5 \times 5) 的卷积核，这个大小足够捕捉局部图像特征，如边缘和简单的纹理，同时减少了参数数量。</li><li><p><strong>分层提取特征</strong>：通过使用多层卷积，每一层可以提取更复杂的特征，逐渐从低级特征（如边缘）到高级特征（如形状）。</p></li><li><p>LeNet主要用于处理尺寸较小的图像（如手写数字的 (28 \times 28) 灰度图像）。</p></li><li>使用 (5 \times 5) 卷积核而非更大的卷积核可以显著减少计算量，因为较大的卷积核需要更多的参数和更多计算，超出了当时的计算资源。</li><li><p>使用较大的步长或无填充（例如第二层卷积没有填充），让特征图的尺寸逐层减少，有助于压缩信息，同时进一步降低计算量。</p></li><li><p>LeNet选择的参数（如每层的通道数）是为了在保持网络学习能力的前提下尽可能减少计算需求。</p></li><li>第一层卷积输出6个通道，第二层增加到16个通道，这种增加是为了在较深层次中允许模型捕获更多信息。</li><li><p>这个层数和通道数的设计已经足以让模型学习到手写数字的基本模式，而不会因为过多的参数而导致过拟合。</p></li><li><p>LeCun的团队通过反复试验，确定了卷积核大小、池化类型、层数等参数，这在深度学习早期是非常常见的方法。</p></li><li>例如，LeNet使用平均池化（而非后来更常见的最大池化），这在当时是一种合理的选择，因为手写字符的模式简单且稳定。</li></ul><h1 id="结构设计原因："><a href="#结构设计原因：" class="headerlink" title="结构设计原因："></a>结构设计原因：</h1><p>LeNet的结构设计（先使用两个卷积层，然后接三个全连接层）是经过深思熟虑的：</p><h4 id="1-逐步提取特征的层次结构"><a href="#1-逐步提取特征的层次结构" class="headerlink" title="1. 逐步提取特征的层次结构"></a>1. <strong>逐步提取特征的层次结构</strong></h4><ul><li><strong>卷积层的作用</strong>：前两个卷积层的主要作用是提取图像的局部特征，如边缘、纹理和形状。每一层卷积操作能够识别出图像的低层次特征，随着层数的增加，可以逐步形成更高层次的抽象。</li><li><strong>分层特征提取</strong>：第一个卷积层用小的卷积核提取低层特征，如简单的边缘和角；第二个卷积层在第一层提取的特征基础上，通过更多的通道数和卷积核继续捕捉更复杂的模式和结构。</li></ul><h4 id="2-逐步减少空间维度，增加特征维度"><a href="#2-逐步减少空间维度，增加特征维度" class="headerlink" title="2. 逐步减少空间维度，增加特征维度"></a>2. <strong>逐步减少空间维度，增加特征维度</strong></h4><ul><li>在卷积和池化操作的过程中，LeNet通过设计将图像的空间尺寸逐渐缩小，从最初的 (28 \times 28) 到更小的特征图（如 (5 \times 5)）。</li><li>这种空间上的压缩让网络在较少的神经元连接上保留了图像的主要特征，减少了参数数量和计算量，有助于提高效率。</li><li>通过这种设计，卷积层的输出特征图在大小上足够小，后续全连接层可以直接接入而不会因为维度过高而导致参数过多。</li></ul><h4 id="3-全连接层的作用：分类与决策"><a href="#3-全连接层的作用：分类与决策" class="headerlink" title="3. 全连接层的作用：分类与决策"></a>3. <strong>全连接层的作用：分类与决策</strong></h4><ul><li><strong>转变为分类任务</strong>：卷积层提取了有意义的特征后，全连接层负责将这些特征用于分类。</li><li>全连接层的三个层次逐渐缩小尺寸，从120到84再到10，通过这种层级结构，网络可以从高维特征表示转化为类别分数。</li><li><strong>逐步抽象特征</strong>：全连接层可以进一步组合卷积层提取的特征，学习不同特征组合的权重关系，形成更抽象的表示，提升模型对复杂模式的识别能力。</li></ul><h4 id="4-设计的平衡：计算量与识别能力"><a href="#4-设计的平衡：计算量与识别能力" class="headerlink" title="4. 设计的平衡：计算量与识别能力"></a>4. <strong>设计的平衡：计算量与识别能力</strong></h4><ul><li><strong>减少参数量</strong>：在卷积层减少图像空间尺寸后，再接全连接层，既保留了重要的图像特征，又避免了巨大的参数量。</li><li><strong>提升识别能力</strong>：全连接层在特征图的低维表示上进行分类，保留了卷积层提取的信息，并将其有效转化为分类结果。</li></ul>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积与感受野的物理意义</title>
    <link href="/2024/11/05/20241105_%E5%8D%B7%E7%A7%AF%E4%B8%8E%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E7%89%A9%E7%90%86%E6%84%8F%E4%B9%89/"/>
    <url>/2024/11/05/20241105_%E5%8D%B7%E7%A7%AF%E4%B8%8E%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E7%89%A9%E7%90%86%E6%84%8F%E4%B9%89/</url>
    
    <content type="html"><![CDATA[<p>卷积操作在数学和信号处理中的物理意义可以从几个方面来理解，尤其是在图像处理、信号滤波和特征提取等领域。以下是卷积的物理意义的几个关键方面：</p><h3 id="1-滤波器作用"><a href="#1-滤波器作用" class="headerlink" title="1. 滤波器作用"></a>1. 滤波器作用</h3><p>在信号处理和图像处理中，卷积操作的一个重要作用是应用滤波器（或卷积核）来改变信号或图像的特性。这可以类比于物理中的滤波器，例如声波滤波器或光学滤镜。通过卷积，我们可以实现以下功能：</p><ul><li><strong>平滑</strong>：去除噪声，平滑图像或信号。</li><li><strong>边缘检测</strong>：通过检测信号或图像中的急剧变化，找到边缘。</li><li><strong>模糊处理</strong>：使用特定的核模糊图像，减少细节。</li></ul><h3 id="2-局部响应"><a href="#2-局部响应" class="headerlink" title="2. 局部响应"></a>2. 局部响应</h3><p>卷积操作的一个重要特性是它通过局部感知来提取特征。卷积核通过在输入信号或图像的每个位置上进行局部加权求和，捕捉到局部的变化和模式。这种局部响应的特性使得卷积可以很好地反映物理世界中的许多现象，例如：</p><ul><li><strong>光的传播</strong>：在光学中，光的强度在不同的空间位置可能是不同的。卷积可以表示光在不同介质中的传播和相互作用。</li><li><strong>声波传播</strong>：在声学中，声波的传播和反射可以通过卷积描述。</li></ul><h3 id="3-重叠与叠加"><a href="#3-重叠与叠加" class="headerlink" title="3. 重叠与叠加"></a>3. 重叠与叠加</h3><p>卷积与物理学中的叠加原理密切相关。根据叠加原理，系统的总响应可以看作是单个输入的响应的总和。卷积操作实际上是在对输入信号进行加权重叠，这与物理中的波动、力学系统中的响应等情况非常相似。</p><h3 id="4-物理模型"><a href="#4-物理模型" class="headerlink" title="4. 物理模型"></a>4. 物理模型</h3><p>在某些物理模型中，卷积可以用来描述系统的输出如何依赖于输入和系统的特性。例如，在电路理论中，输入信号通过一个线性时不变系统时，其输出可以用输入信号与系统的冲激响应（impulse response）进行卷积来表示。这种模型反映了实际物理系统对输入信号的反应特性。</p><h3 id="5-变换和信号分析"><a href="#5-变换和信号分析" class="headerlink" title="5. 变换和信号分析"></a>5. 变换和信号分析</h3><p>卷积还可以与傅里叶变换等频域分析工具结合使用，帮助我们理解信号的频率特性。在物理学中，很多现象（如振动、波动等）可以通过频域进行分析，卷积在此过程中起着至关重要的作用。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>卷积操作在物理意义上涉及滤波、局部响应、重叠与叠加等概念，使得它在信号处理、图像分析和物理建模中都具有广泛的应用。通过卷积，我们能够有效地捕捉和分析物理系统的特征和行为，为我们理解复杂现象提供了强有力的工具。</p><p>感受野的物理意义主要体现在它对输入数据中局部特征的影响和神经元之间信息传递的机制。下面将详细解释感受野的物理意义及其在卷积神经网络中的作用。</p><h3 id="1-局部特征提取"><a href="#1-局部特征提取" class="headerlink" title="1. 局部特征提取"></a>1. 局部特征提取</h3><p>感受野的大小决定了每个神经元能够感知到的输入区域。小的感受野意味着神经元只能看到输入数据中的局部特征，而较大的感受野则能够整合更多信息。例如，在图像处理中：</p><ul><li><strong>小感受野</strong>（如 (3 \times 3)）的神经元可以捕捉边缘、纹理等局部特征。</li><li><strong>大感受野</strong>（如 (7 \times 7) 或更大）可以整合多个局部特征，帮助识别更复杂的形状或对象。</li></ul><p>这种特征提取的过程与人类视觉系统相似，人眼能够通过不同区域的感知，逐渐形成对整体场景的理解。</p><h3 id="2-信息传递机制"><a href="#2-信息传递机制" class="headerlink" title="2. 信息传递机制"></a>2. 信息传递机制</h3><p>感受野也反映了神经元之间信息传递的方式。在深度学习模型中，低层的神经元通常关注局部特征，而高层的神经元则结合来自多个低层神经元的信息。这种结构设计使得网络能够从简单到复杂逐层构建特征表示，类似于人脑处理信息的方式：</p><ul><li><strong>低层</strong>：感知局部信息（如边缘、角落）。</li><li><strong>中层</strong>：组合局部信息，识别更复杂的形状或模式。</li><li><strong>高层</strong>：综合多个特征，形成对整体对象的理解。</li></ul><h3 id="3-影响模型性能"><a href="#3-影响模型性能" class="headerlink" title="3. 影响模型性能"></a>3. 影响模型性能</h3><p>感受野的大小直接影响到模型的性能和适用性：</p><ul><li><strong>特征丰富性</strong>：如果感受野过小，模型可能无法捕捉到全局信息，导致对复杂数据的理解不足。</li><li><strong>泛化能力</strong>：适当的感受野可以帮助模型在训练和测试时都能更好地泛化，从而提高模型的准确性和鲁棒性。</li></ul><h3 id="4-感受野与多尺度特征"><a href="#4-感受野与多尺度特征" class="headerlink" title="4. 感受野与多尺度特征"></a>4. 感受野与多尺度特征</h3><p>在许多计算机视觉任务中，物体可能以不同的尺度出现在图像中。通过设计具有不同感受野的层（例如，使用不同大小的卷积核），网络能够同时提取多尺度特征。这对于目标检测、分割等任务至关重要，因为物体可能具有不同的大小和形状。</p><h3 id="5-物理意义的类比"><a href="#5-物理意义的类比" class="headerlink" title="5. 物理意义的类比"></a>5. 物理意义的类比</h3><p>感受野的概念可以类比于生物学中的感官系统。例如，视网膜上的每个感光细胞（视杆和视锥细胞）只对一个小区域的光线敏感，而大脑通过整合来自不同感光细胞的信息形成对图像的理解。感受野在神经网络中起到了类似的作用，使得网络能够有效处理和理解输入数据。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>感受野的物理意义体现在其对特征提取、信息传递和模型性能的影响上。它不仅决定了神经元能够感知的输入范围，还影响了网络对复杂数据的理解能力，类似于生物视觉系统的工作原理。理解感受野的物理意义对于设计有效的深度学习模型至关重要。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>根据烈度图生成危险概率分布图</title>
    <link href="/2024/11/05/20241105_%E7%94%9F%E6%88%90%E5%8D%B1%E9%99%A9%E6%A6%82%E7%8E%87%E5%9B%BE/"/>
    <url>/2024/11/05/20241105_%E7%94%9F%E6%88%90%E5%8D%B1%E9%99%A9%E6%A6%82%E7%8E%87%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> rasterio<br><span class="hljs-keyword">from</span> rasterio.enums <span class="hljs-keyword">import</span> Resampling<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib<br><br><span class="hljs-comment"># 定义文件路径</span><br>intensity_file = <span class="hljs-string">&#x27;intensity.tif&#x27;</span><br>base_file = <span class="hljs-string">&#x27;base.tif&#x27;</span><br>output_file = <span class="hljs-string">&#x27;risk_probability.tif&#x27;</span><br><br><span class="hljs-comment"># 风险概率计算函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_risk_probability</span>(<span class="hljs-params">intensity, base</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(<span class="hljs-number">0</span> - <span class="hljs-number">0.00250165038535077</span> * np.exp(<span class="hljs-number">0.6931</span> * intensity) - base))<br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-comment"># 读取基础数据</span><br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(base_file) <span class="hljs-keyword">as</span> src:<br>        base_data = src.read(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 读取第一层数据</span><br>        base_meta = src.meta<br><br>    <span class="hljs-comment"># 读取并重采样强度数据</span><br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(intensity_file) <span class="hljs-keyword">as</span> src:<br>        intensity_data_resampled = src.read(<br>            out_shape=(<span class="hljs-number">1</span>, base_data.shape[<span class="hljs-number">0</span>], base_data.shape[<span class="hljs-number">1</span>]),<br>            resampling=Resampling.bilinear<br>        )[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 选择第一层数据</span><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Base data shape:&quot;</span>, base_data.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Intensity data shape (after resampling):&quot;</span>, intensity_data_resampled.shape)<br><br>    <span class="hljs-comment"># 计算风险概率</span><br>    risk_probability = calculate_risk_probability(intensity_data_resampled, base_data)<br><br>    <span class="hljs-comment"># 处理无效值</span><br>    risk_probability[np.isinf(risk_probability)] = <span class="hljs-number">0</span><br>    risk_probability = np.clip(risk_probability, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 分级处理</span><br>    risk_classification = np.zeros_like(risk_probability)<br>    risk_classification[risk_probability &gt;= <span class="hljs-number">0.1</span>] = <span class="hljs-number">4</span>  <span class="hljs-comment"># 高风险</span><br>    risk_classification[(risk_probability &gt;= <span class="hljs-number">0.01</span>) &amp; (risk_probability &lt; <span class="hljs-number">0.1</span>)] = <span class="hljs-number">3</span>  <span class="hljs-comment"># 中高风险</span><br>    risk_classification[(risk_probability &gt;= <span class="hljs-number">0.001</span>) &amp; (risk_probability &lt; <span class="hljs-number">0.01</span>)] = <span class="hljs-number">2</span>  <span class="hljs-comment"># 中风险</span><br>    risk_classification[(risk_probability &gt;= <span class="hljs-number">0.0001</span>) &amp; (risk_probability &lt; <span class="hljs-number">0.001</span>)] = <span class="hljs-number">1</span>  <span class="hljs-comment"># 中低风险</span><br>    risk_classification[risk_probability &lt; <span class="hljs-number">0.0001</span>] = <span class="hljs-number">0</span>  <span class="hljs-comment"># 低风险</span><br><br>    <span class="hljs-comment"># 可视化风险概率</span><br>    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))<br>    cmap = matplotlib.colormaps[<span class="hljs-string">&#x27;RdYlBu_r&#x27;</span>]  <span class="hljs-comment"># 使用反转的颜色映射</span><br>    plt.imshow(risk_classification, cmap=cmap, interpolation=<span class="hljs-string">&#x27;nearest&#x27;</span>, extent=(base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>][<span class="hljs-number">2</span>], <br>                                                                             base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>][<span class="hljs-number">2</span>] + base_meta[<span class="hljs-string">&#x27;width&#x27;</span>] * base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>][<span class="hljs-number">0</span>], <br>                                                                             base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>][<span class="hljs-number">5</span>] + base_meta[<span class="hljs-string">&#x27;height&#x27;</span>] * base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>][<span class="hljs-number">4</span>], <br>                                                                             base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>][<span class="hljs-number">5</span>]))<br><br>    <span class="hljs-comment"># 添加经纬度刻度</span><br>    plt.colorbar(ticks=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], label=<span class="hljs-string">&#x27;风险等级&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;次生地质灾害风险概率分级图&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;经度&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;纬度&#x27;</span>)<br>    plt.axis(<span class="hljs-string">&#x27;on&#x27;</span>)  <span class="hljs-comment"># 显示坐标轴</span><br>    plt.show()<br><br>    <span class="hljs-comment"># 将风险概率写入新的 TIFF 文件</span><br>    risk_probability = (risk_probability * <span class="hljs-number">255</span>).astype(np.uint8)  <span class="hljs-comment"># 归一化到 0-255</span><br>    <span class="hljs-keyword">with</span> rasterio.<span class="hljs-built_in">open</span>(output_file, <span class="hljs-string">&#x27;w&#x27;</span>, driver=<span class="hljs-string">&#x27;GTiff&#x27;</span>,<br>                       height=risk_probability.shape[<span class="hljs-number">0</span>],<br>                       width=risk_probability.shape[<span class="hljs-number">1</span>],<br>                       count=<span class="hljs-number">1</span>,<br>                       dtype=<span class="hljs-string">&#x27;uint8&#x27;</span>,<br>                       crs=base_meta[<span class="hljs-string">&#x27;crs&#x27;</span>],<br>                       transform=base_meta[<span class="hljs-string">&#x27;transform&#x27;</span>]) <span class="hljs-keyword">as</span> dst:<br>        dst.write(risk_probability, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;风险概率地图已保存至 <span class="hljs-subst">&#123;output_file&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;发生错误: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">base_meta<br>以下是对从 GeoTIFF 文件中提取的属性的解释：g<br><span class="hljs-string">&#x27;driver&#x27;</span>: <span class="hljs-string">&#x27;GTiff&#x27;</span>:<br>解释：这表明文件格式是 GeoTIFF（GTiff 是 GeoTIFF 的缩写）。GeoTIFF 是一种广泛使用的地理空间栅格数据格式，它扩展了 TIFF（标签图像文件格式）以支持地理坐标系统信息。<br><span class="hljs-string">&#x27;dtype&#x27;</span>: <span class="hljs-string">&#x27;float32&#x27;</span>:<br>解释：这表示栅格数据中的每个像素值的数据类型是 <span class="hljs-number">32</span> 位浮点数。这意味着每个像素可以存储一个浮点数值，其范围大约在 -<span class="hljs-number">3.4e+38</span> 到 <span class="hljs-number">3.4e+38</span> 之间。<br><span class="hljs-string">&#x27;nodata&#x27;</span>: -<span class="hljs-number">3.4028230607370965e+38</span>:<br>解释：这是定义的无数据值，用于表示栅格数据中缺失或无效的像素。在这个例子中，nodata 值设置为一个非常小的负数，这是 float32 类型所能表示的最小数值之一。<br><span class="hljs-string">&#x27;width&#x27;</span>: <span class="hljs-number">1822</span>, <span class="hljs-string">&#x27;height&#x27;</span>: <span class="hljs-number">588</span>:<br>解释：这些属性表示栅格数据的尺寸。width 是图像的宽度（以像素为单位），而 height 是图像的高度（以像素为单位）。所以这个 GeoTIFF 文件包含一个 <span class="hljs-number">1822</span> 像素宽和 <span class="hljs-number">588</span> 像素高的图像。<br><span class="hljs-string">&#x27;count&#x27;</span>: <span class="hljs-number">1</span>:<br>解释：这表示栅格数据集包含一个波段（band）。如果是彩色图像，count 可能是 <span class="hljs-number">3</span>（红、绿、蓝波段）或者更多。<br><span class="hljs-string">&#x27;crs&#x27;</span>: CRS.from_wkt(<span class="hljs-string">&#x27;...&#x27;</span>):<br>解释：这是栅格数据的坐标参考系统（CRS）。CRS 定义了数据在地球上的位置和如何将像素坐标转换为地理坐标。这里的 WKT（Well-Known Text）字符串定义了一个地理坐标系 WGS <span class="hljs-number">84</span>，这是全球定位系统（GPS）使用的坐标系。<br><span class="hljs-string">&#x27;transform&#x27;</span>: Affine(<span class="hljs-number">0.008333333300000006</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">89.82031276588475</span>, <span class="hljs-number">0.0</span>, -<span class="hljs-number">0.0083333333</span>, <span class="hljs-number">32.3978756035457</span>):<br>解释：这是一个仿射变换矩阵，用于将像素坐标转换为地理坐标。这个 Affine 对象包含六个参数，分别是：<br>a (x-scale): <span class="hljs-number">0.008333333300000006</span>，表示像素在 x 方向上的大小（经度方向上的分辨率）。<br>b (x-skew): <span class="hljs-number">0.0</span>，表示像素在 x 方向上的倾斜度（通常为 <span class="hljs-number">0</span>）。<br>c (x-translate): <span class="hljs-number">89.82031276588475</span>，表示图像左上角像素的 x 坐标（经度）。<br>d (y-skew): <span class="hljs-number">0.0</span>，表示像素在 y 方向上的倾斜度（通常为 <span class="hljs-number">0</span>）。<br>e (y-scale): -<span class="hljs-number">0.0083333333</span>，表示像素在 y 方向上的大小（纬度方向上的分辨率，通常是负值）。<br>f (y-translate): <span class="hljs-number">32.3978756035457</span>，表示图像左上角像素的 y 坐标（纬度）。<br>这个仿射变换矩阵用于计算给定像素坐标 (x, y) 的地理坐标 (longitude, latitude)。<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>绘图</category>
      
      <category>pytohon</category>
      
    </categories>
    
    
    <tags>
      
      <tag>绘图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自定义层实现</title>
    <link href="/2024/11/05/20241105_%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E4%BE%8B%E5%AD%90/"/>
    <url>/2024/11/05/20241105_%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E4%BE%8B%E5%AD%90/</url>
    
    <content type="html"><![CDATA[<p>要设计一个接受输入并计算张量降维的层，返回值为 </p><script type="math/tex; mode=display">y_k = \sum_{i,j} W_{ijk} x_i x_j</script><p> ，我们需要实现一个自定义的 PyTorch 模块。这个层将接收一个输入张量 ( X )（通常是一维向量），并通过权重张量 ( W ) 计算输出。</p><h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><ol><li><strong>定义自定义层</strong>：该层将包含权重张量 ( W )。</li><li><strong>计算输出</strong>：在 <code>forward</code> 方法中，计算每个 ( y_k ) 的值。</li><li><strong>支持批处理</strong>：确保层可以处理多个输入样本。</li></ol><p>以下是具体的实现代码：</p><h3 id="自定义层实现"><a href="#自定义层实现" class="headerlink" title="自定义层实现"></a>自定义层实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TensorReductionLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, output_dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 初始化权重 W，大小为 (output_dim, input_dim, input_dim)</span><br>        self.W = nn.Parameter(torch.randn(output_dim, input_dim, input_dim) * <span class="hljs-number">0.01</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># X 的形状为 (batch_size, input_dim)</span><br>        <span class="hljs-comment"># W 的形状为 (output_dim, input_dim, input_dim)</span><br>        <br>        <span class="hljs-comment"># 计算 x_i * x_j 的外积</span><br>        outer_product = torch.matmul(X.unsqueeze(<span class="hljs-number">2</span>), X.unsqueeze(<span class="hljs-number">1</span>))  <span class="hljs-comment"># 形状为 (batch_size, input_dim, input_dim)</span><br>        <br>        <span class="hljs-comment"># 对每个输出维度计算加权求和</span><br>        <span class="hljs-comment"># y_k 的形状为 (batch_size, output_dim)</span><br>        y_k = torch.einsum(<span class="hljs-string">&#x27;bxy,zyx-&gt;bz&#x27;</span>, outer_product, self.W)  <span class="hljs-comment"># batch_size, output_dim</span><br>        <br>        <span class="hljs-keyword">return</span> y_k<br><br><span class="hljs-comment"># 示例使用</span><br>input_dim = <span class="hljs-number">5</span>   <span class="hljs-comment"># 输入特征的维度</span><br>output_dim = <span class="hljs-number">3</span>  <span class="hljs-comment"># 输出特征的维度</span><br>layer = TensorReductionLayer(input_dim, output_dim)<br><br><span class="hljs-comment"># 创建一个随机输入张量，大小为 (2, 5)</span><br>input_tensor = torch.rand(<span class="hljs-number">2</span>, input_dim)<br><br><span class="hljs-comment"># 通过层进行前向传播</span><br>output_tensor = layer(input_tensor)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;输出张量:\n&quot;</span>, output_tensor)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;输出张量的形状:&quot;</span>, output_tensor.shape)  <span class="hljs-comment"># 应该是 (2, output_dim)</span><br></code></pre></td></tr></table></figure><h3 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h3><ol><li><p><strong>权重 ( W )</strong>：</p><ul><li>在 <code>__init__</code> 方法中，使用 <code>nn.Parameter</code> 来定义权重张量 ( W )，其形状为 ( (output_dim, input_dim, input_dim) )。这使得每个输出维度都可以根据输入特征的外积进行加权。</li></ul></li><li><p><strong>前向传播</strong>：</p><ul><li>在 <code>forward</code> 方法中，通过 <code>X.unsqueeze(2)</code> 和 <code>X.unsqueeze(1)</code> 计算输入的外积，得到形状为 ( (batch_size, input_dim, input_dim) ) 的张量。</li><li>使用 <code>torch.einsum</code> 进行加权求和，计算每个 ( y_k )，其形状为 ( (batch_size, output_dim) )。</li></ul></li></ol><h3 id="预期结果"><a href="#预期结果" class="headerlink" title="预期结果"></a>预期结果</h3><p>运行示例代码后，你应该能够看到输出张量和其形状的信息：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">输出张量:<br> <span class="hljs-built_in">tensor</span>(<span class="hljs-selector-attr">[...]</span>, grad_fn=&lt;SumBackward0&gt;)<br>输出张量的形状: torch<span class="hljs-selector-class">.Size</span>(<span class="hljs-selector-attr">[2, output_dim]</span>)<br></code></pre></td></tr></table></figure><p>这里的输出张量包含了每个输入样本的降维结果，形状为 ( (2, 3) )（假设 <code>output_dim</code> 设置为3）。</p><p>要理解 <code>outer_product = torch.matmul(X.unsqueeze(2), X.unsqueeze(1))</code>，我们可以通过一个数学示例来说明如何使用这个操作计算外积。外积是将两个向量结合起来生成一个矩阵。</p><h3 id="设定示例"><a href="#设定示例" class="headerlink" title="设定示例"></a>设定示例</h3><p>假设我们有一个输入张量 ( X )，其形状为 ( (2, 3) )，表示有 2 个样本，每个样本有 3 个特征。我们可以设定如下：</p><script type="math/tex; mode=display">X = \begin{bmatrix}1 & 2 & 3 \\4 & 5 & 6\end{bmatrix}</script><h3 id="使用-unsqueeze-操作"><a href="#使用-unsqueeze-操作" class="headerlink" title="使用 unsqueeze 操作"></a>使用 <code>unsqueeze</code> 操作</h3><p>首先，使用 <code>X.unsqueeze(2)</code> 和 <code>X.unsqueeze(1)</code>：</p><ul><li><strong><code>X.unsqueeze(2)</code></strong>：在第三维添加一个新维度。结果将变为形状为 ( (2, 3, 1) ) 的张量。</li></ul><script type="math/tex; mode=display">X.unsqueeze(2) = \begin{bmatrix}\begin{bmatrix}1 \\2 \\3\end{bmatrix}\end{bmatrix}\text{ 和 }\begin{bmatrix}\begin{bmatrix}4 \\5 \\6\end{bmatrix}\end{bmatrix}</script><ul><li><strong><code>X.unsqueeze(1)</code></strong>：在第二维添加一个新维度。结果将变为形状为 ( (2, 1, 3) ) 的张量。</li></ul><script type="math/tex; mode=display">X.unsqueeze(1) = \begin{bmatrix}\begin{bmatrix}1 & 2 & 3\end{bmatrix}\end{bmatrix}\text{ 和 }\begin{bmatrix}\begin{bmatrix}4 & 5 & 6\end{bmatrix}\end{bmatrix}</script><h3 id="计算外积"><a href="#计算外积" class="headerlink" title="计算外积"></a>计算外积</h3><p>使用 <code>torch.matmul</code> 进行矩阵乘法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>X = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br>outer_product = torch.matmul(X.unsqueeze(<span class="hljs-number">2</span>), X.unsqueeze(<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><ul><li><strong>外积的结果</strong>：此操作会将 ( X.unsqueeze(2) ) 和 ( X.unsqueeze(1) ) 进行矩阵乘法，从而生成一个形状为 ( (2, 3, 3) ) 的张量。</li></ul><script type="math/tex; mode=display">\text{outer_product} = \begin{bmatrix}\begin{bmatrix}1 \times 1 & 1 \times 2 & 1 \times 3 \\2 \times 1 & 2 \times 2 & 2 \times 3 \\3 \times 1 & 3 \times 2 & 3 \times 3\end{bmatrix} & \begin{bmatrix}4 \times 1 & 4 \times 2 & 4 \times 3 \\5 \times 1 & 5 \times 2 & 5 \times 3 \\6 \times 1 & 6 \times 2 & 6 \times 3\end{bmatrix}\end{bmatrix}</script><p>计算结果为：</p><script type="math/tex; mode=display">\text{outer_product} = \begin{bmatrix}\begin{bmatrix}1 & 2 & 3 \\2 & 4 & 6 \\3 & 6 & 9\end{bmatrix} & \begin{bmatrix}4 & 8 & 12 \\5 & 10 & 15 \\6 & 12 & 18\end{bmatrix}\end{bmatrix}</script><h3 id="结果解释"><a href="#结果解释" class="headerlink" title="结果解释"></a>结果解释</h3><ul><li>外积的每个切片（第一个维度的每个样本）将生成一个 ( 3 \times 3 ) 的矩阵，其中的每个元素 ( (i,j) ) 是 ( x_i ) 和 ( x_j ) 的乘积。</li><li>例如，对于第一个样本：</li></ul><script type="math/tex; mode=display">\begin{bmatrix}1 & 2 & 3 \\2 & 4 & 6 \\3 & 6 & 9\end{bmatrix}</script><p>表示的就是第一个样本特征的外积。</p><p>对于第二个样本：</p><script type="math/tex; mode=display">\begin{bmatrix}4 & 8 & 12 \\5 & 10 & 15 \\6 & 12 & 18\end{bmatrix}</script><p>表示的就是第二个样本特征的外积。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过 <code>unsqueeze</code> 操作，我们将原始向量转化为适合进行外积计算的格式。<code>torch.matmul</code> 将两个张量相乘，从而得到外积结果，生成的张量的形状是 ( (2, 3, 3) )，其中包含了每个样本的外积矩阵。如果你有任何进一步的问题或需要更多例子，请随时告诉我！</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三层网络模型梯度求解</title>
    <link href="/2024/11/04/20241104_%E4%B8%89%E5%B1%82%E6%A8%A1%E5%9E%8B%E6%A2%AF%E5%BA%A6%E6%B1%82%E8%A7%A3/"/>
    <url>/2024/11/04/20241104_%E4%B8%89%E5%B1%82%E6%A8%A1%E5%9E%8B%E6%A2%AF%E5%BA%A6%E6%B1%82%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>构建一个简单的三层神经网络模型，并详细分析每一层的梯度计算过程。</p><p>假设这个模型由以下三层构成：</p><ol><li>输入层：大小为 2</li><li>隐藏层：大小为 3，激活函数为 ReLU</li><li>输出层：大小为 1</li></ol><p>每一层的权重和偏置参数如下：</p><ul><li>第一层：权重 ( W_1 ) 和偏置 ( b_1 )</li><li>第二层：权重 ( W_2 ) 和偏置 ( b_2 )</li><li>输出层：权重 ( W_3 ) 和偏置 ( b_3 )</li></ul><h3 id="1-先建立模型并计算前向传播"><a href="#1-先建立模型并计算前向传播" class="headerlink" title="1. 先建立模型并计算前向传播"></a>1. 先建立模型并计算前向传播</h3><p>我们将输入数据设为 <code>x</code>，标签设为 <code>y_true</code>。模型的前向传播计算过程如下：</p><script type="math/tex; mode=display">z_1 = x \cdot W_1 + b_1</script><script type="math/tex; mode=display">a_1 = \text{ReLU}(z_1)</script><script type="math/tex; mode=display">z_2 = a_1 \cdot W_2 + b_2</script><script type="math/tex; mode=display">a_2 = \text{ReLU}(z_2)</script><script type="math/tex; mode=display">y_{\text{pred}} = a_2 \cdot W_3 + b_3</script><p>损失函数使用均方误差（MSE）：</p><script type="math/tex; mode=display">\text{loss} = \frac{1}{N} \sum (y_{\text{pred}} - y_{\text{true}})^2</script><h3 id="2-用-PyTorch-实现这个三层模型"><a href="#2-用-PyTorch-实现这个三层模型" class="headerlink" title="2. 用 PyTorch 实现这个三层模型"></a>2. 用 PyTorch 实现这个三层模型</h3><p>以下是代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-comment"># 初始化输入和标签</span><br>x = torch.tensor([[<span class="hljs-number">0.5</span>, -<span class="hljs-number">1.5</span>]], requires_grad=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 输入为 2 维</span><br>y_true = torch.tensor([[<span class="hljs-number">1.0</span>]], requires_grad=<span class="hljs-literal">False</span>)   <span class="hljs-comment"># 标签为 1 维</span><br><br><span class="hljs-comment"># 初始化模型参数</span><br>W1 = torch.randn((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 第一层的权重 (2x3)</span><br>b1 = torch.randn((<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 第一层的偏置 (1x3)</span><br><br>W2 = torch.randn((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 第二层的权重 (3x3)</span><br>b2 = torch.randn((<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 第二层的偏置 (1x3)</span><br><br>W3 = torch.randn((<span class="hljs-number">3</span>, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 输出层的权重 (3x1)</span><br>b3 = torch.randn((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 输出层的偏置 (1x1)</span><br><br><span class="hljs-comment"># 前向传播</span><br>z1 = x @ W1 + b1<br>a1 = F.relu(z1)<br>z2 = a1 @ W2 + b2<br>a2 = F.relu(z2)<br>y_pred = a2 @ W3 + b3<br><br><span class="hljs-comment"># 计算损失</span><br>loss = torch.mean((y_pred - y_true) ** <span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 反向传播</span><br>loss.backward()<br><br><span class="hljs-comment"># 输出每一层的梯度</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;W1 的梯度：&quot;</span>, W1.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;b1 的梯度：&quot;</span>, b1.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;W2 的梯度：&quot;</span>, W2.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;b2 的梯度：&quot;</span>, b2.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;W3 的梯度：&quot;</span>, W3.grad)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;b3 的梯度：&quot;</span>, b3.grad)<br></code></pre></td></tr></table></figure><h3 id="3-梯度计算分析"><a href="#3-梯度计算分析" class="headerlink" title="3. 梯度计算分析"></a>3. 梯度计算分析</h3><p>现在，我们分析每一层参数梯度的计算过程：</p><h4 id="第一层（输入到隐藏层）"><a href="#第一层（输入到隐藏层）" class="headerlink" title="第一层（输入到隐藏层）"></a>第一层（输入到隐藏层）</h4><ol><li>对于第一层的权重  <script type="math/tex; mode=display">W_1</script><script type="math/tex; mode=display">，其梯度为</script><script type="math/tex; mode=display">\frac{\partial \text{loss}}{\partial W_1}</script></li></ol><script type="math/tex; mode=display">   。   - 通过链式法则，我们可以将梯度分解为：</script><script type="math/tex; mode=display">\frac{\partial \text{loss}}{\partial W_1} = \frac{\partial \text{loss}}{\partial y_{\text{pred}}} \cdot \frac{\partial y_{\text{pred}}}{\partial a_2} \cdot \frac{\partial a_2}{\partial z_2} \cdot \frac{\partial z_2}{\partial a_1} \cdot \frac{\partial a_1}{\partial z_1} \cdot \frac{\partial z_1}{\partial W_1}</script><ul><li>PyTorch 自动计算并累积这些链式法则中的每个项的梯度，最终得到 <code>W1.grad</code>。</li></ul><ol><li>对于第一层的偏置 ( b_1 )，其梯度为 (\frac{\partial \text{loss}}{\partial b_1})，计算过程与 ( W_1 ) 类似，但没有权重的部分。</li></ol><h4 id="第二层（隐藏层到隐藏层）"><a href="#第二层（隐藏层到隐藏层）" class="headerlink" title="第二层（隐藏层到隐藏层）"></a>第二层（隐藏层到隐藏层）</h4><ol><li><p>对于第二层的权重 ( W_2 )，其梯度为 (\frac{\partial \text{loss}}{\partial W_2})。</p><ul><li>同样通过链式法则分解：(\frac{\partial \text{loss}}{\partial W_2} = \frac{\partial \text{loss}}{\partial y_{\text{pred}}} \cdot \frac{\partial y_{\text{pred}}}{\partial a_2} \cdot \frac{\partial a_2}{\partial z_2} \cdot \frac{\partial z_2}{\partial W_2})。</li><li>PyTorch 自动追踪这些操作并计算 <code>W2.grad</code>。</li></ul></li><li><p>对于第二层的偏置 ( b_2 )，其梯度为 (\frac{\partial \text{loss}}{\partial b_2})。</p></li></ol><h4 id="输出层（隐藏层到输出层）"><a href="#输出层（隐藏层到输出层）" class="headerlink" title="输出层（隐藏层到输出层）"></a>输出层（隐藏层到输出层）</h4><ol><li><p>对于输出层的权重 ( W_3 )，其梯度为 (\frac{\partial \text{loss}}{\partial W_3})。</p><ul><li>这一步相对简单，因为它直接涉及到最终的输出：(\frac{\partial \text{loss}}{\partial W_3} = \frac{\partial \text{loss}}{\partial y_{\text{pred}}} \cdot \frac{\partial y_{\text{pred}}}{\partial W_3})。</li><li>PyTorch 在反向传播中计算出 <code>W3.grad</code>。</li></ul></li><li><p>对于输出层的偏置 ( b_3 )，其梯度为 (\frac{\partial \text{loss}}{\partial b_3})。</p></li></ol><p>通过这三层的链式求导法则，PyTorch 能够自动计算每层权重和偏置的梯度并存储在 <code>.grad</code> 中，用于之后的参数更新。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>正则化的作用</title>
    <link href="/2024/10/30/20241030_%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E4%BD%9C%E7%94%A8/"/>
    <url>/2024/10/30/20241030_%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E4%BD%9C%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>进行正则化惩罚后，权重减少的原因主要与优化算法的机制有关。下面我将详细说明这一过程，以及在学习过程中的体现。</p><h3 id="正则化的作用"><a href="#正则化的作用" class="headerlink" title="正则化的作用"></a>正则化的作用</h3><p>正则化通过在损失函数中增加惩罚项，迫使学习算法在最小化损失时，不仅要考虑训练误差（例如均方误差），还要考虑权重的大小。这种机制可以用来防止过拟合，使得模型的泛化能力更强。</p><h3 id="优化过程中的体现"><a href="#优化过程中的体现" class="headerlink" title="优化过程中的体现"></a>优化过程中的体现</h3><ol><li><p><strong>损失函数的构成</strong>：</p><ul><li>正则化后的损失函数通常是这样的形式：<br>[<br>L = L_{原始} + \lambda R(w)<br>]<br>其中，( L_{原始} ) 是原始损失，( R(w) ) 是正则化项（L1或L2），而 ( \lambda ) 是正则化强度的超参数。</li></ul></li><li><p><strong>学习算法</strong>：</p><ul><li>常见的优化算法如梯度下降法，旨在通过更新权重以最小化损失函数。在每次迭代中，算法计算当前权重下的梯度，并根据这个梯度更新权重。</li></ul></li><li><p><strong>惩罚项的影响</strong>：</p><ul><li>当引入正则化项后，损失函数的梯度不仅包含原始损失的梯度，还包含惩罚项的梯度。以L2正则化为例，其梯度形式为：<br>[<br>\nabla L = \nabla L_{原始} + 2\lambda w<br>]<br>这里，( 2\lambda w ) 是惩罚项的梯度，它会影响每个权重的更新方向和幅度。</li></ul></li><li><p><strong>权重更新</strong>：</p><ul><li><p>在每次更新权重时，使用如下公式：<br>[<br>w’ = w - \eta \nabla L<br>]<br>其中 ( \eta ) 是学习率，( w’ ) 是更新后的权重。</p></li><li><p>结合上述的梯度表达式，可以看到，惩罚项的存在将导致更新后的权重减少：<br>[<br>w’ = w - \eta (\nabla L_{原始} + 2\lambda w)<br>]</p><ul><li>这个公式说明，权重的更新不仅要考虑原始损失的梯度，还会受到惩罚项的影响，使得权重会向零的方向调整。</li></ul></li></ul></li></ol><h3 id="举个具体的例子"><a href="#举个具体的例子" class="headerlink" title="举个具体的例子"></a>举个具体的例子</h3><p>假设我们有一个简单的线性回归模型，当前权重为 ( w = 4 )，并且原始损失的梯度为 ( \nabla L_{原始} = -1 )（负号表示误差的减小方向）。我们选择的学习率 ( \eta = 0.1 ) 和正则化强度 ( \lambda = 0.5 )。</p><ol><li><p><strong>计算惩罚项的梯度</strong>：<br>[<br>\nabla R(w) = 2 \lambda w = 2 \times 0.5 \times 4 = 4<br>]</p></li><li><p><strong>计算总梯度</strong>：<br>[<br>\nabla L = -1 + 4 = 3<br>]</p></li><li><p><strong>更新权重</strong>：<br>[<br>w’ = w - \eta \nabla L = 4 - 0.1 \times 3 = 4 - 0.3 = 3.7<br>]</p></li></ol><p>通过这个过程，我们可以看到，正则化引入了一个惩罚项，使得权重在更新时减少了。这种机制促使模型不会过度依赖某些特征，从而降低过拟合的风险。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li><strong>正则化通过在损失函数中引入惩罚项</strong>，使得优化过程不仅关注减少训练误差，也要考虑权重的大小。</li><li><strong>在权重更新过程中</strong>，惩罚项的存在直接影响每个权重的更新幅度，促使权重向零的方向调整，从而实现权重的减小。</li><li>这种机制最终有助于提高模型的泛化能力和稳定性。</li></ol><p>正则化（Regularization）是一种减少模型过拟合的方法。过拟合指的是模型在训练集上表现很好，但在测试集或新数据上表现不佳，说明模型学习了训练数据的噪声或细节，而不是一般化的模式。正则化的主要目的是限制模型的复杂度，使其在新数据上有更好的泛化能力。</p><p>在深度学习中，常用的正则化方法有以下几种：</p><h3 id="1-L1-和-L2-正则化"><a href="#1-L1-和-L2-正则化" class="headerlink" title="1. L1 和 L2 正则化"></a>1. <strong>L1 和 L2 正则化</strong></h3><ul><li><strong>L2 正则化</strong>（也称为权重衰减）：在损失函数中加入权重的平方和，即在损失函数后添加一个 (\lambda \sum w^2) 项，使模型倾向于学习更小的权重。这可以防止某些权重变得过大，从而控制模型的复杂性。</li><li><strong>L1 正则化</strong>：在损失函数中加入权重的绝对值和，即 (\lambda \sum |w|) 项，这会产生稀疏的权重矩阵，有助于特征选择，因为某些权重会被强制缩减到零，从而降低模型的复杂度。</li></ul><h3 id="2-Dropout"><a href="#2-Dropout" class="headerlink" title="2. Dropout"></a>2. <strong>Dropout</strong></h3><p>   Dropout 是在训练过程中随机丢弃一定比例的神经元，防止神经元之间的过度依赖。这样模型在每次训练时会使用不同的神经元子集，相当于训练了多个子模型的集成，可以有效地防止过拟合。Dropout 常用于神经网络的隐藏层。</p><h3 id="3-数据增强"><a href="#3-数据增强" class="headerlink" title="3. 数据增强"></a>3. <strong>数据增强</strong></h3><p>   数据增强通过对训练数据进行随机变换（如旋转、平移、翻转、裁剪等）来增加样本的多样性，从而降低模型对特定数据模式的过拟合倾向。数据增强本质上增加了数据集的规模，使模型更好地学习数据的普遍模式。</p><h3 id="4-提前停止（Early-Stopping）"><a href="#4-提前停止（Early-Stopping）" class="headerlink" title="4. 提前停止（Early Stopping）"></a>4. <strong>提前停止（Early Stopping）</strong></h3><p>   提前停止是在训练过程中监控验证集的误差，当验证误差不再下降或开始上升时，停止训练。这样可以避免模型在训练数据上学得过多（即过拟合），从而提高模型在新数据上的表现。</p><h3 id="5-批量归一化（Batch-Normalization）"><a href="#5-批量归一化（Batch-Normalization）" class="headerlink" title="5. 批量归一化（Batch Normalization）"></a>5. <strong>批量归一化（Batch Normalization）</strong></h3><p>   批量归一化通过标准化隐藏层的输入，将其均值和方差固定在一定范围内，从而加速训练并提高模型的泛化能力。虽然批量归一化的主要目的是稳定训练过程，但它也能起到一定的正则化作用，降低对每个单一批次的过拟合。</p><h3 id="6-噪声注入"><a href="#6-噪声注入" class="headerlink" title="6. 噪声注入"></a>6. <strong>噪声注入</strong></h3><p>   在输入层或隐藏层中加入随机噪声，让模型学习更加稳健的特征。常见的噪声注入方法包括对输入数据添加高斯噪声或 dropout。这使模型在训练过程中学会忽略随机噪声，提高泛化能力。</p><h3 id="7-模型剪枝（Pruning）"><a href="#7-模型剪枝（Pruning）" class="headerlink" title="7. 模型剪枝（Pruning）"></a>7. <strong>模型剪枝（Pruning）</strong></h3><p>   模型剪枝通过删除权重较小或对模型贡献较小的连接，减少模型的复杂度。模型剪枝不仅能降低模型的计算量，还可以提高模型的泛化能力，是一种结构化的正则化方法。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>正则化在深度学习中主要通过限制模型复杂度、增加数据多样性、提高训练稳定性来防止过拟合。选择合适的正则化方法通常取决于模型的结构、数据特征和实际任务需求。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数学角度看深度学习</title>
    <link href="/2024/10/29/20241029_MachineLearning_/"/>
    <url>/2024/10/29/20241029_MachineLearning_/</url>
    
    <content type="html"><![CDATA[<p>从数学的角度来看，这段代码展示了神经网络训练的基本流程，包括前向传播、损失计算、反向传播和参数更新。我们可以通过梯度下降的方法来最小化损失函数。</p><h3 id="数学解析"><a href="#数学解析" class="headerlink" title="数学解析"></a>数学解析</h3><h4 id="1-定义和初始化"><a href="#1-定义和初始化" class="headerlink" title="1. 定义和初始化"></a>1. 定义和初始化</h4><ul><li><p><code>net</code> 是一个神经网络模型，设模型参数为 (\theta)，包括权重和偏置。</p></li><li><p><code>loss</code> 是损失函数，定义为 ( L(\hat{y}, y) )，它衡量模型输出 </p><script type="math/tex; mode=display">\hat{y} = \text{net}(X; \theta)</script><p>和真实标签 ( y ) 的误差。</p></li><li><p><code>num_epochs = 3</code> 表示我们将训练模型 3 个轮次。</p></li></ul><h4 id="2-训练循环"><a href="#2-训练循环" class="headerlink" title="2. 训练循环"></a>2. 训练循环</h4><p>在训练过程中，每一个 <code>epoch</code> 都会经历以下步骤：</p><h4 id="3-小批量训练"><a href="#3-小批量训练" class="headerlink" title="3. 小批量训练"></a>3. 小批量训练</h4><p>代码中 <code>for X, y in data_iter</code> 遍历每个小批量的输入数据 (X) 和标签 (y)：</p><ol><li><p><strong>前向传播</strong>：对于每个小批量 ( X ) 和标签 ( y )：</p><ul><li><p>模型通过前向传播计算预测输出： </p><script type="math/tex; mode=display">\hat{y} = \text{net}(X; \theta)</script></li><li><p>这里的 <code>net(X)</code> 代表了从输入到输出的所有计算，这通常包括线性变换、非线性激活函数等。</p></li></ul></li><li><p><strong>损失计算</strong>：计算当前小批量数据的损失 ( l )：</p><script type="math/tex; mode=display">l = L(\hat{y}, y)</script><p>其中，</p><script type="math/tex; mode=display">\hat{y} = \text{net}(X)</script><p>常见的损失函数有均方误差（MSE）和交叉熵（Cross Entropy）等，具体取决于任务的类型（回归或分类）。</p></li><li><p><strong>梯度清零</strong>：<code>trainer.zero_grad()</code> </p></li></ol><ul><li>为了避免梯度的累积，清除上一批次计算出的梯度。</li></ul><ol><li><strong>反向传播</strong>：计算损失 ( l ) 对模型参数 (\theta) 的梯度：<script type="math/tex; mode=display">\nabla_\theta l = \frac{\partial L(\hat{y}, y)}{\partial \theta}</script></li></ol><ul><li>通过 <code>l.backward()</code> 调用链式法则，将损失的梯度从输出层逐层传递到每一层的参数（即计算各层参数的偏导数）。</li></ul><ol><li><strong>参数更新</strong>：利用梯度下降算法更新参数：<script type="math/tex; mode=display">\theta := \theta - \alpha \nabla_\theta l</script>其中 (\alpha) 是学习率，控制每次更新的步长大小。</li></ol><h4 id="4-整体损失评估"><a href="#4-整体损失评估" class="headerlink" title="4. 整体损失评估"></a>4. 整体损失评估</h4><p>在每个 <code>epoch</code> 结束时，代码再次计算模型在整个数据集上的损失：</p><script type="math/tex; mode=display">L_{\text{total}} = L(\text{net}(\text{features}), \text{labels})</script><p>这样可以监测每个 <code>epoch</code> 后的损失，判断训练的进展。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从数学角度看，这段代码实现了一个典型的 <strong>梯度下降优化过程</strong>，通过前向传播计算损失，然后通过反向传播计算梯度，再利用梯度下降更新参数。最终，损失逐渐减小，模型在数据上的性能逐步提升。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化</title>
    <link href="/2024/05/31/20240531_ConvexOptimization/"/>
    <url>/2024/05/31/20240531_ConvexOptimization/</url>
    
    <content type="html"><![CDATA[<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>数学基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>凸优化</tag>
      
      <tag>SVM</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>支持向量机</title>
    <link href="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/"/>
    <url>/2024/05/21/20240521_MachineLearning_SupportVectorMachines/</url>
    
    <content type="html"><![CDATA[<h1 id="线性可分定义"><a href="#线性可分定义" class="headerlink" title="线性可分定义"></a>线性可分定义</h1><p>​    二维平面中，<strong>存在一条直线</strong>可以把圆圈和叉分开；三维平面中，<strong>存在一个面</strong>可以把圆圈和叉分开；四维及以上，<strong>超平面</strong>。</p><p><style>.xyirytypusto{zoom:67%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240521231920803.png" class="xyirytypusto" alt="image-20240521231920803"></p><h2 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h2><p>​    我们有N个训练样本和他们的标签${(X_1,y_1),(X_2,y_2),…,(X_N,y_N)}$，</p><p>​    其中$X_i = [x_{i1},x_{i2}]^T$，$y_i = {+1,-1}$，这样，$y_i = +1$时，$X_1$属于$C_1$</p><h2 id="数学定义"><a href="#数学定义" class="headerlink" title="数学定义"></a>数学定义</h2><p>线性可分的严格定义：一个训练样本集${(X_i,y_i),…,(X_N,y_N)}$，在i=1~N线性可分，是指存在$(w_1,w_2,b)$，使得对i = 1~N，有：</p><ul><li>若$y_i = +1$，则$\omega_1x_{i1}+\omega_2x_{i2}+b &gt; 0$</li><li>若$y_i = -1$，则$\omega_1x_{i1}+\omega_2x_{i2}+b &lt; 0$</li></ul><h2 id="向量形式定义"><a href="#向量形式定义" class="headerlink" title="向量形式定义"></a>向量形式定义</h2><p>假设：$X_i={\begin{bmatrix}X_{i1}\\X_{i2}\end{bmatrix}}^T  \omega={\begin{bmatrix}\omega_{1}\\\omega_{2}\end{bmatrix}}^T$</p><ul><li>若$y_i = +1$，则$\omega^TX_{i}+b &gt; 0$</li><li>若$y_i = -1$，则$\omega^TX_{i}+b &lt; 0$</li></ul><h2 id="最简化形式"><a href="#最简化形式" class="headerlink" title="最简化形式"></a>最简化形式</h2><p>如果    $y_i=+1$或-1</p><p>一个训练样本集${(X_i,y_i)}$，在i = 1~N线性可分，是指存在(\omega，b)，使得对i = 1~N，有：</p> $$y_i(\omega^TX_i+b)>0 $$<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><h3 id="解决线性可分问题"><a href="#解决线性可分问题" class="headerlink" title="解决线性可分问题"></a>解决线性可分问题</h3><ul><li><p>在无数多个分开各个类别的超平面中，到底哪一个最好？</p><p><style>.hdbfgtisrujg{zoom:50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240522000808394.png" class="hdbfgtisrujg" alt="image-20240522000808394"></p><p>基于对训练样本先验分布有一定假设，如假设训练样本的位置在特征空间上有测量误差，图中二号线对训练样本误差的容忍程度是最高的，相比1号线和3号线更能抵御训练样本位置的误差</p></li><li><p>2号线是怎么画出来的？</p><p>基于最优化理论，间隔最大的是2号线，(确定唯一)取上下两个平行线中间</p><p><style>.qskhubiaclyk{zoom:50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240522001428124.png" class="qskhubiaclyk" alt="image-20240522001428124"></p><ol><li>该直线分开了两类</li><li>该直线最大化间隔</li><li>该直线处于间隔的中间，到所有支持向量距离相等</li></ol></li></ul><h3 id="再将线性可分问题中获得的结论推广到线性不可分情况"><a href="#再将线性可分问题中获得的结论推广到线性不可分情况" class="headerlink" title="再将线性可分问题中获得的结论推广到线性不可分情况"></a>再将线性可分问题中获得的结论推广到线性不可分情况</h3><h1 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h1><p><strong>如何用严格的数学，寻找最有分类超平面的过程，写成一个最优化的问题</strong></p><p>假定训练样本集是线性可分的,支持向量机需要的是最大化间隔(MARGIN)的超平面(离两边所有支持向量的距离相等)</p><h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p>已知：训练样本集{(x_i,y_i)},i=1到N；</p><p>待求：(w,b)</p><h2 id="最小化"><a href="#最小化" class="headerlink" title="最小化"></a>最小化</h2><p>${1 \over 2}{||\omega||}^2$</p><p>为什么看事实2</p><p><style>.tqqstwhluqvq{zoom:67%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528121654953.png" class="tqqstwhluqvq" alt="image-20240528121654953"></p><h2 id="限制条件"><a href="#限制条件" class="headerlink" title="限制条件"></a>限制条件</h2><p><strong>$y_i(w^Tx_i+b)&gt;=1,(i=1 ~ N)$</strong></p><p>在支持向量机（Support Vector Machine, SVM）中，约束条件$y_i (\omega^T x_i + b) \geq 1 ) （其中 (i = 1, 2, \ldots, N)$是用于确保数据点被正确分类并且在超平面边界以外有一定的间隔。具体解释如下：</p><ol><li><p><strong>定义符号</strong>：</p><ul><li>$\omega$是超平面的法向量。</li><li>$x_i$是第 $i$ 个样本点。</li><li>$b$是超平面的偏置项。</li><li>$y_i$ 是第$i$个样本点的类别标签，取值为$\pm1$。</li></ul></li><li><p><strong>支持向量机的目标</strong>：<br>SVM的目标是找到一个能够最大化分类间隔（Margin）的超平面。分类间隔定义为到最近数据点的距离。</p></li><li><p><strong>约束条件解释</strong>：<br>约束条件$y_i (\omega^T x_i + b) \geq 1$用于确保所有训练样本点被正确分类，并且离超平面至少有一个单位的距离。$y_i$协调超平面的左右。详细解释如下：</p><ul><li>当 $y_i = 1$ 时，约束条件为$\omega^T x_i + b \geq 1$。这意味着正类样本点$x_i $应该位于超平面的正侧并且到超平面的距离至少为 1。</li><li>当 $y_i = -1 $时，约束条件为$\omega^T x_i + b \leq -1$。这意味着负类样本点$x_i$应该位于超平面的负侧并且到超平面的距离至少为 1。</li></ul></li><li><p><strong>最大化间隔</strong>：<br>通过这些约束条件，我们确保了最小间隔为 1 的正确分类，同时目标是最大化此间隔。在优化过程中，我们会最小化 $\frac{1}{2} |\omega|^2$，等价于最大化间隔，因为间隔与$|\omega|$成反比。</p></li><li><p><strong>几何解释</strong>：<br>通过添加这个约束条件，我们可以确保找到的超平面不仅能正确分类所有样本点，还能最大化分类的鲁棒性，即使数据点在决策边界附近有少量扰动，也能保证分类的准确性。</p></li></ol><p>综上所述，约束条件$y_i (\omega^T x_i + b) \geq 1$是支持向量机的重要组成部分，它保证了正确分类并且尽可能地增大分类间隔，从而提高模型的泛化能力。</p><h2 id="事实"><a href="#事实" class="headerlink" title="事实"></a>事实</h2><h3 id="事实1"><a href="#事实1" class="headerlink" title="事实1"></a>事实1</h3><p>$\omega^Tx+b = b$与$(a\omega^T)x+(ab)=0$是同一个超平面。($a \neq 0$)</p><h3 id="事实2"><a href="#事实2" class="headerlink" title="事实2"></a>事实2</h3><p><strong>一个点$X_0$到超平面$\omega^Tx+b = 0$的距离$d = {|\omega^Tx_0+b| \over ||\omega||}$</strong></p><p><strong>一个点$(x_0,y_0)$到超平面$\omega_1x+\omega_2y+b = 0 $的距离$d = {|\omega_1x_0 + \omega_2y_0 + b| \over  \sqrt {\omega_1^2 + \omega_2^2}}$</strong></p><ol><li><p><strong>平面方程</strong>：给定平面$ \alpha $的方程为：<br>$Ax + By + Cz + D = 0 $</p></li><li><p><strong>点和法向量</strong>：点  $P_0(x_0, y_0, z_0) $是要计算到平面距离的点，平面的法向量为 $\vec{n} = (A, B, C) $。</p></li><li><p><strong>距离公式的推导</strong>：</p><ol><li>选择平面上的一点 $P_1(x_1, y_1, z_1)$  作为参考点。</li><li>向量 $\vec{P_1P_0} $表示从点 $ P_1 $ 到点 $ P_0 $的向量，其表示为：<br>$\vec{P_1P_0} = (x_0 - x_1, y_0 - y_1, z_0 - z_1) $</li><li>点 $P_0 $到平面的距离 $d$等于向量$\vec{P_1P_0}$ 在法向量 $\vec{n} $上的投影的绝对值，公式为：<br>$d = \frac{|\vec{P_1P_0} \cdot \vec{n}|}{|\vec{n}|}$</li><li>计算向量点积$\vec{P_1P_0} \cdot \vec{n}$：<br>$ \vec{P_1P_0} \cdot \vec{n} = A(x_0 - x_1) + B(y_0 - y_1) + C(z_0 - z_1)$</li><li>计算法向量$\vec{n}$的模长：<br>$ |\vec{n}| = \sqrt{A^2 + B^2 + C^2}$</li></ol></li><li><p><strong>化简距离公式</strong>：</p><ol><li>由于点$P_1$在平面上，所以 $Ax_1 + By_1 + Cz_1 + D = 0$，因此$D = -(Ax_1 + By_1 + Cz_1)$。</li><li>将上面的结果代入到公式中，得到：<br>$d = \frac{|A(x_0 - x_1) + B(y_0 - y_1) + C(z_0 - z_1)|}{\sqrt{A^2 + B^2 + C^2}}$</li><li>将 ( P_1(x_1, y_1, z_1) ) 替换成点 ( P_0(x_0, y_0, z_0) ) 的坐标，公式变为：<br>$d = \frac{|Ax_0 + By_0 + Cz_0 + D|}{\sqrt{A^2 + B^2 + C^2}}$</li></ol></li></ol><p>因此，点 $P_0(x_0, y_0, z_0)$到平面$Ax + By + Cz + D = 0$的距离公式为：</p><p>$d = \frac{|Ax_0 + By_0 + Cz_0 + D|}{\sqrt{A^2 + B^2 + C^2}}$</p><h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><ul><li>用a去缩放$/omega b$</li><li>$(/omega , b)$-&gt;$(a/omega , ab)$</li><li>最终使在支持向量$x_0$上有$|/omega^Tx_0 + b| = 1$，而在非支持向量上$ |/omega^Tx_0 + b| &gt; 1$</li><li>根据事实2，支持向量机$x_0$到超平面距离将会变为：$d = \frac{|\omega^T x_0 + b|}{|\omega|} = \frac{1}{|\omega|}$</li><li>最大化支持向量到超平面的距离等价于最小化||/omega||</li></ul><h2 id="二次规划"><a href="#二次规划" class="headerlink" title="二次规划"></a>二次规划</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul><li><p>目标函数是二次项</p><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528171356369.png" class="" title="image-20240528171356369"></li><li><p>限制条件是一次项</p><p><style>.oioikeynhkcs{zoom: 50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528171415612.png" class="oioikeynhkcs" alt="image-20240528171415612"></p></li><li><p>这种凸优化问题要么无解，要么只有唯一的最小值解，可以应用梯度算法来解</p></li></ul><h1 id="线性不可分情况"><a href="#线性不可分情况" class="headerlink" title="线性不可分情况"></a>线性不可分情况</h1><ul><li><p>不存在$\omega$和$b$满足上面所有N个限制条件</p></li><li><p>需要放松限制条件(基本思路)</p><ul><li>对每个训练样本及标签$(X_i,Y_i)$</li><li>松弛变量$\delta_i$</li><li>限制条件改写：$y_i(\omega^TX_i + b) \ge 1 - \delta_i (i = 1\sim N)$</li></ul></li><li><p>改造后的支持向量机优化版本</p><p><style>.gbkhvefdhsyg{zoom: 33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531112604943.png" class="gbkhvefdhsyg" alt="image-20240531112604943"></p></li><li><p>人为实现设定的参数叫做算法的超参数，不断变化C的值，同时测试算法的识别率，选取超参数C</p></li><li><p>支持向量机是超参数很少的算法模型</p></li></ul><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p><style>.jvalpectqllm{zoom:33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531113517531.png" class="jvalpectqllm" alt="image-20240531113517531"></p><p><strong>C很大</strong>，会迫使所有的$\delta_i$趋于0，<strong>超平面和线性可分情况保持基本一致</strong></p><p><style>.tcxjhsstvtro{zoom:50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531113702251.png" class="tcxjhsstvtro" alt="image-20240531113702251"></p><p>未达到求解目的(类型:所有的圆圈被所有的叉包围了)，这个解远远不能让人满意，分错了一半训练样本</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我们是假设分开两类的函数是线性的，线性模型的表现力是不够的，无论我们如何取直线，都是不好的，应该扩大可选函数范围，使得其超越线性</p><h2 id="课后思考"><a href="#课后思考" class="headerlink" title="课后思考"></a>课后思考</h2><p>请问：在这个例子中，你能否设计出一个这样的非线性变换，将这个分类问题转化为线性可分？</p><p>要将这个非线性可分的分类问题转化为线性可分，可以考虑使用核函数或特征变换。一个常见的非线性变换方法是将输入空间映射到一个更高维的特征空间</p><p>对于这个例子，可以使用径向基函数(BRF)核函数或多项式核函数来进行非线性变换</p><h3 id="特征变换的示例"><a href="#特征变换的示例" class="headerlink" title="特征变换的示例"></a>特征变换的示例</h3><p>假设我们有两个特征$x_1$和$x_2$，可以将其转换为新的特征z，例如：</p><p>$ z_1 = x_1^2$</p><p>$ z_2 = x_2^2$</p><p>$ z_3 = x_1 \cdot x_2$</p><p>这种变换可以将原始的二维非线性可分数据映射到三维空间，使得在这个新空间中变得线性可分</p><h3 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h3><p>另一种方法是使用核函数，例如径向基函数核(RBF核)：</p><p>$K(x_i,x_j) = exp(\gamma||x_i - x_j||^2)$</p><p>通过这种方法，可以隐式地将数据映射到一个高维空间，而无需显示地计算特征变换</p><h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-comment"># 导入Numpy库，用于数值计算</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<span class="hljs-comment"># 导入Matplotlib库，用于绘图</span><br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<span class="hljs-comment"># 从Scikit-learn库中导入支持向量分类器</span><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_circles<span class="hljs-comment"># 从Scikit-learn库中导入make_circles函数，用于生成示例数据集</span><br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<span class="hljs-comment"># 从Matplotlib库中导入3D绘图工具</span><br><br><span class="hljs-comment"># 生成非线性可分的数据</span><br>X, y = make_circles(n_samples=<span class="hljs-number">100</span>, factor=<span class="hljs-number">.3</span>, noise=<span class="hljs-number">.05</span>)<br><span class="hljs-comment"># factor的值是介于0和1之间的小数，表示内圈半径与外圈半径的比例。这里表示内圈是外圈的30%</span><br><span class="hljs-comment"># noise参数控制数据点的随机扰动或噪声的量。表示生成数据点加入的高斯噪声的标准差。这里noise=.05表示数据点会有一定程度的随机偏移，以增加数据的真实感和复杂性</span><br><span class="hljs-comment"># x：形状为(n_samples,2)的Numpy数组，其中每一行表示二维数据点。具体来说，x的每一行包含一个数据点的两个特征</span><br><span class="hljs-comment"># y：形状为(n_samples,)的Numpy数组，包含每一个数据点的类别标签。类别标签为二进制的（0或1），表示数据点的外圈和内圈</span><br><br><span class="hljs-comment"># 绘制原始数据</span><br>plt.scatter(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>], c=y, cmap=plt.cm.Paired)<br>plt.title(<span class="hljs-string">&quot;Original Data&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;$x_1$&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;$x_2$&#x27;</span>)<br>plt.show()<br><br><span class="hljs-comment"># 特征变换，变换后新特征矩阵Z具有三个特征列</span><br>Z = np.array([X[:, <span class="hljs-number">0</span>]**<span class="hljs-number">2</span>, <br>              X[:, <span class="hljs-number">1</span>]**<span class="hljs-number">2</span>, <br>              X[:, <span class="hljs-number">0</span>] * X[:, <span class="hljs-number">1</span>]]).T<br><br><br><span class="hljs-comment"># 绘制变换后的数据</span><br>fig = plt.figure()<br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br>ax.scatter(Z[:, <span class="hljs-number">0</span>], Z[:, <span class="hljs-number">1</span>], Z[:, <span class="hljs-number">2</span>], c=y, cmap=plt.cm.Paired)<br>plt.title(<span class="hljs-string">&quot;Transformed Data&quot;</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;$z_1$&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;$z_2$&#x27;</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;$z_3$&#x27;</span>)<br>plt.show()<br><br><span class="hljs-comment"># 使用RBF核进行SVM分类</span><br>clf = SVC(kernel=<span class="hljs-string">&#x27;rbf&#x27;</span>)<br>clf.fit(X, y)<br><br><span class="hljs-comment"># 绘制决策边界</span><br>xx, yy = np.meshgrid(np.linspace(-<span class="hljs-number">1.5</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">500</span>), np.linspace(-<span class="hljs-number">1.5</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">500</span>))<br>Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])<br>Z = Z.reshape(xx.shape)<br><br>plt.scatter(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>], c=y, cmap=plt.cm.Paired)<br>plt.contour(xx, yy, Z, levels=[<span class="hljs-number">0</span>], linewidths=<span class="hljs-number">2</span>, colors=<span class="hljs-string">&#x27;black&#x27;</span>)<br>plt.title(<span class="hljs-string">&quot;Decision Boundary with RBF Kernel&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;$x_1$&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;$x_2$&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="思维方式"><a href="#思维方式" class="headerlink" title="思维方式"></a>思维方式</h3><ol><li><p>观察数据分布</p><p>首先，我们需要仔细观察数据的分布。通过可视化数据（如散点图），我们可以识别出数据的结构和模式。在你的例子中，数据呈现出同心圆的分布，明显不是线性可分的。</p></li><li><p>找到适合的特征变换</p><p>为了使数据变得线性可分，我们需要找到一种变换方式，使得数据在新的特征空间中分布更适合线性分类。常见的思路包括：</p><ul><li><strong>多项式变换</strong>：对于同心圆分布的数据，平方或交叉项（如$x_1^2 、x_2^2 和x_1 \cdot x_2$）可能会有帮助，因为这些变换可以捕捉到数据的非线性关系。</li><li><strong>非线性变换</strong>：使用核方法（如RBF核）来隐式地将数据映射到高维空间，其中数据可能会变得线性可分。</li></ul></li><li><p>数学和几何直觉</p><p>通过数学和几何直觉，我们可以推断出一些变换可能会使数据线性可分。例如，考虑二次多项式变换。对于同心圆数据，使用平方项可以将圆形分布的数据转换为线性可分的数据。这是因为平方变换会放大远离原点的数据点的特征，使得数据点在新的空间中分布得更加分散。</p></li><li><p>实验和验证</p><p>即使有数学和几何直觉的支持，我们仍然需要通过实验和验证来确认选择的特征变换是否有效。这可以通过以下步骤实现：</p><ul><li><strong>选择变换</strong>：选定一种或几种可能的特征变换。</li><li><strong>应用变换</strong>：将原始数据应用选定的变换。</li><li><strong>训练模型</strong>：在变换后的特征空间中训练线性分类模型。</li><li><strong>验证结果</strong>：评估模型的表现，查看其是否能够有效分类数据。</li></ul></li></ol><h1 id="低维到高维的映射"><a href="#低维到高维的映射" class="headerlink" title="低维到高维的映射"></a>低维到高维的映射</h1><ul><li><p>在扩大可选函数范围方面独树一帜</p></li><li><p>特征空间由低维映射到高维，用线性超平面对数据进行分类</p></li><li><p><style>.lwenyhujbkwe{zoom: 33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150013897.png" class="lwenyhujbkwe" alt="image-20240531150013897"></p></li><li><p>构造一个二维到五维的映射$\varphi(x)$</p><ul><li><style>.hbpwkstklmjn{zoom: 33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150401228.png" class="hbpwkstklmjn" alt="image-20240531150401228"></li><li><style>.mpizbxsxwcbn{zoom:33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150540767.png" class="mpizbxsxwcbn" alt="image-20240531150540767"></li><li>此时线性可分</li><li><style>.wqgturqjvtyn{zoom:33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150706444.png" class="wqgturqjvtyn" alt="image-20240531150706444"></li></ul></li><li><p>假设：</p><p>在一个<strong>M维空间</strong>上随机取N个训练样本</p><p>随机的对每个训练样本赋予标签<strong>+1或-1</strong></p><p><strong>假设</strong>：</p><p>这些训练样本线性可分的概率为<strong>P(M)</strong></p><p><strong>当M趋于无穷大时    P(M)=1</strong></p></li></ul><h2 id="优化问题-1"><a href="#优化问题-1" class="headerlink" title="优化问题"></a>优化问题</h2><p>前$\omega维度与X_i$维度相同    $\omega$维度与$\varphi(x_i)$相同</p><p>高维情况下优化问题的解法和低维情况下是完全类似的</p><p><style>.uzkpysmukiws{zoom:67%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531151519887.png" class="uzkpysmukiws" alt="image-20240531151519887"></p><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531151548140.png" class="" title="image-20240531151548140"><h2 id="优化问题的凸性"><a href="#优化问题的凸性" class="headerlink" title="优化问题的凸性"></a>优化问题的凸性</h2><h3 id="凸优化问题的定义"><a href="#凸优化问题的定义" class="headerlink" title="凸优化问题的定义"></a>凸优化问题的定义</h3><ul><li>一个优化问题是凸的，如果其目标函数是凸函数，并且约束条件也定义了一个凸集</li><li>凸函数的一个重要性质是其任意局部最优解也是全局最优解，这使得优化问题易于求解</li></ul><h3 id="SVM优化目标"><a href="#SVM优化目标" class="headerlink" title="SVM优化目标"></a>SVM优化目标</h3><ul><li><p>支持向量机的目标是找到一个分离超平面，使得两个类别的间隔最大化。对于线性 SVM，其优化问题可以表示为： </p><p>$\min_{w,b}{1\over2}||w||^2 $</p><p>其中 <strong>w</strong> 是权重向量，b* 是偏置。这个目标函数是凸的。</p></li></ul><h1 id="核函数的定义"><a href="#核函数的定义" class="headerlink" title="核函数的定义"></a>核函数的定义</h1><p>$K(X_1,X_2) = \varphi(X_1)^T\varphi(X_2)$完成对测试样本类别的预测</p><h2 id="核方法和核矩阵"><a href="#核方法和核矩阵" class="headerlink" title="核方法和核矩阵"></a>核方法和核矩阵</h2><h3 id="核函数的引入"><a href="#核函数的引入" class="headerlink" title="核函数的引入"></a>核函数的引入</h3><ul><li>在处理非线性可分问题时，SVM使用核函数$K(X_i,X_j)$将数据映射到高维特征空间，以实现线性可分</li><li>核函数K计算两个输入数据点$X_i和X_j$在高维空间中的内积，而不需要显示地进行高维映射</li></ul><h3 id="核矩阵"><a href="#核矩阵" class="headerlink" title="核矩阵"></a>核矩阵</h3><ul><li>$K_{ij} = K(X_i,X_j)$</li><li>核矩阵K是一个对称矩阵，其元素是核函数在数据点间计算的值</li></ul><h2 id="半正定性的重要性"><a href="#半正定性的重要性" class="headerlink" title="半正定性的重要性"></a>半正定性的重要性</h2><h3 id="半正定性定义"><a href="#半正定性定义" class="headerlink" title="半正定性定义"></a>半正定性定义</h3><ul><li>一个对称矩阵K是半正定的，如果对于任何向量z，都有$z^TKz \ge 0$</li></ul><h3 id="核矩阵的半正定性与凸性"><a href="#核矩阵的半正定性与凸性" class="headerlink" title="核矩阵的半正定性与凸性"></a>核矩阵的半正定性与凸性</h3><ul><li>对于SVM的优化问题，目标函数包含核矩阵K。如果K是半正定的，那么相应的二次规划问题也是凸的</li><li>半正定性保证了目标函数在所有方向上的二次型都是非负的，即目标函数是凸函数</li></ul><h3 id="唯一解的存在性"><a href="#唯一解的存在性" class="headerlink" title="唯一解的存在性"></a>唯一解的存在性</h3><ul><li>在凸优化问题中，目标函数的任何局部最优解也是全局最优解。因此，确保核矩阵是半正定的，能保证SVM优化问题有唯一解。</li></ul><h2 id="核函数与-varphi-x-的关系"><a href="#核函数与-varphi-x-的关系" class="headerlink" title="核函数与$\varphi(x)$的关系"></a>核函数与$\varphi(x)$的关系</h2><p>核函数K和映射$\varphi$是一一对应的，核函数的形式不能随意取，需满足为一定条件才能分解为两个$\varphi$内积的形式</p><h3 id="Mercer’s-Theorem定理"><a href="#Mercer’s-Theorem定理" class="headerlink" title="Mercer’s Theorem定理"></a>Mercer’s Theorem定理</h3><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531154748128.png" class="" title="image-20240531154748128"><h3 id="已知-varphi-求K"><a href="#已知-varphi-求K" class="headerlink" title="已知$\varphi$求K"></a>已知$\varphi$求K</h3><p>假设：$\varphi(x)$是一个将二维向量映射为三维向量的映射</p><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153113219.png" class="" title="image-20240531153113219"><p>假设有两个二维向量</p><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153414510.png" class="" title="image-20240531153414510"><h3 id="已知K求-varphi"><a href="#已知K求-varphi" class="headerlink" title="已知K求$\varphi()$"></a>已知K求$\varphi()$</h3><p>假设：</p><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153902859.png" class="" title="image-20240531153902859"><p>假设：</p><p>$X = [x_1,x_2]^T$</p><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531154142917.png" class="" title="image-20240531154142917"><p><strong>$K(X_1,X_2)$就是前面那个形式</strong></p><h1 id="原问题和对偶问题"><a href="#原问题和对偶问题" class="headerlink" title="原问题和对偶问题"></a>原问题和对偶问题</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><ol><li><p>原问题</p><ul><li>最小化：$f(\omega)$</li><li>限制条件<ul><li>$g_i(\omega) \le 0    i = 1 \sim K$</li><li>$h_i(\omega) = 0     i = 1 \sim m$</li></ul></li></ul></li><li><p>对偶问题</p><ul><li><p>$ L(\omega, \alpha, \beta) = f(\omega) + \sum_{i=1}^{K} \alpha_i g_i(\omega) + \sum_{i=1}^{K} \beta_i h_i(\omega) $</p><p> $ = f(\omega) + \alpha^T g(\omega) + \beta^T h(\omega) $</p></li><li><p>其中</p><p>$ \alpha = \begin{bmatrix} \alpha_1, \alpha_2, \ldots, \alpha_K \end{bmatrix}^T $</p><p>$ \beta = \begin{bmatrix} \beta_1, \beta_2, \ldots, \beta_M \end{bmatrix}^T $</p><p>$ g(\omega) = \begin{bmatrix} g_1(\omega), g_2(\omega), \ldots, g_k(\omega) \end{bmatrix}^T $</p><p>$ h(\omega) = \begin{bmatrix} h_1(\omega), h_2(\omega), \ldots, h_m(\omega) \end{bmatrix}^T $</p></li><li><p>最大化：$\theta(\alpha,\beta) = \inf   L(\omega,\alpha,\beta)$，所有定义域内的$\omega $, 使得L最小</p></li><li><p>限制条件：$\alpha_i \ge 0, i =  1 \sim K$</p></li></ul></li><li><p>定理一</p><p>如果$\omega$是原问题的解，$(\alpha^\ast,\beta^\ast)$是对偶问题的解则有：</p><p><strong>$f(\omega^\ast) \ge \theta(\alpha^\ast,\beta^\ast)$</strong></p><p>证明：$\theta(\alpha^\ast, \beta^\ast) = \inf L(\omega, \alpha^\ast, \beta^\ast)$</p><p>​           $\leq L(\omega^\ast, \alpha^\ast, \beta^\ast)$</p><p>​           $= f(\omega^\ast) + \alpha^{\ast T} g(\omega^\ast) + \beta^{\ast T} h(\omega^\ast)$</p><p>​           $\leq f(\omega^\ast)$</p><ul><li><p>原问题的解总是大于对偶问题的解</p></li><li><p>对偶差距: $ f(\omega^\ast) - \theta(\alpha^\ast, \beta^\ast)$</p><p>对偶差距为大于等于零的函数</p></li></ul></li><li><p>强对偶定理</p><p>如果$g(\omega)=A\omega+b,h(\omega)=C\omega+d$,$f(\omega)$为凸函数，则有$f(\omega^\ast) = \theta(\alpha^\ast,\beta^\ast)$,</p><p>则对偶差距为0。</p><ul><li>原问题的目标函数是凸函数，限制条件是线性函数，那么$f(\omega^\ast) = \theta(\alpha^\ast,\beta^\ast)$</li></ul></li><li><p>KKT条件</p><p>若 $f(\omega^{\ast}) = \theta(\alpha^{\ast}, \beta^{\ast})$，则定理一中必然能够推出，对于所有的 $i = 1 \sim K$，要么 $\alpha_i = 0$，要么 $g_i(\omega^{\ast}) = 0$。这个条件称为 KKT 条件。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>AI</tag>
      
      <tag>SVM</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习引言</title>
    <link href="/2024/05/19/20240519_MachineLearning_Introduction/"/>
    <url>/2024/05/19/20240519_MachineLearning_Introduction/</url>
    
    <content type="html"><![CDATA[<h1 id="机器学习观点"><a href="#机器学习观点" class="headerlink" title="机器学习观点"></a>机器学习观点</h1><ul><li><p>拿到数据之后，<strong>构建机器学习算法第一步</strong>：观察数据，总结规律</p><ul><li><p><strong>不正确观点</strong>：收集足够多数据，从网上随便下载一个开源算法模型，直接将数据扔进模型中训练，就可能获得很好的结果（大多数不正确）</p></li><li><p>对数据有足够的感性认识，才能设计出好的算法以及认识算法的性能极限</p></li></ul></li><li><strong>设计算法</strong>：思考一个任务的经验E和性能指标P是什么</li><li>一个解决分类的问题稍微加以改造就可以解决回归问题，反之亦然，因为连续与离散是可以转换的</li><li>机器学习的重点不是提取特征，而是假设在<strong>已经提取好特征</strong>的前提下，如何构造算法获得更好的性能</li><li>提取特征很重要，不同媒质不同任务，提取特征的方式千变万化</li><li>维度与标准决定了我们要用机器学习，维度：人对超过二维的数据难以想象，标准：对某些区域的划分是不一样的</li><li>机器学习是典型的最优化问题，数学在现代化机器学习中占有重要的作用</li></ul><h1 id="机器学习定义"><a href="#机器学习定义" class="headerlink" title="机器学习定义"></a>机器学习定义</h1><h2 id="ARCHUR-SAMUEL"><a href="#ARCHUR-SAMUEL" class="headerlink" title="ARCHUR SAMUEL"></a>ARCHUR SAMUEL</h2><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs applescript">ARCHUR SAMUEL：<br>​Machine Learning <span class="hljs-keyword">is</span> Fields <span class="hljs-keyword">of</span> study <span class="hljs-keyword">that</span> gives computers <span class="hljs-keyword">the</span> ability <span class="hljs-keyword">to</span> learn <span class="hljs-keyword">without</span> being explicitly programmed.<br>​机器学习是这样的领域，它土语计算机学习的能力，（这种学习能力）不是通过显著式编程获得的。<br></code></pre></td></tr></table></figure><h3 id="显著式编程"><a href="#显著式编程" class="headerlink" title="显著式编程"></a>显著式编程</h3><ul><li>通过人为预先定义出规律，告诉计算机实现一一对照区别。</li><li>劣势：<strong>人为</strong>帮计算机<strong>规划</strong>所处的环境，将环境、规律调查得一清二楚</li></ul><h3 id="非显著式编程"><a href="#非显著式编程" class="headerlink" title="非显著式编程"></a>非显著式编程</h3><ul><li>事先并不约束计算机总结出什么规律，只给大量数据，编写程序让计算机自己挑出能分辨事物的规律，总结不同事物的区别</li><li>规定在特定环境下，做一些行为带来的收益，将收益称为<strong>收益函数</strong></li><li>规定了收益函数后，让计算机去自己<strong>找最大化收益函数</strong>的行为</li><li>优势：<strong>通过数据、经验自动学习</strong></li></ul><h2 id="TOM-MITSHELL"><a href="#TOM-MITSHELL" class="headerlink" title="TOM MITSHELL"></a>TOM MITSHELL</h2><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs applescript">TOM MITSHELL:<br>​A computer program <span class="hljs-keyword">is</span> said <span class="hljs-keyword">to</span> learn <span class="hljs-keyword">from</span> experience E <span class="hljs-keyword">with</span> respect <span class="hljs-keyword">to</span> <span class="hljs-keyword">some</span> task T <span class="hljs-keyword">and</span> <span class="hljs-keyword">some</span> performance measure P, <span class="hljs-keyword">if</span> <span class="hljs-keyword">its</span> performance <span class="hljs-keyword">on</span> T, <span class="hljs-keyword">as</span> measured <span class="hljs-keyword">by</span> P, improves <span class="hljs-keyword">with</span> experience E.<br>​一个计算机程序被称为可以学习，是指它能够针对某个任务T和某个性能指标P，从经验E中学习。这种学习的特点是，它在T上的被P所衡量的性能，会随着经验E的增加而提高。<br>​任务 T：编写计算机程序识别菊花和玫瑰<br>经验 E：一大堆菊花和玫瑰的图片<br>性能指标 P：不同的机器学习算法会有不同，如把识别的正确率简称为识别率，将其作为性能指标<br></code></pre></td></tr></table></figure><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>Experience越来越多，Performance Measure也会越来越高</li><li>更数学化，典型的最优化问题</li></ul><h3 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h3><ul><li>数学在现代化机器学习中占有重要的作用</li></ul><h1 id="机器学习分类"><a href="#机器学习分类" class="headerlink" title="机器学习分类"></a>机器学习分类</h1><p>现在的强化学习利用到了监督学习，如ALPHAGO，先通过监督学习获得初试围棋程序，再将初试围棋程序进行强化学习</p><h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><ul><li>经验E是完全由人搜集起来输入进计算机</li><li>为训练数据打标签，此时经验E为：<strong>训练样本</strong>和<strong>标签</strong>的集合<ul><li>垃圾邮件识别，教计算机自动识别某个邮件识别是垃圾邮件</li><li>人脸识别，教计算机通过人脸的图像识别这个人是谁</li></ul></li></ul><h3 id="传统监督学习"><a href="#传统监督学习" class="headerlink" title="传统监督学习"></a>传统监督学习</h3><p>每一个训练数据都有对应的标签</p><ul><li>支持向量机</li><li>人工神经网络</li><li>深度神经网络</li></ul><h3 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h3><p>所有训练数据都没有对应的标签</p><ul><li>聚类</li><li>EM算法</li><li>主成分分析</li></ul><h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>训练数据中一部分有标签，一部分没有标签（如何用少量标注数据与大量未标注数据，获得更好的机器学习算法）</p><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><ul><li>经验E是由计算机与环境互动获得的</li><li>产生<strong>行为</strong>，定义这些行为的收益函数(Reward function)，改变自己行为模式去<strong>最大化收益函数</strong></li><li>计算机通过与环境的互动，逐渐强化自己的行为模式<ul><li>教计算机下棋</li><li>无人驾驶，教计算机自动驾驶汽车，从一个指定地点到另一个指定地点</li></ul></li></ul><h1 id="机器学习算法过程"><a href="#机器学习算法过程" class="headerlink" title="机器学习算法过程"></a>机器学习算法过程</h1><p>识别尿沉中的红白细胞</p><p><style>.luhoiuprxiuh{zoom:50%;}</style><img src="/2024/05/19/20240519_MachineLearning_Introduction/image-20240520000512315.png" class="luhoiuprxiuh" alt="image-20240520000512315"></p><p>可能被观察到的区别</p><ul><li>平均来说，白细胞面积比红细胞大</li><li>白细胞没有红细胞圆</li><li>白细胞内部纹理比红细胞粗糙</li></ul><h2 id="第一步：提取特征"><a href="#第一步：提取特征" class="headerlink" title="第一步：提取特征"></a>第一步：提取特征</h2><p>通过训练样本获得的，对机器学习任务有帮助的多维度的特征数据</p><p>很重要，提取了好的特征，（即使算法不是很好）也能获得不错的性能</p><p>提取了差的特征，不可能获得好的性能</p><p><strong>细胞的面积</strong>    <strong>圆形度</strong>    <strong>表面粗糙程度</strong></p><h3 id="提取面积特征方法"><a href="#提取面积特征方法" class="headerlink" title="提取面积特征方法"></a>提取面积特征方法</h3><p><style>.ljjyhpkscmjq{zoom:50%;}</style><img src="/2024/05/19/20240519_MachineLearning_Introduction/image-20240520001815389.png" class="ljjyhpkscmjq" alt="image-20240520001815389"></p><h2 id="第二步：特征选择"><a href="#第二步：特征选择" class="headerlink" title="第二步：特征选择"></a>第二步：特征选择</h2><p>只选择面积与周长作为区分，来构建机器学习系统，后面归一化一下</p><p><style>.ssfhtaajmmuj{zoom:50%;}</style><img src="/2024/05/19/20240519_MachineLearning_Introduction/image-20240520002610676.png" class="ssfhtaajmmuj" alt="image-20240520002610676"></p><p><style>.mbixtrpinryy{zoom: 50%;}</style><img src="/2024/05/19/20240519_MachineLearning_Introduction/image-20240520002746171.png" class="mbixtrpinryy" alt="image-20240520002746171"></p><h2 id="第三步：设计算法"><a href="#第三步：设计算法" class="headerlink" title="第三步：设计算法"></a>第三步：设计算法</h2><h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul><li>线性内核</li><li>多项式内核</li><li>高斯径向基函数核</li></ul><p><style>.dzbnxkhnwkam{zoom: 50%;}</style><img src="/2024/05/19/20240519_MachineLearning_Introduction/image-20240520003916270.png" class="dzbnxkhnwkam" alt="image-20240520003916270"></p><h2 id="第四步：训练结果"><a href="#第四步：训练结果" class="headerlink" title="第四步：训练结果"></a>第四步：训练结果</h2><p>获得训练库准确率</p><p><style>.yaneqkflhiwh{zoom:67%;}</style><img src="/2024/05/19/20240519_MachineLearning_Introduction/image-20240520003934456.png" class="yaneqkflhiwh" alt="image-20240520003934456"></p><h1 id="机器学习算法比较"><a href="#机器学习算法比较" class="headerlink" title="机器学习算法比较"></a>机器学习算法比较</h1><h2 id="没有免费午餐定理"><a href="#没有免费午餐定理" class="headerlink" title="没有免费午餐定理"></a>没有免费午餐定理</h2><p>​    任何一个预测函数，如果在一些训练样本上表现好，那么必然在另一些训练样本上表现不好，如果不对数据在特征空间的先验分布有一定假设，那么表现好于表现不好的情况一样多。</p><p>​    在设计机器学习算法的时候有一个假设：在特征空间上距离接近的样本，他们属于同一个类别的概率会更高。</p><p>​    道理是从以前的事实中来的。通过类比推广到对未来的预测。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​    不对特征空间的先验分布有假设，所有算法的表现都一样。</p><p>​    机器学习的本质：从有限的已知数据，在复杂的高维特征空间中预测未知样本的属性和类别。<strong>然而</strong>，我们不知道未知样本在哪里、性质如何，因此，再好的算法也存在犯错误的风险。</p><h1 id="机器学习作业"><a href="#机器学习作业" class="headerlink" title="机器学习作业"></a>机器学习作业</h1><p>编程大作业</p><ul><li>人脸识别</li></ul><ul><li>人脸性别年龄估计</li></ul><ul><li>五子棋对战程序</li></ul><ul><li>水果识别</li></ul><ul><li>人脸特征点检测</li></ul><ul><li>语种识别</li></ul><ul><li>视频行为识别</li></ul>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pandas库入门</title>
    <link href="/2024/05/17/20240517_Pandas/"/>
    <url>/2024/05/17/20240517_Pandas/</url>
    
    <content type="html"><![CDATA[<h1 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h1><p>提供高性能易用数据类型和分析工具</p><p><a href="http://pandas.pydata.org">http://pandas.pydata.org</a></p><p>Pandas基于NumPy实现，常与NumPy和Matplotlib一同使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>    d = pd.Serier(<span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>))<br>    d<br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">0</span><br><span class="hljs-number">1</span><span class="hljs-number">1</span><br><span class="hljs-number">2</span><span class="hljs-number">2</span><br><span class="hljs-number">3</span><span class="hljs-number">3</span><br><span class="hljs-number">4</span><span class="hljs-number">4</span><br>...<br><span class="hljs-number">19</span><span class="hljs-number">19</span><br>dtype: int32<br><br>In :d.cumsum()<span class="hljs-comment">#计算前N项累加和</span><br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">0</span><br><span class="hljs-number">1</span><span class="hljs-number">1</span><br><span class="hljs-number">2</span><span class="hljs-number">3</span><br><span class="hljs-number">3</span><span class="hljs-number">6</span><br><span class="hljs-number">4</span><span class="hljs-number">10</span><br>...<br><span class="hljs-number">18</span><span class="hljs-number">171</span><br><span class="hljs-number">19</span><span class="hljs-number">190</span><br>dtype: int32<br></code></pre></td></tr></table></figure><h2 id="Series，DataFrame"><a href="#Series，DataFrame" class="headerlink" title="Series，DataFrame"></a>Series，DataFrame</h2><p>像对待单一数据一样对待</p><p>基于这两种数据类型有各类操作：<strong>基本操作、运算操作、特征类操作、关联类操作</strong></p><h2 id="对比NumPy与Pandas"><a href="#对比NumPy与Pandas" class="headerlink" title="对比NumPy与Pandas"></a>对比NumPy与Pandas</h2><h3 id="基础数据类型与扩展数据类型"><a href="#基础数据类型与扩展数据类型" class="headerlink" title="基础数据类型与扩展数据类型"></a>基础数据类型与扩展数据类型</h3><p>NumPy的基础数据类型ndarray可以表达n维数组，Pandas提供两种基于ndarray的扩展数据类型</p><h3 id="数据结构表达与数据应用表达"><a href="#数据结构表达与数据应用表达" class="headerlink" title="数据结构表达与数据应用表达"></a>数据结构表达与数据应用表达</h3><p>NumPy关注数据的结构表达，数据的结构表达即数据构成的维度，即你给我一些数据，我关注要用什么维度将数据存储起来并表示出来，数据通过n维方式存储至一个变量中</p><p>Pandas关注数据的应用表达，使用数据的时候，怎么更有效地提取数据，以及对这些数据进行运算</p><p>我们把数据维度简历好，可以将数据结构表达清楚，但是在使用数据的时候，过于紧密的维度关系并不利于数据的实际应用，因此Pandas并没过分关注数据的结构表达，而是关注数据的应用表达，应用表达体现在数据与索引的关系</p><h3 id="维度-数据间关系-、数据与索引间关系"><a href="#维度-数据间关系-、数据与索引间关系" class="headerlink" title="维度(数据间关系)、数据与索引间关系"></a>维度(数据间关系)、数据与索引间关系</h3><p>Series与DataFrame都非常明确有效的索引，通过索引可以对数据进行相关分析与提取，通过数据与索引的关系可以使得数据的应用非常方便</p><h1 id="Series类型"><a href="#Series类型" class="headerlink" title="Series类型"></a>Series类型</h1><ul><li>Series是一维带“标签”数组</li><li>Pandas的一维数据类型</li><li>Series基本操作类似ndarray和字典，根据索引对齐，不根据维度</li><li>由一组数据及与之相关的数据索引组成</li></ul><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">index_0</span>--&gt;</span> data_a<br><span class="hljs-function"><span class="hljs-title">index_1</span> --&gt;</span> data_b<br><span class="hljs-function"><span class="hljs-title">index_2</span> --&gt;</span> data_c<br><span class="hljs-function"><span class="hljs-title">index_3</span> --&gt;</span> data_d<br>索引  数据<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>a = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>])<br>a<br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">9</span><span class="hljs-comment"># 自动索引</span><br><span class="hljs-number">1</span><span class="hljs-number">8</span><br><span class="hljs-number">2</span><span class="hljs-number">7</span><br><span class="hljs-number">3</span><span class="hljs-number">6</span><br>dtype: int64 <span class="hljs-comment"># &lt;--NumPy中数据类型</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],index=[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<span class="hljs-comment"># 作为第二个参数，可以省略index=</span><br>b<br><br>Out:<br>a<span class="hljs-number">9</span><span class="hljs-comment"># 自定义索引</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>d<span class="hljs-number">6</span><br>dtype: int64<br></code></pre></td></tr></table></figure><h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>可以由如下类型创建</p><p><strong>Python列表    标量值    Python字典    ndarray    其他函数</strong></p><h3 id="标量类型创建"><a href="#标量类型创建" class="headerlink" title="标量类型创建"></a>标量类型创建</h3><p>index表达Series类型的尺寸</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>s = pd.Series(<span class="hljs-number">25</span>,index=[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>])<span class="hljs-comment"># 此处不能省略index=</span><br>s<br><br>Out:<br>a<span class="hljs-number">25</span><br>b<span class="hljs-number">25</span><br>c<span class="hljs-number">25</span><br>dtype: int64<br></code></pre></td></tr></table></figure><h3 id="字典类型创建"><a href="#字典类型创建" class="headerlink" title="字典类型创建"></a>字典类型创建</h3><p>键值对中“键”是索引，index从字典中进行选择操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>d = pd.Series(&#123;<span class="hljs-string">&#x27;a&#x27;</span>:<span class="hljs-number">9</span>,<span class="hljs-string">&#x27;b&#x27;</span>:<span class="hljs-number">8</span>,<span class="hljs-string">&#x27;c&#x27;</span>:<span class="hljs-number">7</span>&#125;)<br>d<br><br>Out:<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>dtype: int64<br>    <br>In :e = pd.Series(&#123;<span class="hljs-string">&#x27;a&#x27;</span>:<span class="hljs-number">9</span>,<span class="hljs-string">&#x27;b&#x27;</span>:<span class="hljs-number">8</span>,<span class="hljs-string">&#x27;c&#x27;</span>:<span class="hljs-number">7</span>&#125;,index=[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>    e<br>    <br>Out:<br>c<span class="hljs-number">7.0</span><br>a<span class="hljs-number">9.0</span><br>b<span class="hljs-number">8.0</span><br>dNaN<br>dtype: float64<br></code></pre></td></tr></table></figure><h3 id="ndarray创建"><a href="#ndarray创建" class="headerlink" title="ndarray创建"></a>ndarray创建</h3><p>Python列表的话index与列表元素个数一致</p><p>ndarray中索引和数据都可以通过ndarray类型创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>n = pd.Series(np.arange(<span class="hljs-number">5</span>))<br>n<br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">0</span><br><span class="hljs-number">1</span><span class="hljs-number">1</span><br><span class="hljs-number">2</span><span class="hljs-number">2</span><br><span class="hljs-number">3</span><span class="hljs-number">3</span><br><span class="hljs-number">4</span><span class="hljs-number">4</span><br>dtype: int32<br>    <br>    <br>In :m = pd.Series(np.arange(<span class="hljs-number">5</span>),index=np.arange(<span class="hljs-number">9</span>,<span class="hljs-number">4</span>,-<span class="hljs-number">1</span>))<br>    m<br>    <br>Out:<br><span class="hljs-number">9</span><span class="hljs-number">0</span><br><span class="hljs-number">8</span><span class="hljs-number">1</span><br><span class="hljs-number">7</span><span class="hljs-number">2</span><br><span class="hljs-number">6</span><span class="hljs-number">3</span><br><span class="hljs-number">5</span><span class="hljs-number">4</span><br>dtype: int32<br></code></pre></td></tr></table></figure><h3 id="其他函数创建"><a href="#其他函数创建" class="headerlink" title="其他函数创建"></a>其他函数创建</h3><p>range()函数等</p><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p>Series类型包括index和values两部分，操作类似ndarray类型与Python字典类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]:<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>In [<span class="hljs-number">2</span>]:b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>In [<span class="hljs-number">3</span>]:b<br>Out[<span class="hljs-number">3</span>]:<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>d<span class="hljs-number">6</span><br>dtype: int64<br><br>In [<span class="hljs-number">4</span>]:b.index<span class="hljs-comment"># 获得索引</span><br>Out[<span class="hljs-number">4</span>]:<br>Index([<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b,&#x27;</span>c<span class="hljs-string">&#x27;,&#x27;</span>d<span class="hljs-string">&#x27;],dtype=&#x27;</span><span class="hljs-built_in">object</span><span class="hljs-string">&#x27;)</span><br><span class="hljs-string"></span><br><span class="hljs-string">In [5]:b.values# 获得数据</span><br><span class="hljs-string">Out[5]:array([9,8,7,6],dtype=int64)</span><br><span class="hljs-string">       </span><br><span class="hljs-string">In [6]:b[&#x27;</span><span class="hljs-string">b&#x27;]# 自定义索引</span><br><span class="hljs-string">Out[6]:8</span><br><span class="hljs-string"></span><br><span class="hljs-string">In [7]:b[1]# 自动索引并存</span><br><span class="hljs-string">Out[7]:8</span><br><span class="hljs-string"></span><br><span class="hljs-string">In [8]:b[[&#x27;</span>c<span class="hljs-string">&#x27;,&#x27;</span>d<span class="hljs-string">&#x27;,0]]</span><br><span class="hljs-string">Out[8]:</span><br><span class="hljs-string">c7.0</span><br><span class="hljs-string">d6.0</span><br><span class="hljs-string">0NaN# 两套索引并存，但不能混用</span><br><span class="hljs-string">dtype: float64</span><br><span class="hljs-string"></span><br><span class="hljs-string">In [9]:b[[&#x27;</span>c<span class="hljs-string">&#x27;,&#x27;</span>d<span class="hljs-string">&#x27;,&#x27;</span>a<span class="hljs-string">&#x27;]]</span><br><span class="hljs-string">Out[9]:</span><br><span class="hljs-string">c7</span><br><span class="hljs-string">d6</span><br><span class="hljs-string">a9</span><br><span class="hljs-string">dtype: int64</span><br></code></pre></td></tr></table></figure><h3 id="ndarray类似方法"><a href="#ndarray类似方法" class="headerlink" title="ndarray类似方法"></a>ndarray类似方法</h3><ul><li>索引方法相同，采用[]</li><li>NumPy中运算和操作可用于Series类型</li><li>可以通过自定义索引的列表进行切片</li><li>可以通过自动索引进行切片，如果存在自定义索引，则一同被切片</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]:<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>In [<span class="hljs-number">2</span>]:b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>In [<span class="hljs-number">3</span>]:b<br>Out[<span class="hljs-number">3</span>]:<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>d<span class="hljs-number">6</span><br>dtype: int64<br><br>In [<span class="hljs-number">4</span>]:b[<span class="hljs-number">3</span>]<span class="hljs-comment"># 一个值</span><br>Out[<span class="hljs-number">4</span>]:<span class="hljs-number">6</span><br><br>In [<span class="hljs-number">5</span>]:b[:<span class="hljs-number">3</span>]<span class="hljs-comment"># series类型</span><br>Out[<span class="hljs-number">5</span>]:<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>dtype: int64<br><br>In [<span class="hljs-number">6</span>]:b[b&gt;b.median()]<br>Out[<span class="hljs-number">6</span>]:<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>dtype: int64<br><br>In [<span class="hljs-number">7</span>]:np.exp(b)<br>Out[<span class="hljs-number">7</span>]:<br>a<span class="hljs-number">8103.0839288</span><br>b<span class="hljs-number">2980.957987</span><br>c<span class="hljs-number">1096.633158</span><br>d <span class="hljs-number">403.428793</span><br>dtype: float64<br></code></pre></td></tr></table></figure><h3 id="Python字典类似方法"><a href="#Python字典类似方法" class="headerlink" title="Python字典类似方法"></a>Python字典类似方法</h3><ul><li>通过自定义索引访问</li><li>保留字in操作</li><li>使用.get()方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]:<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>In [<span class="hljs-number">2</span>]:b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br><br>In [<span class="hljs-number">3</span>]:b[<span class="hljs-string">&#x27;b&#x27;</span>]<br>Out[<span class="hljs-number">3</span>]:<span class="hljs-number">8</span><br><br>In [<span class="hljs-number">4</span>]:<span class="hljs-string">&#x27;c&#x27;</span> <span class="hljs-keyword">in</span> b<br>Out[<span class="hljs-number">4</span>]:<span class="hljs-literal">True</span><br><br>In [<span class="hljs-number">5</span>]:<span class="hljs-number">0</span> <span class="hljs-keyword">in</span> b<span class="hljs-comment"># 不会判断自动索引</span><br>Out[<span class="hljs-number">5</span>]:<span class="hljs-literal">False</span><br><br>In [<span class="hljs-number">6</span>]:b.get(<span class="hljs-string">&#x27;f&#x27;</span>,<span class="hljs-number">100</span>)<br>Out[<span class="hljs-number">6</span>]:<span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><h2 id="对齐操作"><a href="#对齐操作" class="headerlink" title="对齐操作"></a>对齐操作</h2><p>Series类型在运算中会自动对齐不同索引的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]:<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>In [<span class="hljs-number">2</span>]:a = pd.Series([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-string">&#x27;e&#x27;</span>])<br><br>In [<span class="hljs-number">3</span>]:b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br><br>In [<span class="hljs-number">4</span>]:a+b<br>Out[<span class="hljs-number">4</span>]:<br>aNaN<br>bNaN<br>c<span class="hljs-number">8.0</span><br>d<span class="hljs-number">8.0</span><br>eNaN<br>dtype: float64<br></code></pre></td></tr></table></figure><h2 id="Name属性"><a href="#Name属性" class="headerlink" title="Name属性"></a>Name属性</h2><p>Series对象和索引都可以有一个名字，存储在属性.name中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>b.name<br>b.name = <span class="hljs-string">&#x27;Series对象&#x27;</span><br>b.index.name = <span class="hljs-string">&#x27;索引列&#x27;</span><br>b<br><br>Out:<br>索引列<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>d<span class="hljs-number">6</span><br>Name: Series对象,dtype: int64<br></code></pre></td></tr></table></figure><h2 id="类型修改"><a href="#类型修改" class="headerlink" title="类型修改"></a>类型修改</h2><p>Series对象可以随时修改并即刻生效</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>b = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>b[<span class="hljs-string">&#x27;a&#x27;</span>] = <span class="hljs-number">15</span><br>b.name = <span class="hljs-string">&quot;Series&quot;</span><br>b<br><br>Out:<br>a<span class="hljs-number">15</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>d<span class="hljs-number">6</span><br>Name: Series,dtype: int64<br><br>In :<br>b.name = <span class="hljs-string">&quot;New Series&quot;</span><br>b[<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>] = <span class="hljs-number">20</span><br>b<br><br>Out:<br>a<span class="hljs-number">15</span><br>b<span class="hljs-number">20</span><br>c<span class="hljs-number">20</span><br>d<span class="hljs-number">6</span><br>Name: New Series,dtype: int64<br></code></pre></td></tr></table></figure><h1 id="DataFrame类型"><a href="#DataFrame类型" class="headerlink" title="DataFrame类型"></a>DataFrame类型</h1><ul><li>Data是二维带”标签”数组</li><li>Pandas的二维数据类型，由共用相同索引的一组列组成</li><li>DataFrame是一个表格型的数据类型，每列值类型可以不同</li><li>DataFrame既有行索引、也有列索引，基本操作类似Series</li><li>DataFrame常用于表达二维数据，但可以表达多维数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">index_0 --&gt; data_adata_1data_w(column)(axis=<span class="hljs-number">1</span>)<br>index_1 --&gt; data_bdata_2data_x<br>index_2 --&gt; data_cdata_3......   data_y<br>index_3 --&gt; data_ddata_4data_z<br>索引(index)多列数据<br>(axis=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h2 id="创建-1"><a href="#创建-1" class="headerlink" title="创建"></a>创建</h2><p>可以由如下类型创建</p><ul><li>二维ndarray对象</li><li>由一维ndarray、列表、字典、元组或Series构成的字典</li><li>Series类型</li><li>其他的DataFrame类型</li></ul><h3 id="二维ndarry对象创建"><a href="#二维ndarry对象创建" class="headerlink" title="二维ndarry对象创建"></a>二维ndarry对象创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>d = pd.DataFrame(np.arange(<span class="hljs-number">10</span>).reshape(<span class="hljs-number">2</span>,<span class="hljs-number">5</span>))<br>d<br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><span class="hljs-number">4</span><span class="hljs-comment"># 自动列索引</span><br><span class="hljs-number">0</span><span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><span class="hljs-number">4</span><br><span class="hljs-number">1</span><span class="hljs-number">5</span><span class="hljs-number">6</span><span class="hljs-number">7</span><span class="hljs-number">8</span><span class="hljs-number">9</span><br><span class="hljs-comment"># 自动行索引</span><br></code></pre></td></tr></table></figure><h3 id="一维ndarray对象字典创建"><a href="#一维ndarray对象字典创建" class="headerlink" title="一维ndarray对象字典创建"></a>一维ndarray对象字典创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dt = &#123;<span class="hljs-string">&#x27;one&#x27;</span>:pd.Series([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],index=[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>]),<br>  <span class="hljs-string">&#x27;two&#x27;</span>:pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],index=[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])&#125;<br>d = pd.DataFrame(dt)<br>d<br><br>Out:<br>onetwo<span class="hljs-comment"># 自动列索引</span><br>a<span class="hljs-number">1.0</span>  <span class="hljs-number">9</span><br>b<span class="hljs-number">2.0</span>  <span class="hljs-number">8</span><br>c<span class="hljs-number">3.0</span>  <span class="hljs-number">7</span><br>dNaN  <span class="hljs-number">6</span><br><span class="hljs-comment"># 自动行索引</span><br><br>In :<br>pd.DataFrame(dt,index=[<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>],columns=[<span class="hljs-string">&#x27;two&#x27;</span>,<span class="hljs-string">&#x27;three&#x27;</span>])<br><br>Out:<br>twothree<br>b<span class="hljs-number">8</span> NaN<br>c<span class="hljs-number">7</span> NaN<br>d<span class="hljs-number">6</span> NaN<br></code></pre></td></tr></table></figure><h3 id="列表类型的字典创建"><a href="#列表类型的字典创建" class="headerlink" title="列表类型的字典创建"></a>列表类型的字典创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dl = &#123;<span class="hljs-string">&#x27;one&#x27;</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<span class="hljs-string">&#x27;two&#x27;</span>:[<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>]&#125;<br>d = pd.DataFrame(dl,index=[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>d<br><br>Out:<br>onetwo<br>a<span class="hljs-number">1</span><span class="hljs-number">9</span><br>b<span class="hljs-number">2</span><span class="hljs-number">8</span><br>c<span class="hljs-number">3</span><span class="hljs-number">7</span><br>d<span class="hljs-number">4</span><span class="hljs-number">6</span><br></code></pre></td></tr></table></figure><h2 id="举例-查询索引等"><a href="#举例-查询索引等" class="headerlink" title="举例(查询索引等)"></a>举例(查询索引等)</h2><p><style>.iytsfpcrugyo{zoom:67%;}</style><img src="/2024/05/17/20240517_Pandas/image-20240517183052878.png" class="iytsfpcrugyo" alt="image-20240517183052878"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dl = &#123;<span class="hljs-string">&#x27;城市&#x27;</span>:[<span class="hljs-string">&#x27;北京&#x27;</span>,<span class="hljs-string">&#x27;上海&#x27;</span>,<span class="hljs-string">&#x27;广州&#x27;</span>,<span class="hljs-string">&#x27;深圳&#x27;</span>,<span class="hljs-string">&#x27;沈阳&#x27;</span>]，<br>  <span class="hljs-string">&#x27;环比&#x27;</span>:[<span class="hljs-number">101.5</span>, <span class="hljs-number">101.2</span>, <span class="hljs-number">101.3</span>, <span class="hljs-number">102.0</span>, <span class="hljs-number">100.1</span>],<br>  <span class="hljs-string">&#x27;同比&#x27;</span>:[<span class="hljs-number">120.7</span>, <span class="hljs-number">127.3</span>, <span class="hljs-number">119.4</span>, <span class="hljs-number">140.9</span>, <span class="hljs-number">101.4</span>],<br>  <span class="hljs-string">&#x27;定基&#x27;</span>:[<span class="hljs-number">121.4</span>, <span class="hljs-number">127.8</span>, <span class="hljs-number">120.0</span>, <span class="hljs-number">145.5</span>, <span class="hljs-number">101.6</span>]&#125;<br>d = pd.DataFrame(dl,index=[<span class="hljs-string">&#x27;c1&#x27;</span>,<span class="hljs-string">&#x27;c2&#x27;</span>,<span class="hljs-string">&#x27;c3&#x27;</span>,<span class="hljs-string">&#x27;c4&#x27;</span>,<span class="hljs-string">&#x27;c5&#x27;</span>])<br>d<br><br>Out:<br>同比城市定基环比<br>c1<span class="hljs-number">120.7</span> 北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br>c2  <span class="hljs-number">127.3</span> 上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c3  <span class="hljs-number">119.4</span> 广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c4  <span class="hljs-number">140.9</span> 深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c5  <span class="hljs-number">101.4</span> 沈阳  <span class="hljs-number">101.6</span> <span class="hljs-number">100.1</span><br><br>In :d.index<br>Out:Index([<span class="hljs-string">&#x27;c1&#x27;</span>,<span class="hljs-string">&#x27;c2&#x27;</span>,<span class="hljs-string">&#x27;c3&#x27;</span>,<span class="hljs-string">&#x27;c4&#x27;</span>,<span class="hljs-string">&#x27;c5&#x27;</span>],dtype=<span class="hljs-string">&#x27;object&#x27;</span>)<br>    <br>In :d.colums<br>Out:Index([<span class="hljs-string">&#x27;同比&#x27;</span>,<span class="hljs-string">&#x27;城市&#x27;</span>,<span class="hljs-string">&#x27;定基&#x27;</span>,<span class="hljs-string">&#x27;环比&#x27;</span>],dtype=<span class="hljs-string">&#x27;object&#x27;</span>)<br><br>In :d.values<br>Out:<br>array([[<span class="hljs-number">120.7</span>,北京,<span class="hljs-number">121.4</span>,<span class="hljs-number">101.5</span>],<br>       [<span class="hljs-number">127.3</span>,上海,<span class="hljs-number">127.8</span>,<span class="hljs-number">101.2</span>],<br>       [<span class="hljs-number">119.4</span>,广州,<span class="hljs-number">120.0</span>,<span class="hljs-number">101.3</span>],<br>       [<span class="hljs-number">140.9</span>,深圳,<span class="hljs-number">145.5</span>,<span class="hljs-number">102.0</span>],<br>       [<span class="hljs-number">101.4</span>,沈阳,<span class="hljs-number">101.6</span>,<span class="hljs-number">100.1</span>]],dtype=<span class="hljs-built_in">object</span>)<br><br><span class="hljs-comment">###字典之间各元素是无序的，因此生成d中列顺序不一定和字典中相同</span><br><br>In :d[<span class="hljs-string">&#x27;同比&#x27;</span>]<br>Out:<br>c1<span class="hljs-number">120.7</span><br>c2  <span class="hljs-number">127.3</span><br>c3  <span class="hljs-number">119.4</span><br>c4  <span class="hljs-number">140.9</span><br>c5  <span class="hljs-number">101.4</span><br>Name:同比,dtype: float64<br>        <br>In :d.ix[<span class="hljs-string">&#x27;c2&#x27;</span>]<br>Out:<br>同比<span class="hljs-number">127.8</span><br>城市上海<br>定基<span class="hljs-number">127.8</span><br>环比<span class="hljs-number">101.2</span><br>Name:c2,dtype:<span class="hljs-built_in">object</span><br><br>In :d[<span class="hljs-string">&#x27;同比&#x27;</span>][<span class="hljs-string">&#x27;c2&#x27;</span>]<br>Out:<span class="hljs-number">127.3</span><br></code></pre></td></tr></table></figure><h1 id="数据类型操作"><a href="#数据类型操作" class="headerlink" title="数据类型操作"></a>数据类型操作</h1><h2 id="如何改变Series和DataFrame对象"><a href="#如何改变Series和DataFrame对象" class="headerlink" title="如何改变Series和DataFrame对象"></a>如何改变Series和DataFrame对象</h2><p>改变指的是增加或重排Series或DataFrame的索引，或者删掉其中的部分值</p><h3 id="索引类型及其常用方法"><a href="#索引类型及其常用方法" class="headerlink" title="索引类型及其常用方法"></a>索引类型及其常用方法</h3><p>Series和DataFrame的索引是Index类型</p><p>Index对象是不可修改类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">In :d.index<br>Out:Index([<span class="hljs-string">&#x27;c5&#x27;</span>,<span class="hljs-string">&#x27;c4&#x27;</span>,<span class="hljs-string">&#x27;c3&#x27;</span>,<span class="hljs-string">&#x27;c2&#x27;</span>,<span class="hljs-string">&#x27;c1&#x27;</span>],dtype=<span class="hljs-string">&#x27;object&#x27;</span>)<br><br>In :d.columns<br>Out:Index([<span class="hljs-string">&#x27;城市&#x27;</span>,<span class="hljs-string">&#x27;同比&#x27;</span>,<span class="hljs-string">&#x27;环比&#x27;</span>,<span class="hljs-string">&#x27;定基&#x27;</span>],dtype=<span class="hljs-string">&#x27;object&#x27;</span>)<br></code></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.append(idx)</td><td>连接另一个Index对象，产生新的Index对象</td></tr><tr><td>.diff(idx)</td><td>计算差集，产生新的Index对象</td></tr><tr><td>.intersection(idx)</td><td>计算交集</td></tr><tr><td>.union(idx)</td><td>计算并集</td></tr><tr><td>.delete(loc)</td><td>删除loc位置处的元素</td></tr><tr><td>.insert(loc,e)</td><td>在loc位置增加一个元素e</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">In :d<br>Out:<br>同比城市定基环比<br>c1<span class="hljs-number">120.7</span> 北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br>c2  <span class="hljs-number">127.3</span> 上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c3  <span class="hljs-number">119.4</span> 广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c4  <span class="hljs-number">140.9</span> 深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c5  <span class="hljs-number">101.4</span> 沈阳  <span class="hljs-number">101.6</span> <span class="hljs-number">100.1</span><br><br>In :<br>nc = d.columns.delete(<span class="hljs-number">2</span>)<br>ni = d.index.insert(<span class="hljs-number">5</span>,<span class="hljs-string">&#x27;c6&#x27;</span>)<br>nd = d.reindex(index=ni,columns=nc,method=<span class="hljs-string">&#x27;ffill&#x27;</span>)<br>nd<br><br>Out:<br>同比城市环比<br>c1<span class="hljs-number">120.7</span> 北京 <span class="hljs-number">101.5</span><br>c2  <span class="hljs-number">127.3</span> 上海 <span class="hljs-number">101.2</span><br>c3  <span class="hljs-number">119.4</span> 广州 <span class="hljs-number">101.3</span><br>c4  <span class="hljs-number">140.9</span> 深圳 <span class="hljs-number">102.0</span><br>c5  <span class="hljs-number">101.4</span> 沈阳 <span class="hljs-number">100.1</span><br>c6  <span class="hljs-number">101.4</span> 沈阳 <span class="hljs-number">100.1</span>  <br></code></pre></td></tr></table></figure><h3 id="增加或重排：重新索引"><a href="#增加或重排：重新索引" class="headerlink" title="增加或重排：重新索引"></a>增加或重排：重新索引</h3><p>.reindex()能够改变或重排Series和DataFrame索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dl = &#123;<span class="hljs-string">&#x27;城市&#x27;</span>:[<span class="hljs-string">&#x27;北京&#x27;</span>,<span class="hljs-string">&#x27;上海&#x27;</span>,<span class="hljs-string">&#x27;广州&#x27;</span>,<span class="hljs-string">&#x27;深圳&#x27;</span>,<span class="hljs-string">&#x27;沈阳&#x27;</span>]，<br>  <span class="hljs-string">&#x27;环比&#x27;</span>:[<span class="hljs-number">101.5</span>, <span class="hljs-number">101.2</span>, <span class="hljs-number">101.3</span>, <span class="hljs-number">102.0</span>, <span class="hljs-number">100.1</span>],<br>  <span class="hljs-string">&#x27;同比&#x27;</span>:[<span class="hljs-number">120.7</span>, <span class="hljs-number">127.3</span>, <span class="hljs-number">119.4</span>, <span class="hljs-number">140.9</span>, <span class="hljs-number">101.4</span>],<br>  <span class="hljs-string">&#x27;定基&#x27;</span>:[<span class="hljs-number">121.4</span>, <span class="hljs-number">127.8</span>, <span class="hljs-number">120.0</span>, <span class="hljs-number">145.5</span>, <span class="hljs-number">101.6</span>]&#125;<br>d = pd.DataFrame(dl,index=[<span class="hljs-string">&#x27;c1&#x27;</span>,<span class="hljs-string">&#x27;c2&#x27;</span>,<span class="hljs-string">&#x27;c3&#x27;</span>,<span class="hljs-string">&#x27;c4&#x27;</span>,<span class="hljs-string">&#x27;c5&#x27;</span>])<br>d<br><br>Out:<br>同比城市定基环比<br>c1<span class="hljs-number">120.7</span> 北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br>c2  <span class="hljs-number">127.3</span> 上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c3  <span class="hljs-number">119.4</span> 广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c4  <span class="hljs-number">140.9</span> 深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c5  <span class="hljs-number">101.4</span> 沈阳  <span class="hljs-number">101.6</span> <span class="hljs-number">100.1</span><br><br>In :<br>d = d.reindex(index=[<span class="hljs-string">&#x27;c5&#x27;</span>,<span class="hljs-string">&#x27;c4&#x27;</span>,<span class="hljs-string">&#x27;c3&#x27;</span>,<span class="hljs-string">&#x27;c2&#x27;</span>,<span class="hljs-string">&#x27;c1&#x27;</span>])<br>d<br><br>Out:<br>同比城市定基环比<br>c5  <span class="hljs-number">101.4</span> 沈阳  <span class="hljs-number">101.6</span> <span class="hljs-number">100.1</span><br>c4  <span class="hljs-number">140.9</span> 深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c3  <span class="hljs-number">119.4</span> 广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c2  <span class="hljs-number">127.3</span> 上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c1<span class="hljs-number">120.7</span> 北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br><br>In :<br>d = d.reindex(colums=[<span class="hljs-string">&#x27;城市&#x27;</span>,<span class="hljs-string">&#x27;同比&#x27;</span>,<span class="hljs-string">&#x27;环比&#x27;</span>,<span class="hljs-string">&#x27;定基&#x27;</span>])<br>d<br><br>Out:<br>城市同比环比定基<br>c5沈阳  <span class="hljs-number">101.4</span> <span class="hljs-number">100.1</span> <span class="hljs-number">101.6</span><br>...<br>c1北京  <span class="hljs-number">120.7</span> <span class="hljs-number">101.5</span> <span class="hljs-number">121.4</span><br></code></pre></td></tr></table></figure><p>.reindex(index=None,columns=None,…)的参数</p><div class="table-container"><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>index,columns</td><td>新的行列自定义索引</td></tr><tr><td>fill_value</td><td>重新索引中，用于填充缺失位置的值</td></tr><tr><td>method</td><td>填充方法，ffill当前值向前填充，bfill向后填充</td></tr><tr><td>limit</td><td>最大填充量</td></tr><tr><td>copy</td><td>默认True，生成新的对象，False时，新旧相等不复制</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br>newc = d.columns.insert(<span class="hljs-number">4</span>,<span class="hljs-string">&#x27;新增&#x27;</span>)<br>newd = d.reindex(colums=newc,fill_value=<span class="hljs-number">200</span>)<br>newd<br><br>Out:<br>城市同比环比定基新增<br>c5沈阳  <span class="hljs-number">101.4</span> <span class="hljs-number">100.1</span> <span class="hljs-number">101.6</span> <span class="hljs-number">200</span><br>...<br>c1北京  <span class="hljs-number">120.7</span> <span class="hljs-number">101.5</span> <span class="hljs-number">121.4</span> <span class="hljs-number">200</span><br></code></pre></td></tr></table></figure><h3 id="删除：drop"><a href="#删除：drop" class="headerlink" title="删除：drop"></a>删除：drop</h3><p>.drop()能够删除Series和DataFrame指定行或列索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">1</span>]:<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>In [<span class="hljs-number">2</span>]:a = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>In [<span class="hljs-number">3</span>]:a<br>Out[<span class="hljs-number">3</span>]:<br>a<span class="hljs-number">9</span><br>b<span class="hljs-number">8</span><br>c<span class="hljs-number">7</span><br>d<span class="hljs-number">6</span><br>dtype: int64<br><br>In :a.drop([<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>])<br>Out:<br>a<span class="hljs-number">9</span><br>d<span class="hljs-number">6</span><br>dtype:int64<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">In :d<br>Out:<br>同比城市定基环比<br>c5  <span class="hljs-number">101.4</span> 沈阳  <span class="hljs-number">101.6</span> <span class="hljs-number">100.1</span><br>c4  <span class="hljs-number">140.9</span> 深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c3  <span class="hljs-number">119.4</span> 广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c2  <span class="hljs-number">127.3</span> 上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c1<span class="hljs-number">120.7</span> 北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br><br>In :d.drop(<span class="hljs-string">&#x27;c5&#x27;</span>)<span class="hljs-comment"># 默认0轴</span><br>Out:<br>同比城市定基环比<br>c4  <span class="hljs-number">140.9</span> 深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c3  <span class="hljs-number">119.4</span> 广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c2  <span class="hljs-number">127.3</span> 上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c1<span class="hljs-number">120.7</span> 北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br><br>In :d.drop(<span class="hljs-string">&#x27;同比&#x27;</span>,axis=<span class="hljs-number">1</span>)<br>Out:<br>城市定基环比<br>c4  深圳  <span class="hljs-number">145.5</span> <span class="hljs-number">102.0</span><br>c3  广州  <span class="hljs-number">120.0</span> <span class="hljs-number">101.3</span><br>c2  上海  <span class="hljs-number">127.8</span> <span class="hljs-number">101.2</span><br>c1北京  <span class="hljs-number">121.4</span> <span class="hljs-number">101.5</span><br></code></pre></td></tr></table></figure><h1 id="数据类型运算"><a href="#数据类型运算" class="headerlink" title="数据类型运算"></a>数据类型运算</h1><h2 id="算数运算法则"><a href="#算数运算法则" class="headerlink" title="算数运算法则"></a>算数运算法则</h2><ul><li>算数运算根据行列索引，补齐后运算，运算默认产生浮点数</li><li>补齐时缺项填充NaN(空值)</li><li>二维和一维、一维和零维间为广播运算</li><li>采用+-*/符号进行的二元运算产生新的对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = pd.DataFrame(np.arange(<span class="hljs-number">12</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br>a<br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><br><span class="hljs-number">0</span><span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><br><span class="hljs-number">1</span><span class="hljs-number">4</span><span class="hljs-number">5</span><span class="hljs-number">6</span><span class="hljs-number">7</span><br><span class="hljs-number">2</span><span class="hljs-number">8</span><span class="hljs-number">9</span><span class="hljs-number">10</span><span class="hljs-number">11</span><br><br>In :<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>))<br>b<br><br>Out:<br><span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><span class="hljs-number">4</span><br><span class="hljs-number">0</span><span class="hljs-number">0</span><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><span class="hljs-number">4</span><br><span class="hljs-number">1</span><span class="hljs-number">5</span><span class="hljs-number">6</span><span class="hljs-number">7</span><span class="hljs-number">8</span><span class="hljs-number">9</span><br><span class="hljs-number">2</span><span class="hljs-number">10</span><span class="hljs-number">11</span><span class="hljs-number">12</span><span class="hljs-number">13</span><span class="hljs-number">14</span><br><span class="hljs-number">3</span><span class="hljs-number">15</span><span class="hljs-number">16</span><span class="hljs-number">17</span><span class="hljs-number">18</span><span class="hljs-number">19</span><br><br>In :a+b<br>Out:<br><span class="hljs-number">0</span> <span class="hljs-number">1</span>  <span class="hljs-number">2</span>   <span class="hljs-number">3</span><span class="hljs-number">4</span><br><span class="hljs-number">0</span><span class="hljs-number">0.0</span> <span class="hljs-number">2.0</span>  <span class="hljs-number">4.0</span>  <span class="hljs-number">6.0</span>  NaN<br><span class="hljs-number">1</span><span class="hljs-number">9.0</span> <span class="hljs-number">11.0</span>  <span class="hljs-number">13.0</span> <span class="hljs-number">15.0</span>NaN<br><span class="hljs-number">2</span><span class="hljs-number">18.0</span> <span class="hljs-number">20.0</span> <span class="hljs-number">22.0</span> <span class="hljs-number">24.0</span>NaN<br><span class="hljs-number">3</span>NaN NaN  NaN  NaNNaN<br><br>In :a*b<br>Out:<span class="hljs-comment"># 自动补齐，缺项补NaN</span><br><span class="hljs-number">0</span> <span class="hljs-number">1</span>  <span class="hljs-number">2</span>    <span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-number">0</span><span class="hljs-number">0.0</span> <span class="hljs-number">1.0</span>  <span class="hljs-number">4.0</span>   <span class="hljs-number">9.0</span>   NaN<br><span class="hljs-number">1</span><span class="hljs-number">20.0</span> <span class="hljs-number">30.0</span> <span class="hljs-number">42.0</span>  <span class="hljs-number">56.0</span>  NaN<br><span class="hljs-number">2</span>   <span class="hljs-number">80.0</span> <span class="hljs-number">99.0</span> <span class="hljs-number">120.0</span> <span class="hljs-number">143.0</span>  NaN<br><span class="hljs-number">3</span>NaN NaN  NaN   NaN  NaN<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 不同维度间运算为广播运算，一维Series默认在轴1参与运算</span><br>In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>))<br><span class="hljs-built_in">print</span>(b)<br>c = pd.Series(np.arange(<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(c)<br><span class="hljs-built_in">print</span>(c-<span class="hljs-number">10</span>)<br><span class="hljs-built_in">print</span>(b-c)<br><br>Out:<br>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br><span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br><span class="hljs-number">1</span>   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br><span class="hljs-number">2</span>  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br><span class="hljs-number">3</span>  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br><br><span class="hljs-number">0</span>    <span class="hljs-number">0</span><br><span class="hljs-number">1</span>    <span class="hljs-number">1</span><br><span class="hljs-number">2</span>    <span class="hljs-number">2</span><br><span class="hljs-number">3</span>    <span class="hljs-number">3</span><br>dtype: int32<br><br><span class="hljs-number">0</span>   -<span class="hljs-number">10</span><br><span class="hljs-number">1</span>    -<span class="hljs-number">9</span><br><span class="hljs-number">2</span>    -<span class="hljs-number">8</span><br><span class="hljs-number">3</span>    -<span class="hljs-number">7</span><br>dtype: int32<br><br>      <span class="hljs-number">0</span>     <span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br><span class="hljs-number">0</span>   <span class="hljs-number">0.0</span>   <span class="hljs-number">0.0</span>   <span class="hljs-number">0.0</span>   <span class="hljs-number">0.0</span> NaN<br><span class="hljs-number">1</span>   <span class="hljs-number">5.0</span>   <span class="hljs-number">5.0</span>   <span class="hljs-number">5.0</span>   <span class="hljs-number">5.0</span> NaN<br><span class="hljs-number">2</span>  <span class="hljs-number">10.0</span>  <span class="hljs-number">10.0</span>  <span class="hljs-number">10.0</span>  <span class="hljs-number">10.0</span> NaN<br><span class="hljs-number">3</span>  <span class="hljs-number">15.0</span>  <span class="hljs-number">15.0</span>  <span class="hljs-number">15.0</span>  <span class="hljs-number">15.0</span> NaN<br></code></pre></td></tr></table></figure><p><strong>方法形式运算</strong></p><p>好处：增加可选参数</p><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.add(d,**argws)</td><td>类型间加法运算，可选参数</td></tr><tr><td>.sub(d,**argws)</td><td>类型间减法运算，可选参数</td></tr><tr><td>.mul(d,**argws)</td><td>类型间乘法运算，可选参数</td></tr><tr><td>.div(d,**argws)</td><td>类型间除法运算，可选参数</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">In :b.add(a,fill_value = <span class="hljs-number">100</span>)<br>Out:<br><span class="hljs-number">0</span> <span class="hljs-number">1</span>  <span class="hljs-number">2</span>   <span class="hljs-number">3</span><span class="hljs-number">4</span><br><span class="hljs-number">0</span><span class="hljs-number">0.0</span> <span class="hljs-number">2.0</span>  <span class="hljs-number">4.0</span>  <span class="hljs-number">6.0</span>  <span class="hljs-number">104.0</span><br><span class="hljs-number">1</span><span class="hljs-number">9.0</span> <span class="hljs-number">11.0</span>  <span class="hljs-number">13.0</span> <span class="hljs-number">15.0</span><span class="hljs-number">109.0</span><br><span class="hljs-number">2</span><span class="hljs-number">18.0</span> <span class="hljs-number">20.0</span> <span class="hljs-number">22.0</span> <span class="hljs-number">24.0</span><span class="hljs-number">114.0</span><br><span class="hljs-number">3</span><span class="hljs-number">115.0</span> <span class="hljs-number">116.0</span> <span class="hljs-number">117.0</span> <span class="hljs-number">118.0</span> <span class="hljs-number">119.0</span><br><br>In :a.mul(b,fill_value = <span class="hljs-number">0</span>)<br>Out:<br><span class="hljs-number">0</span> <span class="hljs-number">1</span>  <span class="hljs-number">2</span>    <span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-number">0</span><span class="hljs-number">0.0</span> <span class="hljs-number">1.0</span>  <span class="hljs-number">4.0</span>   <span class="hljs-number">9.0</span>   <span class="hljs-number">0</span><br><span class="hljs-number">1</span><span class="hljs-number">20.0</span> <span class="hljs-number">30.0</span> <span class="hljs-number">42.0</span>  <span class="hljs-number">56.0</span>  <span class="hljs-number">0</span><br><span class="hljs-number">2</span>   <span class="hljs-number">80.0</span> <span class="hljs-number">99.0</span> <span class="hljs-number">120.0</span> <span class="hljs-number">143.0</span>  <span class="hljs-number">0</span><br><span class="hljs-number">3</span><span class="hljs-number">0</span> <span class="hljs-number">0</span>   <span class="hljs-number">0</span>     <span class="hljs-number">0</span>     <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用运算方法可以令一维Series参与轴0运算</span><br>In :b.sub(c,axis=<span class="hljs-number">0</span>)<br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br><span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br><span class="hljs-number">1</span>   <span class="hljs-number">4</span>   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span><br><span class="hljs-number">2</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span>  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span><br><span class="hljs-number">3</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span>  <span class="hljs-number">15</span>  <span class="hljs-number">16</span><br></code></pre></td></tr></table></figure><h2 id="比较运算法则"><a href="#比较运算法则" class="headerlink" title="比较运算法则"></a>比较运算法则</h2><ul><li>比较运算只能比较相同索引的元素，不进行补齐</li><li>二维和一维、一维和零维间为广播运算</li><li>采用&gt; &lt; &gt;= &lt;= == !=等符号进行的二元运算产生布尔对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 同纬度运算，尺寸一致</span><br>In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = pd.DataFrame(np.arange(<span class="hljs-number">12</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(a)<br>d = pd.DataFrame(np.arange(<span class="hljs-number">12</span>,<span class="hljs-number">0</span>,-<span class="hljs-number">1</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(d)<br><span class="hljs-built_in">print</span>(a&gt;d)<br><span class="hljs-built_in">print</span>(a==d)<br><br>Out:<br>   <span class="hljs-number">0</span>  <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span><br><span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span><br><span class="hljs-number">1</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span><br><span class="hljs-number">2</span>  <span class="hljs-number">8</span>  <span class="hljs-number">9</span>  <span class="hljs-number">10</span>  <span class="hljs-number">11</span><br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>  <span class="hljs-number">3</span><br><span class="hljs-number">0</span>  <span class="hljs-number">12</span>  <span class="hljs-number">11</span>  <span class="hljs-number">10</span>  <span class="hljs-number">9</span><br><span class="hljs-number">1</span>   <span class="hljs-number">8</span>   <span class="hljs-number">7</span>   <span class="hljs-number">6</span>  <span class="hljs-number">5</span><br><span class="hljs-number">2</span>   <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>  <span class="hljs-number">1</span><br>       <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span>      <span class="hljs-number">3</span><br><span class="hljs-number">0</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span><br><span class="hljs-number">1</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>   <span class="hljs-literal">True</span><br><span class="hljs-number">2</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span><br>       <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span>      <span class="hljs-number">3</span><br><span class="hljs-number">0</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span><br><span class="hljs-number">1</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>   <span class="hljs-literal">True</span>  <span class="hljs-literal">False</span><br><span class="hljs-number">2</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 不同维度，广播运算，默认在1轴</span><br>In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = pd.DataFrame(np.arange(<span class="hljs-number">12</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(a)<br>c = pd.Series(np.arange(<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(c)<br><span class="hljs-built_in">print</span>(a&gt;c)<br><span class="hljs-built_in">print</span>(c&gt;<span class="hljs-number">0</span>)<br><br>Out:<br>   <span class="hljs-number">0</span>  <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span><br><span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span><br><span class="hljs-number">1</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span><br><span class="hljs-number">2</span>  <span class="hljs-number">8</span>  <span class="hljs-number">9</span>  <span class="hljs-number">10</span>  <span class="hljs-number">11</span><br><br><span class="hljs-number">0</span>    <span class="hljs-number">0</span><br><span class="hljs-number">1</span>    <span class="hljs-number">1</span><br><span class="hljs-number">2</span>    <span class="hljs-number">2</span><br><span class="hljs-number">3</span>    <span class="hljs-number">3</span><br>dtype: int32<br>    <br>       <span class="hljs-number">0</span>      <span class="hljs-number">1</span>      <span class="hljs-number">2</span>      <span class="hljs-number">3</span><br><span class="hljs-number">0</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span>  <span class="hljs-literal">False</span><br><span class="hljs-number">1</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span><br><span class="hljs-number">2</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span>   <span class="hljs-literal">True</span><br><br><span class="hljs-number">0</span>    <span class="hljs-literal">False</span><br><span class="hljs-number">1</span>     <span class="hljs-literal">True</span><br><span class="hljs-number">2</span>     <span class="hljs-literal">True</span><br><span class="hljs-number">3</span>     <span class="hljs-literal">True</span><br>dtype: <span class="hljs-built_in">bool</span><br></code></pre></td></tr></table></figure><h1 id="数据的排序"><a href="#数据的排序" class="headerlink" title="数据的排序"></a>数据的排序</h1><p>一组数据表达一个或多个含义，通过<strong>摘要</strong>，我们<strong>有损地提取数据特征</strong>，获得：</p><ul><li><p>基本统计（含排序）</p></li><li><p>分布/累计统计</p></li><li><p>数据特征</p><p>相关性、周期性等</p></li><li><p>数据挖掘（形成知识）</p></li></ul><h2 id="sort-index"><a href="#sort-index" class="headerlink" title=".sort_index()"></a>.sort_index()</h2><p>在指定轴上根据<strong>索引</strong>进行排序，默认升序</p><ul><li>.sort_index(axis=0,ascending=True)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>),index=[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>])<br>b<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br><br>In :<br>b.sort_index()<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br><br>In :<br>b.sort_index(ascending=<span class="hljs-literal">False</span>)<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br><br>In :<br>c = b.sort_index(axis=<span class="hljs-number">1</span>,ascending = <span class="hljs-literal">False</span>)<br>c<br><br>Out:<br>    <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span><br>c   <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span><br>a   <span class="hljs-number">9</span>   <span class="hljs-number">8</span>   <span class="hljs-number">7</span>   <span class="hljs-number">6</span>   <span class="hljs-number">5</span><br>d  <span class="hljs-number">14</span>  <span class="hljs-number">13</span>  <span class="hljs-number">12</span>  <span class="hljs-number">11</span>  <span class="hljs-number">10</span><br>b  <span class="hljs-number">19</span>  <span class="hljs-number">18</span>  <span class="hljs-number">17</span>  <span class="hljs-number">16</span>  <span class="hljs-number">15</span><br><br>In :<br>c = c.sort_index()<br>c<br><br>Out:<br>    <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span><br>a   <span class="hljs-number">9</span>   <span class="hljs-number">8</span>   <span class="hljs-number">7</span>   <span class="hljs-number">6</span>   <span class="hljs-number">5</span><br>b  <span class="hljs-number">19</span>  <span class="hljs-number">18</span>  <span class="hljs-number">17</span>  <span class="hljs-number">16</span>  <span class="hljs-number">15</span><br>c   <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span><br>d  <span class="hljs-number">14</span>  <span class="hljs-number">13</span>  <span class="hljs-number">12</span>  <span class="hljs-number">11</span>  <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><h2 id="sort-values"><a href="#sort-values" class="headerlink" title=".sort_values()"></a>.sort_values()</h2><p>在指定轴上根据<strong>数值</strong>进行排序，默认升序</p><ul><li>.sort_values(axis=0,ascendinng=True)</li><li>DataFrame.sort_values(by,axis=0,ascending=True)    #by:axis轴上的某个索引或索引列表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>),index=[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>])<br>b<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br><br>In :<br>c = b.sort_values(<span class="hljs-number">2</span>,ascending=<span class="hljs-literal">False</span>)<br>c<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br><br>In :<br>c = c.sort_values(<span class="hljs-string">&#x27;a&#x27;</span>,axis=<span class="hljs-number">1</span>,ascending=<span class="hljs-literal">False</span>)<br>c<br><br>Out:<br>    <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span><br>b  <span class="hljs-number">19</span>  <span class="hljs-number">18</span>  <span class="hljs-number">17</span>  <span class="hljs-number">16</span>  <span class="hljs-number">15</span><br>d  <span class="hljs-number">14</span>  <span class="hljs-number">13</span>  <span class="hljs-number">12</span>  <span class="hljs-number">11</span>  <span class="hljs-number">10</span><br>a   <span class="hljs-number">9</span>   <span class="hljs-number">8</span>   <span class="hljs-number">7</span>   <span class="hljs-number">6</span>   <span class="hljs-number">5</span><br>c   <span class="hljs-number">4</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><h2 id="NaN统一放到排序末尾"><a href="#NaN统一放到排序末尾" class="headerlink" title="NaN统一放到排序末尾"></a>NaN统一放到排序末尾</h2><img src="/2024/05/17/20240517_Pandas/image-20240518113034686.png" class="" title="image-20240518113034686"><h1 id="数据的基本统计分析"><a href="#数据的基本统计分析" class="headerlink" title="数据的基本统计分析"></a>数据的基本统计分析</h1><h2 id="适用于Series和DataFrame类型"><a href="#适用于Series和DataFrame类型" class="headerlink" title="适用于Series和DataFrame类型"></a>适用于Series和DataFrame类型</h2><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.sum()</td><td>计算数据的总和，<strong>按0轴计算</strong>，下同</td></tr><tr><td>.count()</td><td>非NaN值的数量</td></tr><tr><td>.mean() .median()</td><td>计算数据的算数平均值、算数中位值</td></tr><tr><td>.var() .std()</td><td>计算数据的方差、标准差</td></tr><tr><td>.min() .max()</td><td>计算数据的最小值、最大值</td></tr><tr><td>.describe()</td><td>针对0轴(各列)的统计汇总</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>a = pd.Series([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>],index=[<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>])<br>a<br><br>Out:<br>a    <span class="hljs-number">9</span><br>b    <span class="hljs-number">8</span><br>c    <span class="hljs-number">7</span><br>d    <span class="hljs-number">6</span><br>dtype: int64<br><br>In :<br>a.describe()<br><br>Out:<br>count    <span class="hljs-number">4.000000</span><br>mean     <span class="hljs-number">7.500000</span><br>std      <span class="hljs-number">1.290994</span><br><span class="hljs-built_in">min</span>      <span class="hljs-number">6.000000</span><br><span class="hljs-number">25</span>%      <span class="hljs-number">6.750000</span><br><span class="hljs-number">50</span>%      <span class="hljs-number">7.500000</span><br><span class="hljs-number">75</span>%      <span class="hljs-number">8.250000</span><br><span class="hljs-built_in">max</span>      <span class="hljs-number">9.000000</span><br>dtype: float64<br><br>In :<br><span class="hljs-built_in">type</span>(a.describe())<br><br>Out:<br>pandas.core.series.Series<br><br>In :<br>a,describe()[<span class="hljs-string">&#x27;count&#x27;</span>]<br><br>Out:<br><span class="hljs-number">4.0</span><br><br>In :<br>a.describe()[<span class="hljs-string">&#x27;max&#x27;</span>]<br><br>Out:<br><span class="hljs-number">9.0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>),index=[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>])<br>b.describe()<br><br>Out:<br>               <span class="hljs-number">0</span>          <span class="hljs-number">1</span>          <span class="hljs-number">2</span>          <span class="hljs-number">3</span>          <span class="hljs-number">4</span><br>count   <span class="hljs-number">4.000000</span>   <span class="hljs-number">4.000000</span>   <span class="hljs-number">4.000000</span>   <span class="hljs-number">4.000000</span>   <span class="hljs-number">4.000000</span><br>mean    <span class="hljs-number">7.500000</span>   <span class="hljs-number">8.500000</span>   <span class="hljs-number">9.500000</span>  <span class="hljs-number">10.500000</span>  <span class="hljs-number">11.500000</span><br>std     <span class="hljs-number">6.454972</span>   <span class="hljs-number">6.454972</span>   <span class="hljs-number">6.454972</span>   <span class="hljs-number">6.454972</span>   <span class="hljs-number">6.454972</span><br><span class="hljs-built_in">min</span>     <span class="hljs-number">0.000000</span>   <span class="hljs-number">1.000000</span>   <span class="hljs-number">2.000000</span>   <span class="hljs-number">3.000000</span>   <span class="hljs-number">4.000000</span><br><span class="hljs-number">25</span>%     <span class="hljs-number">3.750000</span>   <span class="hljs-number">4.750000</span>   <span class="hljs-number">5.750000</span>   <span class="hljs-number">6.750000</span>   <span class="hljs-number">7.750000</span><br><span class="hljs-number">50</span>%     <span class="hljs-number">7.500000</span>   <span class="hljs-number">8.500000</span>   <span class="hljs-number">9.500000</span>  <span class="hljs-number">10.500000</span>  <span class="hljs-number">11.500000</span><br><span class="hljs-number">75</span>%    <span class="hljs-number">11.250000</span>  <span class="hljs-number">12.250000</span>  <span class="hljs-number">13.250000</span>  <span class="hljs-number">14.250000</span>  <span class="hljs-number">15.250000</span><br><span class="hljs-built_in">max</span>    <span class="hljs-number">15.000000</span>  <span class="hljs-number">16.000000</span>  <span class="hljs-number">17.000000</span>  <span class="hljs-number">18.000000</span>  <span class="hljs-number">19.000000</span><br><br>In :<br><span class="hljs-built_in">type</span>(b.describe())<br><br>Out:<br>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;pandas.core.frame.DataFrame&#x27;</span>&gt;<br><br>In :<br>b.describe().ix[<span class="hljs-string">&#x27;max&#x27;</span>] <span class="hljs-comment"># 在pandas版本0.20.0及其以后版本中，ix已经不被推荐使用，使用loc</span><br><br>Out:<br><span class="hljs-number">0</span>    <span class="hljs-number">15.0</span><br><span class="hljs-number">1</span>    <span class="hljs-number">16.0</span><br><span class="hljs-number">2</span>    <span class="hljs-number">17.0</span><br><span class="hljs-number">3</span>    <span class="hljs-number">18.0</span><br><span class="hljs-number">4</span>    <span class="hljs-number">19.0</span><br>Name: <span class="hljs-built_in">max</span>, dtype: float64<br><br>In :<br>b.describe()[<span class="hljs-number">2</span>]<br><br>Out:<br>count     <span class="hljs-number">4.000000</span>     <br>mean      <span class="hljs-number">9.500000</span>     <br>std       <span class="hljs-number">6.454972</span>     <br><span class="hljs-built_in">min</span>       <span class="hljs-number">2.000000</span>     <br><span class="hljs-number">25</span>%       <span class="hljs-number">5.750000</span>     <br><span class="hljs-number">50</span>%       <span class="hljs-number">9.500000</span>     <br><span class="hljs-number">75</span>%      <span class="hljs-number">13.250000</span>     <br><span class="hljs-built_in">max</span>      <span class="hljs-number">17.000000</span>     <br>Name: <span class="hljs-number">2</span>, dtype: float64<br></code></pre></td></tr></table></figure><h2 id="适用于Series类型"><a href="#适用于Series类型" class="headerlink" title="适用于Series类型"></a>适用于Series类型</h2><p>自动索引容易获得元素区间部分(做切片)，自定义索引很难得到一个序列，不易做切片</p><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.argmin() .argmax()</td><td>计算数据最大值、最小值所在位置的索引位置(自动索引)</td></tr><tr><td>.idxmin() .idxmax()</td><td>计算数据最大值、最小值所在位置的索引(自定义索引)</td></tr></tbody></table></div><h1 id="数据的累计统计分析"><a href="#数据的累计统计分析" class="headerlink" title="数据的累计统计分析"></a>数据的累计统计分析</h1><ul><li>减少for循环使用，数据运算更加灵活</li><li>适用于Series和DataFrame类型</li></ul><h2 id="普通计算"><a href="#普通计算" class="headerlink" title="普通计算"></a>普通计算</h2><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.cumsum()</td><td>依次给出前1、2、…、n个数的和</td></tr><tr><td>.cumprod()</td><td>依次给出前1、2、…、n个数的积</td></tr><tr><td>.cummax()</td><td>依次给出前1、2、…、n个数的最大值</td></tr><tr><td>.cummin()</td><td>依次给出前1、2、…、n个数的最小值</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>),index=[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>])<br>b<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br><br>In :<br>b.cumsum()<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">7</span>   <span class="hljs-number">9</span>  <span class="hljs-number">11</span>  <span class="hljs-number">13</span><br>d  <span class="hljs-number">15</span>  <span class="hljs-number">18</span>  <span class="hljs-number">21</span>  <span class="hljs-number">24</span>  <span class="hljs-number">27</span><br>b  <span class="hljs-number">30</span>  <span class="hljs-number">34</span>  <span class="hljs-number">38</span>  <span class="hljs-number">42</span>  <span class="hljs-number">46</span><br><br>In :<br>b.cumprod()<br><br>Out:<br>   <span class="hljs-number">0</span>     <span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">3</span>     <span class="hljs-number">4</span><br>c  <span class="hljs-number">0</span>     <span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">3</span>     <span class="hljs-number">4</span><br>a  <span class="hljs-number">0</span>     <span class="hljs-number">6</span>    <span class="hljs-number">14</span>    <span class="hljs-number">24</span>    <span class="hljs-number">36</span><br>d  <span class="hljs-number">0</span>    <span class="hljs-number">66</span>   <span class="hljs-number">168</span>   <span class="hljs-number">312</span>   <span class="hljs-number">504</span><br>b  <span class="hljs-number">0</span>  <span class="hljs-number">1056</span>  <span class="hljs-number">2856</span>  <span class="hljs-number">5616</span>  <span class="hljs-number">9576</span><br><br>In :<br>b.cummin()<br><br>Out:<br>   <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span><br>c  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span><br>a  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span><br>d  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span><br>b  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span><br><br>In :<br>b.cummax()<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br></code></pre></td></tr></table></figure><h2 id="滚动计算-窗口计算"><a href="#滚动计算-窗口计算" class="headerlink" title="滚动计算(窗口计算)"></a>滚动计算(窗口计算)</h2><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.rolling(w).sum()</td><td>依次计算相邻w个元素的和</td></tr><tr><td>.rolling(w).mean()</td><td>依次计算相邻w个元素的算术平均值</td></tr><tr><td>.rolling(w).var()</td><td>依次计算相邻w个元素的方差</td></tr><tr><td>.rolling(w).std()</td><td>依次计算相邻w个元素的标准差</td></tr><tr><td>.rolling(w).min() .max()</td><td>依次计算相邻w个元素的最小值和最大值</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>b = pd.DataFrame(np.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>),index=[<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>])<br>b<br><br>Out:<br>    <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>c   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span><br>a   <span class="hljs-number">5</span>   <span class="hljs-number">6</span>   <span class="hljs-number">7</span>   <span class="hljs-number">8</span>   <span class="hljs-number">9</span><br>d  <span class="hljs-number">10</span>  <span class="hljs-number">11</span>  <span class="hljs-number">12</span>  <span class="hljs-number">13</span>  <span class="hljs-number">14</span><br>b  <span class="hljs-number">15</span>  <span class="hljs-number">16</span>  <span class="hljs-number">17</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span><br><br>In :<br>b.rolling(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br><br>Out:<br>      <span class="hljs-number">0</span>     <span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">3</span>     <span class="hljs-number">4</span><br>c   NaN   NaN   NaN   NaN   NaN<br>a   <span class="hljs-number">5.0</span>   <span class="hljs-number">7.0</span>   <span class="hljs-number">9.0</span>  <span class="hljs-number">11.0</span>  <span class="hljs-number">13.0</span><br>d  <span class="hljs-number">15.0</span>  <span class="hljs-number">17.0</span>  <span class="hljs-number">19.0</span>  <span class="hljs-number">21.0</span>  <span class="hljs-number">23.0</span><br>b  <span class="hljs-number">25.0</span>  <span class="hljs-number">27.0</span>  <span class="hljs-number">29.0</span>  <span class="hljs-number">31.0</span>  <span class="hljs-number">33.0</span><br><br>In :<br>b.rolling(<span class="hljs-number">3</span>).<span class="hljs-built_in">sum</span>()<br><br>Out:<br>      <span class="hljs-number">0</span>     <span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">3</span>     <span class="hljs-number">4</span><br>c   NaN   NaN   NaN   NaN   NaN<br>a   NaN   NaN   NaN   NaN   NaN<br>d  <span class="hljs-number">15.0</span>  <span class="hljs-number">18.0</span>  <span class="hljs-number">21.0</span>  <span class="hljs-number">24.0</span>  <span class="hljs-number">27.0</span><br>b  <span class="hljs-number">30.0</span>  <span class="hljs-number">33.0</span>  <span class="hljs-number">36.0</span>  <span class="hljs-number">39.0</span>  <span class="hljs-number">42.0</span><br></code></pre></td></tr></table></figure><h1 id="数据的相关分析"><a href="#数据的相关分析" class="headerlink" title="数据的相关分析"></a>数据的相关分析</h1><p>两个事物，表示为X和Y，如何判断他们之间的存在相关性？</p><ul><li>X增大，Y增大，两个变量<strong>正相关</strong></li><li>X增大，Y减小，两个变量<strong>负相关</strong></li><li>X增大，Y无视，两个变量<strong>不相关</strong></li></ul><h2 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h2> $$cov(X,Y)={{\textstyle \sum_{i=1}^{n}(X_i-\bar{X})(Y_i-\bar{Y})}\over{n-1}}$$ <ul><li>协方差&gt;0，X和Y正相关</li><li>协方差&lt;0，X和Y负相关</li><li>协方差=0，X和Y独立无关</li></ul><h2 id="Pearson相关系数"><a href="#Pearson相关系数" class="headerlink" title="Pearson相关系数"></a>Pearson相关系数</h2> $$r = {{{\textstyle \sum_{i=1}^{n}}(x_i-\bar{x})(y_i-\bar{y})}\over{\sqrt{\textstyle\sum_{i=1}^{n}(x_i-\bar{x})^2}}{\sqrt{\textstyle\sum_{i=1}^{n}(y_i-\bar{y})^2}}}$$ <ul><li>r的取值范围[-1,1]</li><li>0.8-1.0 极强相关</li><li>0.6-0.8 强相关</li><li>0.4-0.6 中等程度相关</li><li>0.2-0.4 弱相关</li><li>0.0-0.2 极弱相关或无相关</li></ul><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.cov()</td><td>计算协方差矩阵</td></tr><tr><td>.corr()</td><td>计算相关系数矩阵，Pearson、Spearman、Kendall等系数</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">In :<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>hprice = pd.Series([<span class="hljs-number">3.03</span>,<span class="hljs-number">22.93</span>,<span class="hljs-number">12.75</span>,<span class="hljs-number">22.6</span>,<span class="hljs-number">12.33</span>],index=[<span class="hljs-string">&#x27;2008&#x27;</span>,<span class="hljs-string">&#x27;2009&#x27;</span>,<span class="hljs-string">&#x27;2010&#x27;</span>,<span class="hljs-string">&#x27;2011&#x27;</span>,<span class="hljs-string">&#x27;2012&#x27;</span>])<br>m2 = pd.Series([<span class="hljs-number">8.18</span>,<span class="hljs-number">18.18</span>,<span class="hljs-number">9.13</span>,<span class="hljs-number">7.82</span>,<span class="hljs-number">6.69</span>],index=[<span class="hljs-string">&#x27;2008&#x27;</span>,<span class="hljs-string">&#x27;2009&#x27;</span>,<span class="hljs-string">&#x27;2010&#x27;</span>,<span class="hljs-string">&#x27;2011&#x27;</span>,<span class="hljs-string">&#x27;2012&#x27;</span>])<br>hprice.corr(m2)<br><br>Out:<br><span class="hljs-number">0.5231190329758817</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>数据分析与展示</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据分析</tag>
      
      <tag>分析工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Matplotlib库入门</title>
    <link href="/2024/05/14/20240514_Matplotlib/"/>
    <url>/2024/05/14/20240514_Matplotlib/</url>
    
    <content type="html"><![CDATA[<h1 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h1><p>关键是如何根据数据特点找到合适的图形来呈现（<strong>图形的绘制以及具体参数设计需要经验</strong>）</p><p><a href="http://matplotlib.org/gallery.html">Matplotlib库的效果</a></p><p>数据可视化第三方库，由各种可视化类构成，内部结构复杂，受Matlab启发</p><p>mtaplotlib.pyplot是绘制各类可视化图形的命令子库，相当于快捷方式</p><h2 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.plot([<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>])<span class="hljs-comment">#对于只有一个参数，则横坐标默认为其数组下标</span><br>plt.ylabel(<span class="hljs-string">&quot;Grade&quot;</span>)<br>plt.savefig(<span class="hljs-string">&#x27;test&#x27;</span>,dpi=<span class="hljs-number">600</span>)<span class="hljs-comment">#PNG文件</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>plt.savefig()将输出图形存储为文件，默认PNG格式，可以通过dpi修改输出质量（每一英寸中包含点的数量）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.plot([<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>])<span class="hljs-comment">#两个以上参数时，按照x轴和y轴顺序绘制数据点</span><br>plt.ylabel(<span class="hljs-string">&quot;Grade&quot;</span>)<br>plt.axis([-<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,<span class="hljs-number">0</span>,<span class="hljs-number">6</span>])<span class="hljs-comment">#设置横纵坐标尺度的函数，参数为有四个变量的列表，如-1，10，表明x轴起始于-1，终止于10</span><br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="绘图区域"><a href="#绘图区域" class="headerlink" title="绘图区域"></a>绘图区域</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.subplot(nrows,ncols,plot_number)<span class="hljs-comment">#横轴数量，纵轴数量，当前在绘图区的哪个区域</span><br>plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>)<br>plt.subplot(<span class="hljs-number">324</span>)<br><span class="hljs-comment">###在全局绘图区域中创建一个分区体系，并定位到一个子绘图区域</span><br></code></pre></td></tr></table></figure><p><style>.qfqdobyouirw{zoom:50%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515120854321.png" class="qfqdobyouirw" alt="image-20240515120854321"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">t</span>):<br><span class="hljs-keyword">return</span> np.exp(-t)*np.cos(<span class="hljs-number">2</span>*np.pi*t)<br><br>a = np.arange(<span class="hljs-number">0.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.02</span>)<br><br>plt.subplot(<span class="hljs-number">211</span>)<br>plt.plot(a,f(a))<br><br>plt.subplot(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>plt.plot(a,np.cos(<span class="hljs-number">2</span>*np.pi*a),<span class="hljs-string">&#x27;r--&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h1 id="Pyplot的plot-函数"><a href="#Pyplot的plot-函数" class="headerlink" title="Pyplot的plot()函数"></a>Pyplot的plot()函数</h1><p>plt.plot(x,y,format_string,**kwargs)</p><ul><li>x：X轴数据，列表或数组，可选。</li><li>y：Y轴数据，列表或数组。</li><li>format_string：控制曲线的格式字符串，可选。</li><li>**kwargs：第二组或更多(x,y,format_string)<ul><li>color：控制颜色，color=’green’</li><li>linestyle：线条风格，linestyle=’dashed’</li><li>marker：标记风格，marker=’o’</li><li>markerfacecolor：标记颜色，markerfacecolor=’blue’</li><li>markersize：标记尺寸，markersize=20</li></ul></li></ul><h2 id="format-string"><a href="#format-string" class="headerlink" title="format_string"></a>format_string</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#尝试绘制四条曲线</span><br>a = np.arange(<span class="hljs-number">10</span>)<br>plt.plot(a,a*<span class="hljs-number">1.5</span>,<span class="hljs-string">&#x27;go-&#x27;</span>,a*<span class="hljs-number">2.5</span>,<span class="hljs-string">&#x27;rx&#x27;</span>,a,a*<span class="hljs-number">3.5</span>,<span class="hljs-string">&#x27;*&#x27;</span>,a,a*<span class="hljs-number">4.5</span>,<span class="hljs-string">&#x27;b-.&#x27;</span>)<br></code></pre></td></tr></table></figure><p><style>.mrqwoxpitdkq{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515222115859.png" class="mrqwoxpitdkq" alt="image-20240515222115859"></p><p>控制曲线的格式字符串，可选由颜色字符、风格字符和标记字符组成</p><h3 id="颜色字符"><a href="#颜色字符" class="headerlink" title="颜色字符"></a>颜色字符</h3><div class="table-container"><table><thead><tr><th>颜色字符</th><th>说明</th><th>颜色字符</th><th>说明</th></tr></thead><tbody><tr><td>‘b’</td><td>蓝色</td><td>‘m’</td><td>洋红色 magenta</td></tr><tr><td>‘g’</td><td>绿色</td><td>‘y’</td><td>黄色</td></tr><tr><td>‘r’</td><td>红色</td><td>‘k’</td><td>黑色</td></tr><tr><td>‘c’</td><td>青绿色</td><td>‘w’</td><td>白色</td></tr><tr><td>‘#008000’</td><td>RGB某颜色</td><td>‘0.8’</td><td>灰度值字符串</td></tr></tbody></table></div><h3 id="风格字符"><a href="#风格字符" class="headerlink" title="风格字符"></a>风格字符</h3><div class="table-container"><table><thead><tr><th>风格字符</th><th>说明</th></tr></thead><tbody><tr><td>‘-‘</td><td>实线</td></tr><tr><td>‘—‘</td><td>破折线</td></tr><tr><td>‘-.’</td><td>点划线</td></tr><tr><td>‘:’</td><td>虚线</td></tr><tr><td>‘ ‘  ‘ ‘</td><td>无线条</td></tr></tbody></table></div><h3 id="标记字符"><a href="#标记字符" class="headerlink" title="标记字符"></a>标记字符</h3><div class="table-container"><table><thead><tr><th>标记字符</th><th>说明</th><th>标记字符</th><th>说明</th><th>标记字符</th><th>说明</th></tr></thead><tbody><tr><td>‘.’</td><td>点标记</td><td>‘1’</td><td>下花三角标记</td><td>‘h’</td><td>竖六边形标记</td></tr><tr><td>‘,’</td><td>像素标记(极小点)</td><td>‘2’</td><td>上花三角标记</td><td>‘H’</td><td>横六边形标记</td></tr><tr><td>‘o’</td><td>实心圈标记</td><td>‘3’</td><td>左花三角标记</td><td>‘+’</td><td>十字标记</td></tr><tr><td>‘v’</td><td>倒三角标记</td><td>‘4’</td><td>右花三角标记</td><td>‘x’</td><td>x标记</td></tr><tr><td>‘^’</td><td>上三角标记</td><td>‘s’</td><td>实心方形标记</td><td>‘D’</td><td>菱形标记</td></tr><tr><td>‘&gt;’</td><td>右三角标记</td><td>‘p’</td><td>实心五角标记</td><td>‘d’</td><td>瘦菱形标记</td></tr><tr><td>‘&lt;’</td><td>左三角标记</td><td>‘*’</td><td>星形标记</td><td>‘\</td><td>‘</td><td>垂直线标记</td></tr></tbody></table></div><h1 id="Pyplot的中文显示"><a href="#Pyplot的中文显示" class="headerlink" title="Pyplot的中文显示"></a>Pyplot的中文显示</h1><p>pyplot并不默认支持中文显示</p><h2 id="rcParams"><a href="#rcParams" class="headerlink" title="rcParams"></a>rcParams</h2><p>rcParams修改字体实现</p><div class="table-container"><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>‘font.family’</td><td>用于显示字体的名字</td></tr><tr><td>‘font.style’</td><td>字体风格，正常’normal’或斜体’italic’</td></tr><tr><td>‘font.size’</td><td>字体大小，整数字号或者’large’、’x-small’</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib<br><br>matplotlib.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>]=<span class="hljs-string">&#x27;SimHei&#x27;</span><br><span class="hljs-comment">#&#x27;SimHei&#x27; 中文黑体&#x27;Kaiti&#x27; 中文楷体&#x27;Lisu&#x27; 中文隶书</span><br><span class="hljs-comment">#&#x27;FangSong&#x27; 中文仿宋&#x27;YouYuan&#x27; 中文幼圆&#x27;STSong&#x27; 华文宋体</span><br>plt.plot([<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>])<br>plt.ylabel(<span class="hljs-string">&quot;纵轴(值)&quot;</span>)<br>plt.savefig(<span class="hljs-string">&#x27;test&#x27;</span>,dpi=<span class="hljs-number">600</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.rfksmkldyuui{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515223858518.png" class="rfksmkldyuui" alt="image-20240515223858518"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib<br><br>matplotlib.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>]=<span class="hljs-string">&#x27;STSong&#x27;</span><br>matplotlib.rcParams[<span class="hljs-string">&#x27;font,.size&#x27;</span>]=<span class="hljs-number">20</span><br><br>a = np.arange(<span class="hljs-number">0.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.02</span>)<br><br>plt.xlabel(<span class="hljs-string">&#x27;横轴：时间&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;纵轴：振幅&#x27;</span>)<br>plt.plot(a,np.cos(<span class="hljs-number">2</span>*np.pi*a),<span class="hljs-string">&#x27;r--&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.bwsrznaoddej{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515225245367.png" class="bwsrznaoddej" alt="image-20240515225245367"></p><h2 id="fontproperties"><a href="#fontproperties" class="headerlink" title="fontproperties"></a>fontproperties</h2><p>在有中文输出的地方，增加一个属性：fontproperties</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>a = np.arange(<span class="hljs-number">0.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.02</span>)<br><br>plt.xlabel(<span class="hljs-string">&#x27;横轴：时间&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">20</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;纵轴：振幅&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">20</span>)<br>plt.plot(a,np.cos(<span class="hljs-number">2</span>*np.pi*a),<span class="hljs-string">&#x27;r--&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h1 id="Pyplot的文本显示"><a href="#Pyplot的文本显示" class="headerlink" title="Pyplot的文本显示"></a>Pyplot的文本显示</h1><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>plt.xlabel()</td><td>对x轴增加文本标签</td></tr><tr><td>plt.ylabel()</td><td>对y轴增加文本标签</td></tr><tr><td>plt.title()</td><td>对图形整体增加文本标签</td></tr><tr><td>plt.text()</td><td>在任意位置增加文本</td></tr><tr><td>plt.annotate()</td><td>在图形中增加带箭头的注解</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>a = np.arange(<span class="hljs-number">0.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.02</span>)<br>plt.plot(a,np.cos(<span class="hljs-number">2</span>*np.pi*a),<span class="hljs-string">&#x27;r--&#x27;</span>)<br><br>plt.xlabel(<span class="hljs-string">&#x27;横轴：时间&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">15</span>,color=<span class="hljs-string">&#x27;green&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;纵轴：振幅&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">15</span>)<br>plt.title(<span class="hljs-string">r&#x27;正弦波实例 $y=cos(2\pi x)$&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">25</span>)<br>plt.text(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-string">r&#x27;$\mu=100$&#x27;</span>,fontsize=<span class="hljs-number">15</span>)<br><br>plt.axis([-<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,-<span class="hljs-number">2</span>,<span class="hljs-number">2</span>])<br>plt.grid(<span class="hljs-literal">True</span>)<span class="hljs-comment">#网格</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.tveadqkyauwm{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515231710356.png" class="tveadqkyauwm" alt="image-20240515231710356"></p><h2 id="plt-annotate"><a href="#plt-annotate" class="headerlink" title="plt.annotate()"></a>plt.annotate()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.annotate(s,xy=arrow_crd,xytext=text_crd,arrowprops=<span class="hljs-built_in">dict</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>a = np.arange(<span class="hljs-number">0.0</span>,<span class="hljs-number">5.0</span>,<span class="hljs-number">0.02</span>)<br>plt.plot(a,np.cos(<span class="hljs-number">2</span>*np.pi*a),<span class="hljs-string">&#x27;r--&#x27;</span>)<br><br>plt.xlabel(<span class="hljs-string">&#x27;横轴：时间&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">15</span>,color=<span class="hljs-string">&#x27;green&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;纵轴：振幅&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">15</span>)<br>plt.title(<span class="hljs-string">r&#x27;正弦波实例 $y=cos(2\pi x)$&#x27;</span>,fontproperties=<span class="hljs-string">&#x27;SimHei&#x27;</span>,fontsize=<span class="hljs-number">25</span>)<br>plt.annotate(<span class="hljs-string">r&#x27;$\mu=100$&#x27;</span>,xy=(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>),xytext=(<span class="hljs-number">3</span>,<span class="hljs-number">1.5</span>),<br>arrowprops=<span class="hljs-built_in">dict</span>(facecolor=<span class="hljs-string">&#x27;black&#x27;</span>,shrink=<span class="hljs-number">0.1</span>,width=<span class="hljs-number">2</span>))<br><br>plt.axis([-<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,-<span class="hljs-number">2</span>,<span class="hljs-number">2</span>])<br>plt.grid(<span class="hljs-literal">True</span>)<span class="hljs-comment">#网格</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.aystvhfpfsun{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515232559993.png" class="aystvhfpfsun" alt="image-20240515232559993"></p><h1 id="PyPlot子绘图区域"><a href="#PyPlot子绘图区域" class="headerlink" title="PyPlot子绘图区域"></a>PyPlot子绘图区域</h1><h2 id="subplot2grid"><a href="#subplot2grid" class="headerlink" title="subplot2grid"></a>subplot2grid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.subplot2grid(GridSpec,CurSPec,colspan=<span class="hljs-number">1</span>,rowspan=<span class="hljs-number">1</span>)<br><span class="hljs-comment">#理念：设定网格，选中网格，确定选中行列区域数量，编号从0开始</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.subplot2grid((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),colspan=<span class="hljs-number">3</span>)<br>...<br>plt.subplot2grid((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>),colspan=<span class="hljs-number">2</span>) <span class="hljs-comment">#(3,3)三行三列九块(1,0)表示第一行第零列colspan表示列的延申</span><br>...<br>plt.subplot2grid((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),rowspan=<span class="hljs-number">2</span>)<br>...<br>plt.subplot2grid((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">2</span>,<span class="hljs-number">0</span>))<br>...<br>plt.subplot2grid((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))<br>...<br></code></pre></td></tr></table></figure><p><style>.vbezvvhpfuyt{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240515235038838.png" class="vbezvvhpfuyt" alt="image-20240515235038838"></p><h2 id="GridSpec类"><a href="#GridSpec类" class="headerlink" title="GridSpec类"></a>GridSpec类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.gridspec <span class="hljs-keyword">as</span> gridspec<br><br>gs = gridspec.GridSpec(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br><br>ax1 = plt.subplot(gs[<span class="hljs-number">0</span>,:])<br>ax2 = plt.subplot(gs[<span class="hljs-number">1</span>,:-<span class="hljs-number">1</span>])<br>ax3 = plt.subplot(gs[<span class="hljs-number">1</span>:,-<span class="hljs-number">1</span>])<br>ax4 = plt.subplot(gs[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>])<br>ax5 = plt.subplot(gs[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><h1 id="Pyplot基础图标函数"><a href="#Pyplot基础图标函数" class="headerlink" title="Pyplot基础图标函数"></a>Pyplot基础图标函数</h1><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>plt.plot(x,y,fmt,…)</td><td>绘制一个坐标图</td><td>plt.psd(x,NFFT=256,pad_to,Fs)</td><td>绘制功率密度图</td></tr><tr><td>plt.boxplot(data,notch,position)</td><td>绘制一个箱型图</td><td>plt.specgram(x,NFFT=256,pad_to,F)</td><td>绘制谱图</td></tr><tr><td>plt.bar(left,height,width,bottom)</td><td>绘制一个条形图</td><td>pltcohere(x,y,NFFT=256,Fs)</td><td>绘制X-Y的相关性函数</td></tr><tr><td>plt.barh(width,bottom,left,height)</td><td>绘制一个横向条形图</td><td>plt.scatter(x,y)</td><td>绘制散点图，其中，x和y长度相同</td></tr><tr><td>plt.polar(theta,r)</td><td>绘制极坐标图</td><td>plt.step(x,y,where)</td><td>绘制步阶图</td></tr><tr><td>plt.pie(data,explode)</td><td>绘制饼图</td><td>plt.hist(x,bins,normed)</td><td>绘制直方图</td></tr><tr><td>plt.contour(X,Y,Z,N)</td><td>绘制等值图</td><td>plt.stem(x,y,linefmt,markerfmt)</td><td>绘制柴火图</td></tr><tr><td>plt.vlines()</td><td>绘制垂直图</td><td>plt.plot_date()</td><td>绘制数据日期</td></tr></tbody></table></div><h2 id="Pyplot的饼图绘制"><a href="#Pyplot的饼图绘制" class="headerlink" title="Pyplot的饼图绘制"></a>Pyplot的饼图绘制</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>labels = <span class="hljs-string">&#x27;Forgs&#x27;</span>,<span class="hljs-string">&#x27;Hogs&#x27;</span>,<span class="hljs-string">&#x27;Dogs&#x27;</span>,<span class="hljs-string">&#x27;Logs&#x27;</span><br>sizes = [<span class="hljs-number">15</span>,<span class="hljs-number">30</span>,<span class="hljs-number">45</span>,<span class="hljs-number">10</span>]<br>explode = (<span class="hljs-number">0</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br><br>plt.pie(sizes,explode=explode,labels=labels,autopct=<span class="hljs-string">&#x27;%1.1f%%&#x27;</span>,<br>    shadow=<span class="hljs-literal">False</span>,startangle=<span class="hljs-number">90</span>)<br><span class="hljs-comment">#explode：哪一块应该突出出来 label：标签autoopct：中间显示百分号的方式</span><br><span class="hljs-comment">#shadow：饼图是否带有阴影效果startangle：饼图起始角度</span><br>plt.axis(<span class="hljs-string">&#x27;equal&#x27;</span>)<br><span class="hljs-comment">#饼图变成标准圆饼图</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.cldfbnsqjetm{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240516121839567.png" class="cldfbnsqjetm" alt="image-20240516121839567"></p><h2 id="Pyplot的直方图绘制"><a href="#Pyplot的直方图绘制" class="headerlink" title="Pyplot的直方图绘制"></a>Pyplot的直方图绘制</h2><p>直方图，看数据分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>np.random.seed(<span class="hljs-number">0</span>)<br>mu,sigma = <span class="hljs-number">100</span>,<span class="hljs-number">20</span><br>a = np.random.normal(mu,sigma,size=<span class="hljs-number">100</span>)<br><br>plt.hist(a,<span class="hljs-number">20</span>,normed=<span class="hljs-number">1</span>,histtype=<span class="hljs-string">&#x27;stepfilled&#x27;</span>,facecolor=<span class="hljs-string">&#x27;b&#x27;</span>,alpha=<span class="hljs-number">0.75</span>)<br><span class="hljs-comment">#bin：最小值和最大值之间均分，分割的直方图的个数</span><br><span class="hljs-comment">#normed=1时，将每一个区间数出现的个数归一化为出现的概率</span><br>plt.title(<span class="hljs-string">&#x27;Histogram&#x27;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.cmfxpvkfylqm{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240516122227339.png" class="cmfxpvkfylqm" alt="image-20240516122227339"></p><h2 id="Pyplot极坐标绘制"><a href="#Pyplot极坐标绘制" class="headerlink" title="Pyplot极坐标绘制"></a>Pyplot极坐标绘制</h2><p>面向对象绘制极坐标（体会即可）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>N = <span class="hljs-number">20</span><br>theta = np.linspace(<span class="hljs-number">0.0</span>,<span class="hljs-number">2</span>*np.pi,N,edpoint=<span class="hljs-literal">False</span>)<br><span class="hljs-comment">#从0到2pi等分出N个不同角度</span><br>radii = <span class="hljs-number">10</span>*np.random.rand(N)<br><span class="hljs-comment">#生成每个角度对应的值</span><br>width = np.pi / <span class="hljs-number">4</span> * np.random.rand(N)<br><br>ax = plt.subplot(<span class="hljs-number">111</span>,projection=<span class="hljs-string">&#x27;ploar&#x27;</span>)<br><span class="hljs-comment">#子绘图区域形成的对象，projection作出绘制极坐标指示</span><br>bars = ax.bar(theta,radii,wiidth=width,bottom=<span class="hljs-number">0.0</span>)<br><span class="hljs-comment">#theta:leftradii:height</span><br><span class="hljs-keyword">for</span> r,bar <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(radii,bars):<br>bar.set_facecolor(plt.cm.viridis(r/<span class="hljs-number">10.</span>))<br>bar.set_alpha(<span class="hljs-number">0.5</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.towiwsoahofs{zoom:67%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240516165312870.png" class="towiwsoahofs" alt="image-20240516165312870"></p><h2 id="Pyplot散点图绘制"><a href="#Pyplot散点图绘制" class="headerlink" title="Pyplot散点图绘制"></a>Pyplot散点图绘制</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>fig,ax = plt.subplots()<br><span class="hljs-comment">#ax为绘图区域对象，这里没参数则默认为111</span><br>ax.plot(<span class="hljs-number">10</span>*np.random.randn(<span class="hljs-number">100</span>),<span class="hljs-number">10</span>*np.random.randn(<span class="hljs-number">100</span>),<span class="hljs-string">&#x27;o&#x27;</span>)<br><span class="hljs-comment">#正态产生的点搞分散些</span><br>ax.set_title(<span class="hljs-string">&#x27;Simple Scatter&#x27;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p><style>.mivddpqbeoqr{zoom: 80%;}</style><img src="/2024/05/14/20240514_Matplotlib/image-20240516210019547.png" class="mivddpqbeoqr" alt="image-20240516210019547"></p><h1 id="引力波的绘制示例"><a href="#引力波的绘制示例" class="headerlink" title="引力波的绘制示例"></a>引力波的绘制示例</h1><p>物理学中，引力波是因为时空弯曲对外以辐射形式传播的能量</p><p>爱因斯坦基于广义相对论预言了引力波的存在</p><img src="/2024/05/14/20240514_Matplotlib/image-20240516211005225.png" class="" title="image-20240516211005225"><p>绘制最原始的引力波和理想引力波</p><p><a href="[Draw of Gravitational Waves (python123.io">下载三个文件</a>](<a href="https://python123.io/dv/grawave.html">https://python123.io/dv/grawave.html</a>))</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> scipy.io <span class="hljs-keyword">import</span> wavfile<br><br>rate_h,hstrain = wavfile.read(<span class="hljs-string">r&quot;H1_Strain.wav&quot;</span>,<span class="hljs-string">&quot;rb&quot;</span>)<br>rate_l,lstrain = wavfile.read(<span class="hljs-string">r&quot;L1_Strain.wav&quot;</span>,<span class="hljs-string">&quot;rb&quot;</span>)<br>reftime,ref_H1 = np.genfromtxt(<span class="hljs-string">&#x27;wf_template.txt&#x27;</span>).transpose()<br><span class="hljs-comment">#np.genfromtxt中有两个循环，第一个循环将文件每一行都转化为字符串序列，第二个循环将每一个字符串序列转化成相应数据类型</span><br><span class="hljs-comment">#这样生成一个两行的矩阵，不便于拆分，因此用transpose进行转置</span><br>htime_interval = <span class="hljs-number">1</span>/rate_h<br>ltime_interval = <span class="hljs-number">1</span>/rate_l<br><span class="hljs-comment">#速率求导数获得波形的时间间隔</span><br>htime_len = hstrain.shape[<span class="hljs-number">0</span>]/rate_h<br><span class="hljs-comment">#strain是一个数据矩阵，shape[0]指的是获取第一维度的长度，即数据点的个数，数据个数乘上时间间隔得坐标轴总长度</span><br>htime = np.arange(-htime_len/<span class="hljs-number">2</span>,htime_len/<span class="hljs-number">2</span>,htime_interval)<br>ltime_len = lstrain.shape[<span class="hljs-number">0</span>]/rate_l<br>ltime = np.arange(-ltime_len/<span class="hljs-number">2</span>,ltime_len/<span class="hljs-number">2</span>,ltime_interval)<br><br><span class="hljs-comment">###绘制H1 Strain###</span><br>fig = plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">6</span>))<span class="hljs-comment">#创建一个大小为12*6的绘图空间</span><br><br>plth = fig.add_subplot(<span class="hljs-number">221</span>)<br>plth.plot(htime,hstrain,<span class="hljs-string">&#x27;y&#x27;</span>)<br>plth.set_xlabel(<span class="hljs-string">&#x27;Time(seconds)&#x27;</span>)<br>plth.set_ylabel(<span class="hljs-string">&#x27;H1 Strain&#x27;</span>)<br>plth.set_title(<span class="hljs-string">&#x27;H1 Strain&#x27;</span>)<br><br>pltl = fig.add_subplot(<span class="hljs-number">222</span>)<br>pltl.plot(ltime,lstrain,<span class="hljs-string">&#x27;g&#x27;</span>)<br>pltl.set_xlabel(<span class="hljs-string">&#x27;Time(seconds)&#x27;</span>)<br>pltl.set_ylabel(<span class="hljs-string">&#x27;L1 Strain&#x27;</span>)<br>pltl.set_title(<span class="hljs-string">&#x27;L1 Strain&#x27;</span>)<br><br>pltref = fig.add_subplot(<span class="hljs-number">212</span>)<br>pltref.plot(reftime,ref_H1)<br>pltref.set_xlabel(<span class="hljs-string">&#x27;Time(seconds)&#x27;</span>)<br>pltref.set_ylabel(<span class="hljs-string">&#x27;Template Strain&#x27;</span>)<br>pltref.set_title(<span class="hljs-string">&#x27;Template&#x27;</span>)<br>fig.tight_layout()<span class="hljs-comment">#自动调整图像外围间距</span><br><br>plt.savefig(<span class="hljs-string">&quot;Gravitational_waves_Original.png&quot;</span>)<br>plt.show()<br>plt.close(fig)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>数据分析与展示</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据分析</tag>
      
      <tag>分析工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python虚拟环境</title>
    <link href="/2024/05/08/20240508_virtualEnv/"/>
    <url>/2024/05/08/20240508_virtualEnv/</url>
    
    <content type="html"><![CDATA[<h1 id="系统解释器"><a href="#系统解释器" class="headerlink" title="系统解释器"></a>系统解释器</h1><ol><li><p>在<a href="https://www.python.org/">python官网</a>下载了python解释器(实际上就是一个软件)</p></li><li><p>将下载好的python解释器安装在<code>D:\Python39</code>目录下</p></li><li><p>那么，在这个目录下就会生成一系列的文件，下面我们了解一下最主要的几个内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cobol">D:\Python39<br>    - python.exe#python解释器<br>    - Scripts#目录：存放可执行文件<br>        - pip.exe<br>        - pip3.exe<br>        - pip3.9.exe<br>    - Lib#目录：存放python内置的模块<br>        - random.py<br>        - re.py<br>        - json.py<br>        - site-packages#目录：存放通过pip安装的第三方模块<br>            - requests.py<br></code></pre></td></tr></table></figure></li></ol><p>在我们的电脑上，同时可以安装多个版本的系统解释器(如：python3.8，python3.9，python3.10)</p><h1 id="环境变量的配置"><a href="#环境变量的配置" class="headerlink" title="环境变量的配置"></a>环境变量的配置</h1><ol><li><p>我们的电脑可以安装多个版本的解释器</p></li><li><p>但是，我们在日常开发中会选择一个系统解释器作为主运用的解释器</p></li><li><p>我们就会将这个版本的解释器的目录添加到环境变量中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cobol">D:\Python39<br>D:\Python39\Scripts\<br></code></pre></td></tr></table></figure></li><li><p>那么，我们就可以在cmd终端中直接用python来调用解释器</p></li><li><p>实际就是通过环境变量中的D:\Python39路径来找到 python.exe</p></li><li><p>在cmd中运行pip install安装第三方模块</p></li><li><p>实际就是通过环境变量中的 D:\Python39\Scripts\ 路径来找到 pip.exe</p></li></ol><h1 id="如何使用虚拟环境"><a href="#如何使用虚拟环境" class="headerlink" title="如何使用虚拟环境"></a>如何使用虚拟环境</h1><h2 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create –n py311 python=<span class="hljs-number">3.11</span><br><span class="hljs-comment"># -n : 虚拟环境的名称</span><br><span class="hljs-comment"># python= : 下载的版本号</span><br><span class="hljs-comment"># 如果下载的不是python3.7版本，将python=()改成相应的版本</span><br></code></pre></td></tr></table></figure><h2 id="进入虚拟环境"><a href="#进入虚拟环境" class="headerlink" title="进入虚拟环境"></a>进入虚拟环境</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda activate py311<br></code></pre></td></tr></table></figure><h2 id="退出虚拟环境"><a href="#退出虚拟环境" class="headerlink" title="退出虚拟环境"></a>退出虚拟环境</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda deactivate<br></code></pre></td></tr></table></figure><h2 id="删除自定义环境"><a href="#删除自定义环境" class="headerlink" title="删除自定义环境"></a>删除自定义环境</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda remove --name py311 --<span class="hljs-built_in">all</span><br></code></pre></td></tr></table></figure><h2 id="查看虚拟环境"><a href="#查看虚拟环境" class="headerlink" title="查看虚拟环境"></a>查看虚拟环境</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda env <span class="hljs-built_in">list</span><br></code></pre></td></tr></table></figure><h2 id="查看环境中的包"><a href="#查看环境中的包" class="headerlink" title="查看环境中的包"></a>查看环境中的包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda <span class="hljs-built_in">list</span><br></code></pre></td></tr></table></figure><h2 id="在虚拟环境中安装、卸载、更新包"><a href="#在虚拟环境中安装、卸载、更新包" class="headerlink" title="在虚拟环境中安装、卸载、更新包"></a>在虚拟环境中安装、卸载、更新包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">conda install python=<span class="hljs-number">3.6</span>  激活虚拟环境后安装包 (可以指定版本)<br>conda remove packname 激活虚拟环境后移除包<br>conda update packname 激活虚拟环境后更新包<br></code></pre></td></tr></table></figure><h1 id="在miniconda3安装spyter"><a href="#在miniconda3安装spyter" class="headerlink" title="在miniconda3安装spyter"></a>在miniconda3安装spyter</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install sip <span class="hljs-comment">##下载太慢了自己用vpn或者换源</span><br>pip.exe install --pre pyqt5-tools~=<span class="hljs-number">5.11</span> <span class="hljs-comment">##这里记得切换环境到3.11</span><br>pip install spyder<br>spyder<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NumPy库入门</title>
    <link href="/2024/04/30/20240430_numPy/"/>
    <url>/2024/04/30/20240430_numPy/</url>
    
    <content type="html"><![CDATA[<p>掌握表示、清洗、统计和展示数据的能力</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>NumPy是一个开源的Python科学计算基础库，底层实现是用C语言实现，实现数组时底层提供高效运算性能。</p><ul><li>一个强大的N维数组对象ndarray</li><li>广播功能函数</li><li>整合C/C++/Fortran代码的工具</li><li>线性代数、傅里叶变换、随机数生成等功能</li></ul><p>Numpy是SciPy、Pandas等数据处理或科学计算库的基础。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#引用</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><h1 id="数据表示"><a href="#数据表示" class="headerlink" title="数据表示"></a>数据表示</h1><h2 id="数据的维度"><a href="#数据的维度" class="headerlink" title="数据的维度"></a>数据的维度</h2><p>从一个数据到一组数据，一个数据表达一个含义，一组数据表达一个或多个含义。维度是一组数据的组织形式。数据之间的关系。</p><h3 id="一维数据"><a href="#一维数据" class="headerlink" title="一维数据"></a>一维数据</h3><p>由对等关系的有序或无序数据构成，采用线性方式组织。（对应<strong>列表</strong>、数组和<strong>集合</strong>等概念）</p><h4 id="列表和数组"><a href="#列表和数组" class="headerlink" title="列表和数组"></a>列表和数组</h4><p>一组数据的有序结构，区别：</p><p>列表：数据类型可以不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">3.14</span>,<span class="hljs-string">&#x27;pi&#x27;</span>,<span class="hljs-number">3.1404</span>,[<span class="hljs-number">3.1401</span>,<span class="hljs-number">3.1349</span>],<span class="hljs-string">&#x27;3.1376&#x27;</span><br></code></pre></td></tr></table></figure><p>数组：数据型相同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">3.1413</span>，<span class="hljs-number">3.1313</span>，<span class="hljs-number">3.1234</span>，<span class="hljs-number">3.1451</span>，<span class="hljs-number">3.5161</span><br></code></pre></td></tr></table></figure><h3 id="二维数据"><a href="#二维数据" class="headerlink" title="二维数据"></a>二维数据</h3><p>二维数据由多个一维数据构成,是一维数据的组合形式。</p><div class="table-container"><table><thead><tr><th>排名</th><th>学校</th><th>总分</th></tr></thead><tbody><tr><td>1</td><td>清华</td><td>100.0</td></tr><tr><td>2</td><td>北大</td><td>99.8</td></tr><tr><td>3</td><td>浙大</td><td>98.8</td></tr></tbody></table></div><h3 id="多维数据"><a href="#多维数据" class="headerlink" title="多维数据"></a>多维数据</h3><p>多维数据由一维或二维数据在新维度扩展形成。<strong>2023-&gt;2024，时间维度</strong>。</p><div class="table-container"><table><thead><tr><th>排名</th><th>学校</th><th>总分</th></tr></thead><tbody><tr><td>1</td><td>清华</td><td>100.0</td></tr><tr><td>2</td><td>北大</td><td>99.8</td></tr><tr><td>3</td><td>浙大</td><td>98.8</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>排名</th><th>学校</th><th>总分</th></tr></thead><tbody><tr><td>1</td><td>清华</td><td>100.0</td></tr><tr><td>2</td><td>北大</td><td>99.6</td></tr><tr><td>3</td><td>浙大</td><td>98.7</td></tr></tbody></table></div><h3 id="高维数据"><a href="#高维数据" class="headerlink" title="高维数据"></a>高维数据</h3><p>高维数据仅仅利用最基本的二元关系展示数据间的复杂结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<br><span class="hljs-string">&quot;firstName&quot;</span>:<span class="hljs-string">&quot;Tian&quot;</span>,<br><span class="hljs-string">&quot;lastName&quot;</span>:<span class="hljs-string">&quot;Song&quot;</span>,<br><span class="hljs-string">&quot;address&quot;</span>:&#123;<br><span class="hljs-string">&quot;streetAddr&quot;</span>:<span class="hljs-string">&quot;中关村南大街5号&quot;</span>,<br><span class="hljs-string">&quot;city&quot;</span>:<span class="hljs-string">&quot;北京市&quot;</span>,<br><span class="hljs-string">&quot;zipcode&quot;</span>:<span class="hljs-string">&quot;1000081&quot;</span><br>&#125;,<br><span class="hljs-string">&quot;prof&quot;</span>:[<span class="hljs-string">&quot;Computer System&quot;</span>,<span class="hljs-string">&quot;Security&quot;</span>]<br>&#125;<br><span class="hljs-comment">#键值对组织</span><br><span class="hljs-comment">#没有数据规整的组织方式，却有数据间的包含关系、数据间的并列关系以及数据间的属性关系等，形成了数据的组织方式</span><br></code></pre></td></tr></table></figure><h3 id="如何表示"><a href="#如何表示" class="headerlink" title="如何表示"></a>如何表示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#一维数据</span><br>[<span class="hljs-number">3.1413</span>，<span class="hljs-number">3.1313</span>，<span class="hljs-number">3.1234</span>，<span class="hljs-number">3.1451</span>，<span class="hljs-number">3.5161</span>]有序、列表<br>&#123;<span class="hljs-number">3.1413</span>，<span class="hljs-number">3.1313</span>，<span class="hljs-number">3.1234</span>，<span class="hljs-number">3.1451</span>，<span class="hljs-number">3.5161</span>&#125;无序、集合<br><br><span class="hljs-comment">#二维数据</span><br>[[<span class="hljs-number">3.1413</span>，<span class="hljs-number">3.1313</span>，<span class="hljs-number">3.1234</span>],<br> [<span class="hljs-number">3.1234</span>，<span class="hljs-number">3.1451</span>，<span class="hljs-number">3.5161</span>]]列表<br><br><span class="hljs-comment">#多维数据</span><br>列表<br><br><span class="hljs-comment">#高维数据</span><br>字典类型或数据表示格式(JSON、XML和YAML格式)<br><span class="hljs-built_in">dict</span> = &#123;<br>    <span class="hljs-string">&quot;firstName&quot;</span>:<span class="hljs-string">&quot;Tian&quot;</span>,<br>    <span class="hljs-string">&quot;lastName&quot;</span>:<span class="hljs-string">&quot;Song&quot;</span>,<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="数组对象-ndarray"><a href="#数组对象-ndarray" class="headerlink" title="数组对象:ndarray"></a>数组对象:ndarray</h2><ul><li><p>数组对象可以去掉元素间运算间运算所需的循环，使一维向量更像单个数据。</p></li><li><p>设置专门的数组对象，经过优化，可以提升这类应用的运算速度。</p></li><li><p>观察：科学计算中，一个维度所有数据的类型往往相同。</p></li><li><p>数组对象采用相同的数据类型，有助于节省运算和存储空间。</p></li><li><p>ndarray是一个多维数组对象，由两部分构成：</p><ul><li>实际的数据</li><li>描述这些数据的元素据（数据维度、数据类型等）</li></ul><p>ndarray数组一般要求所有元素类型相同（同质），数组下标从0开始。</p></li></ul><p>例：计算$A^2+B^3$，其中，A和B是一维数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">pySum</span>():<br>a = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br>b = [<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>]<br>c = []<br>    <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(a)):<br>c.append(a[i]**<span class="hljs-number">2</span> + b[i]**<span class="hljs-number">3</span>)<br><br><span class="hljs-keyword">return</span> c<br><br><span class="hljs-built_in">print</span>(pySum())<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">npSum</span>():<br>a = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>b = np.array([<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>])<br><br>c = a**<span class="hljs-number">2</span> + b**<span class="hljs-number">3</span><br><br><span class="hljs-keyword">return</span> c<br><br><span class="hljs-built_in">print</span>(npSum())<br><br><span class="hljs-comment">#np.array()生成一个ndarray数组</span><br><span class="hljs-comment">#ndarray在程序中的别名是：array</span><br><span class="hljs-comment">#np.array()输出成[]形式，元素由空格分割</span><br><span class="hljs-comment">#轴(axis):保存数据的维度秩(rank):轴的数量</span><br></code></pre></td></tr></table></figure><h3 id="ndarray对象的属性"><a href="#ndarray对象的属性" class="headerlink" title="ndarray对象的属性"></a>ndarray对象的属性</h3><div class="table-container"><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>.ndim</td><td>秩，即轴数量或维度的数量</td></tr><tr><td>.shape</td><td>ndarray对象的尺度，对于矩阵，n行m列</td></tr><tr><td>.size</td><td>ndarray对象元素的个数，相当于.shape中n*m的值</td></tr><tr><td>.dtype</td><td>ndarray对象的元素类型</td></tr><tr><td>.itemsize</td><td>ndarray对象中每个元素的大小，以字节为单位</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">22</span>]: a = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br>[<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>]])<br>    <br>In [<span class="hljs-number">23</span>]: a.ndim<br>Out[<span class="hljs-number">23</span>]: <span class="hljs-number">2</span><br>    <br>In [<span class="hljs-number">24</span>]: a.shape<br>Out[<span class="hljs-number">24</span>]: (<span class="hljs-number">2</span>,<span class="hljs-number">5</span>)<br>    <br>In [<span class="hljs-number">25</span>]: a.size<br>Out[<span class="hljs-number">25</span>]: <span class="hljs-number">10</span><br>    <br>In [<span class="hljs-number">26</span>]: a.dtype<br>Out[<span class="hljs-number">26</span>]: dtype(<span class="hljs-string">&#x27;int32&#x27;</span>)<br>    <br>In [<span class="hljs-number">27</span>]: a.itemsize<br>Out[<span class="hljs-number">27</span>]: <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>数据类型</th><th>说明</th></tr></thead><tbody><tr><td>intc</td><td>与C语言中的int类型一直，一般是int32或int64</td></tr><tr><td>intp</td><td>用于索引的整数，与C语言中ssize_t一致，int32或int64</td></tr><tr><td>int8</td><td>字节长度整数，取值：[-128,127]</td></tr><tr><td>int16</td><td>16位长度整数，取值：[-32768,32767]</td></tr><tr><td>int32</td><td>32位长度整数，取值：[$-2^31,2^31-1$]</td></tr><tr><td>int64</td><td>64位长度整数，取值：[-2^63,2^63-1]</td></tr><tr><td>uint64</td><td>64位无符号整数，取值：[0,2^64-1]</td></tr><tr><td>float64</td><td>64位半精度浮点数：1位符号位，11位指数，52位尾数</td></tr><tr><td>complex64</td><td>复数类型，实部和虚部都是32位浮点数，实部(.real)+j虚部(.imag)</td></tr><tr><td>…</td><td>…</td></tr></tbody></table></div><p><strong>对比</strong>：Python语法仅支持整数、浮点数和复数3种类型，且其中整数类型是没有取值范围划分的，浮点数和复数仅有一种。</p><h3 id="支持那么多种数据类型？"><a href="#支持那么多种数据类型？" class="headerlink" title="支持那么多种数据类型？"></a>支持那么多种数据类型？</h3><ol><li>科学计算涉及数据较多，对存储和性能都有比较高要求。</li><li>对元素类型精细定义，有助于NumPy合理使用存储空间并进行优化性能。</li><li>对元素类型精细定义，有助于程序员对程序规模有合理的评估。</li></ol><h3 id="可由非同质对象构成"><a href="#可由非同质对象构成" class="headerlink" title="可由非同质对象构成"></a>可由非同质对象构成</h3><p>非同质ndarray对象无法发挥NumPy优势，尽量避免使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">61</span>]: x = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],<br> [<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>]])<br><br>In [<span class="hljs-number">62</span>]: x.shape<br>Out[<span class="hljs-number">63</span>]: (<span class="hljs-number">2</span>,)<br><br>In [<span class="hljs-number">63</span>]: x.dtype<br>Out[<span class="hljs-number">63</span>]: dtype(<span class="hljs-string">&#x27;O&#x27;</span>)  <span class="hljs-comment">#非同质ndarray元素为对象类型。</span><br><br>In [<span class="hljs-number">64</span>]: x<br>Out[<span class="hljs-number">64</span>]: array([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">9</span>,<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>]],dtype=<span class="hljs-built_in">object</span>)<br><br>In [<span class="hljs-number">65</span>]: x.itemsize<br>Out[<span class="hljs-number">65</span>]: <span class="hljs-number">4</span><br><br>In [<span class="hljs-number">66</span>]: x.size<br>Out[<span class="hljs-number">66</span>]: <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h2 id="ndarray数组的创建和变换"><a href="#ndarray数组的创建和变换" class="headerlink" title="ndarray数组的创建和变换"></a>ndarray数组的创建和变换</h2><h3 id="ndarray数组的创建方法"><a href="#ndarray数组的创建方法" class="headerlink" title="ndarray数组的创建方法"></a>ndarray数组的创建方法</h3><ol><li><p>从Python中的列表，元组等类型创建ndarray数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">x = np.array(<span class="hljs-built_in">list</span>/<span class="hljs-built_in">tuple</span>)<br>x = np.array(<span class="hljs-built_in">list</span>/<span class="hljs-built_in">tuple</span>,dtype=np.float32)<br><span class="hljs-comment"># 当np.array()不指定dtype时，NumPy将根据数据情况关联一个dtype类型</span><br><br>In [<span class="hljs-number">32</span>]: x = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])<span class="hljs-comment">#从列表类型创建</span><br><br>In [<span class="hljs-number">33</span>]: <span class="hljs-built_in">print</span>(x)<br>[<span class="hljs-number">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br><br>In [<span class="hljs-number">34</span>]: x = np.array((<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>)<span class="hljs-comment">#从元组类型创建</span><br><br>In [<span class="hljs-number">35</span>]: <span class="hljs-built_in">print</span>(x)<br>[<span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span> <span class="hljs-number">7</span>]<br><br>In [<span class="hljs-number">36</span>]: x = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">9</span>,<span class="hljs-number">8</span>],(<span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>)])<span class="hljs-comment">#从列表和元组混合类型创建</span><br><br>In [<span class="hljs-number">37</span>]: <span class="hljs-built_in">print</span>(x)<br>[[ <span class="hljs-number">1.</span> <span class="hljs-number">2.</span>]<br> [ <span class="hljs-number">9.</span> <span class="hljs-number">8.</span>]<br> [<span class="hljs-number">0.1</span> <span class="hljs-number">0.2</span>]]<br></code></pre></td></tr></table></figure></li><li><p>使用NumPy中函数创建ndarray数组，如：arange,ones,zeros等。</p><p>| 函数               | 说明                                           |<br>| ————————— | ——————————————————————— |<br>| np.arange(n)       | 类似range()函数，返回ndarray类型，元素从0到n-1 |<br>| np.ones(shape)     | 根据shape生成一个全1数组，shape是元组类型      |<br>| np.zeros(shape)    | 根据shape生成一个全0数组，shape是元组类型      |<br>| np.full(shape.val) | 根据shape生成一个数组，每个元素值都是val       |<br>| np.eye(n)          | 创建一个正方的n*n得矩阵，对角线为1，其余为0    |</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">73</span>]: np.arange(<span class="hljs-number">10</span>)<br>Out[<span class="hljs-number">73</span>]: array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>])<br><br>In [<span class="hljs-number">74</span>]: np.ones((<span class="hljs-number">3</span>,<span class="hljs-number">6</span>))<br>Out[<span class="hljs-number">74</span>]: array([[<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>]<br>   [<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>],<br>   [<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>]])<br><br>In [<span class="hljs-number">75</span>]: np.zeros((<span class="hljs-number">3</span>,<span class="hljs-number">6</span>),dtype=np.int32)<br>Out[<span class="hljs-number">75</span>]: array([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],<br>   [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],<br>   [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]])<br><br>In [<span class="hljs-number">76</span>]: np.eye(<span class="hljs-number">5</span>)<br>Out[<span class="hljs-number">76</span>]: array([[<span class="hljs-number">1.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>],<br>   [<span class="hljs-number">0.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>],<br>   [<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>],<br>   [<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">0.</span>],<br>   [<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">0.</span>,<span class="hljs-number">1.</span>]])<br>   <br>In [<span class="hljs-number">81</span>]: x = np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><br>In [<span class="hljs-number">82</span>]: <span class="hljs-built_in">print</span>(x)<br>[[[<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]<br>  [<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]<br>  [<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]]<br>  <br>  [[<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]<br>   [<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]<br>   [<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]]]<br>   <br>In [<span class="hljs-number">83</span>]: x.shape<br>Out[<span class="hljs-number">83</span>]: (<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure><p>| 函数                | 说明                                           |<br>| —————————- | ——————————————————————— |<br>| np.ones_like(a)     | 根据数组a的形状生成一个全1数组                 |<br>| np.zeros_like(a)    | 根据数组a的形状生成一个全0数组                 |<br>| np.full_like(a,val) | 根据数组a的形状生成一个数组，每个元素值都是val |</p></li><li><p>使用NumPy中其他函数创建ndarray数组</p><p>| 函数             | 说明                                   |<br>| ———————— | ——————————————————— |<br>| np.linspace()    | 根据起止数据等间距地填充数据，形成数组 |<br>| np.concatenate() | 将两个或多个数组合并成一个新的数组     |</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">51</span>]: a = np.linspace(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">4</span>) <span class="hljs-comment">#起始位置，终止位置，希望生成几个元素</span><br><br>In [<span class="hljs-number">52</span>]: a<br>Out[<span class="hljs-number">52</span>]: array([<span class="hljs-number">1.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">7.</span>, <span class="hljs-number">10.</span>]) <span class="hljs-comment">#1到10中间等间距分成3份</span><br><br>In [<span class="hljs-number">53</span>]: b = np.linspace(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">4</span>, endpoint = <span class="hljs-literal">False</span>) <span class="hljs-comment">#最后一个元素是否为生成元素中的一个</span><br><br>In [<span class="hljs-number">54</span>]: b<br>Out[<span class="hljs-number">54</span>]: array([ <span class="hljs-number">1.</span>, <span class="hljs-number">3.25</span>, <span class="hljs-number">5.5</span>, <span class="hljs-number">7.75</span>]) <span class="hljs-comment">#1到10中间等间距分成4份</span><br><br>In [<span class="hljs-number">55</span>]: c = np.concatenate((a,b))<br><br>In [<span class="hljs-number">56</span>]: c<br>Out[<span class="hljs-number">56</span>]: array([ <span class="hljs-number">1.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">7.</span>, <span class="hljs-number">10.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">3.25</span>, <span class="hljs-number">5.5</span>, <span class="hljs-number">7.75</span>])<br></code></pre></td></tr></table></figure></li><li><p>从字节流(raw bytes)中创建ndarry数组。</p></li></ol><h3 id="ndarray数组的变换"><a href="#ndarray数组的变换" class="headerlink" title="ndarray数组的变换"></a>ndarray数组的变换</h3><h4 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h4><p>对于创建后的ndarray数组，可以对其进行维度变换和元素类型变换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">a = np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>) , dtype = np.int32)<br></code></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>.reshape(shape)</td><td>不改变数组元素，返回一个shape形状的数组，<strong>原数组不变</strong></td></tr><tr><td>.resize(shape)</td><td>与.reshape()功能一致，但修改原数组</td></tr><tr><td>.swapaxes(ax1,ax2)</td><td>将数组n个维度中两个维度进行调换</td></tr><tr><td>.flatten()</td><td>对数组进行降维，放回折叠后的一维数组，<strong>原数组不变</strong></td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">105</span>]: a.reshape((<span class="hljs-number">3</span>,<span class="hljs-number">8</span>))<span class="hljs-comment">###a.reshape</span><br>Out[<span class="hljs-number">105</span>]:<br>array([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])<br>   <br>In [<span class="hljs-number">106</span>]: a<br>Out[<span class="hljs-number">106</span>]:<br>array([[[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]],<br>    <br>   [[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]]])<br>    <br>In [<span class="hljs-number">107</span>]: a.resize((<span class="hljs-number">3</span>,<span class="hljs-number">8</span>))<span class="hljs-comment">###a.resize</span><br><br>In [<span class="hljs-number">108</span>]: a<br>Out[<span class="hljs-number">108</span>]:<br>array([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])<br><br>In [<span class="hljs-number">109</span>]: a.flatten()<span class="hljs-comment">###a.flatten</span><br>Out[<span class="hljs-number">109</span>]: array([<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,...,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])<br><br>In [<span class="hljs-number">110</span>]: a<br>Out[<span class="hljs-number">110</span>]:<br>array([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,...,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,...,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,...,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])<br>   <br>In [<span class="hljs-number">111</span>]: b = a.flatten()<br><br>In [<span class="hljs-number">112</span>]: b<br>Out[<span class="hljs-number">112</span>]: array([<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,...,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><h4 id="类型变换"><a href="#类型变换" class="headerlink" title="类型变换"></a>类型变换</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">new_a = a.astype(new_type)<br></code></pre></td></tr></table></figure><p>astype()方法一定会创建新的数组(原始数据的一个拷贝)，即使两个类型一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">119</span>]: a = np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),dtype = np.<span class="hljs-built_in">int</span>)<br><br>In [<span class="hljs-number">120</span>]: a<br>Out[<span class="hljs-number">120</span>]:<br>array([[[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]],<br>    <br>   [[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]]])<br>    <br>In [<span class="hljs-number">121</span>]: b = a.astype(np.<span class="hljs-built_in">float</span>)<span class="hljs-comment">###a.astype，可以改变类型</span><br><br>In [<span class="hljs-number">122</span>]: b<br>Out[<span class="hljs-number">122</span>]:<br>array([[[<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>],<br>    [<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>],<br>    [<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>]],<br>    <br>   [[<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>],<br>    [<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>],<br>    [<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>,<span class="hljs-number">1.</span>]]])<br></code></pre></td></tr></table></figure><h4 id="向列表的转换"><a href="#向列表的转换" class="headerlink" title="向列表的转换"></a>向列表的转换</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Ls = a.tolist()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">128</span>]: a = np.full((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),<span class="hljs-number">25</span>,dtype=np.int32)<br><br>In [<span class="hljs-number">129</span>]: a<br>Out[<span class="hljs-number">129</span>]:([[[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],<br>   [<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],<br>   [<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>]],<br>  [[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],<br>   [<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],<br>   [<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>]]])<br>   <br>In [<span class="hljs-number">130</span>]: a.tolist()<span class="hljs-comment">###a.tolist</span><br>Out[<span class="hljs-number">130</span>]:<br>[[[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>]],<br> [[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>],[<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>,<span class="hljs-number">25</span>]]]<br></code></pre></td></tr></table></figure><h2 id="ndarray数组的操作"><a href="#ndarray数组的操作" class="headerlink" title="ndarray数组的操作"></a>ndarray数组的操作</h2><h3 id="数组的索引和切片"><a href="#数组的索引和切片" class="headerlink" title="数组的索引和切片"></a>数组的索引和切片</h3><p>索引：获取数组中特定位置元素的过程</p><p>切片：获取数组元素子集的过程</p><h3 id="一维数组"><a href="#一维数组" class="headerlink" title="一维数组"></a>一维数组</h3><p>与python的列表类似</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">In <span class="hljs-selector-attr">[131]</span>: <span class="hljs-selector-tag">a</span> = np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[9,8,7,6,5]</span>)<br><br>In <span class="hljs-selector-attr">[132]</span>: <span class="hljs-selector-tag">a</span><span class="hljs-selector-attr">[2]</span><br>Out<span class="hljs-selector-attr">[132]</span>: <span class="hljs-number">7</span><br><br>In <span class="hljs-selector-attr">[133]</span>: <span class="hljs-selector-tag">a</span><span class="hljs-selector-attr">[ 1 : 4 : 2]</span>###起始编号：终止编号(不含)：步长<br>Out<span class="hljs-selector-attr">[133]</span>: <span class="hljs-built_in">array</span>(<span class="hljs-selector-attr">[8,6]</span>)<br></code></pre></td></tr></table></figure><h3 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a>多维数组</h3><p><strong>索引</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">146</span>]: a = np.arrange(<span class="hljs-number">24</span>).reshape((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><br>In [<span class="hljs-number">147</span>]: a<br>Out[<span class="hljs-number">147</span>]:<br>array([[[<span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>    [<span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>],<br>    [<span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br>    <br>   [[<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>],<br>    [<span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>],<br>    [<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]]])<br><br>In [<span class="hljs-number">148</span>]: a[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>Out[<span class="hljs-number">148</span>]: <span class="hljs-number">23</span><br><br>In [<span class="hljs-number">149</span>]: a[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]<br>Out[<span class="hljs-number">149</span>]: <span class="hljs-number">6</span><br><br>In [<span class="hljs-number">150</span>]: a[-<span class="hljs-number">1</span>,-<span class="hljs-number">2</span>,-<span class="hljs-number">3</span>]<br>Out[<span class="hljs-number">150</span>]: <span class="hljs-number">17</span><br></code></pre></td></tr></table></figure><p><strong>切片</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">146</span>]: a = np.arrange(<span class="hljs-number">24</span>).reshape((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><br>In [<span class="hljs-number">147</span>]: a<br>Out[<span class="hljs-number">147</span>]:<br>array([[[<span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>    [<span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>],<br>    [<span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br>    <br>   [[<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>],<br>    [<span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>],<br>    [<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]]])<br>    <br>In [<span class="hljs-number">158</span>]: a[:,<span class="hljs-number">1</span>,-<span class="hljs-number">3</span>]<span class="hljs-comment">###a[第一个维度的要求，第二个维度的要求，第三个维度的要求]</span><br>Out[<span class="hljs-number">158</span>]: array([<span class="hljs-number">5</span>,<span class="hljs-number">17</span>])<span class="hljs-comment">###选取一个维度用：</span><br><br>In [<span class="hljs-number">159</span>]: a[:,<span class="hljs-number">1</span>:<span class="hljs-number">3</span>,:]<br>Out[<span class="hljs-number">159</span>]:<br>array([[[<span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>],<br>    [<span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br>    <br>   [[<span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>],<br>    [<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]]])<br>    <br>In [<span class="hljs-number">160</span>]: a[:,:,::<span class="hljs-number">2</span>]<span class="hljs-comment">###每个维度可以使用步长跳跃切片</span><br>Out[<span class="hljs-number">160</span>]:<br>array([[[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>],<br>    [<span class="hljs-number">4</span>,<span class="hljs-number">6</span>],<br>    [<span class="hljs-number">8</span>,<span class="hljs-number">10</span>]],<br>    <br>   [[<span class="hljs-number">12</span>,<span class="hljs-number">14</span>],<br>    [<span class="hljs-number">16</span>,<span class="hljs-number">18</span>],<br>    [<span class="hljs-number">20</span>,<span class="hljs-number">22</span>]]])<br></code></pre></td></tr></table></figure><h2 id="ndarry数组的运算"><a href="#ndarry数组的运算" class="headerlink" title="ndarry数组的运算"></a>ndarry数组的运算</h2><h3 id="数组与标量之间的运算"><a href="#数组与标量之间的运算" class="headerlink" title="数组与标量之间的运算"></a>数组与标量之间的运算</h3><p>数组与标量之间的运算作用域数组的每一个元素</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">###实例：计算a与元素平均值的商</span><br><br>In [<span class="hljs-number">146</span>]: a = np.arrange(<span class="hljs-number">24</span>).reshape((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><br>In [<span class="hljs-number">147</span>]: a<br>Out[<span class="hljs-number">147</span>]:<br>array([[[<span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>    [<span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>],<br>    [<span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br>    <br>   [[<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>],<br>    [<span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>],<br>    [<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]]])<br>    <br>In [<span class="hljs-number">169</span>]: a.mean()<br>Out[<span class="hljs-number">169</span>]: <span class="hljs-number">11.5</span><br><br>In [<span class="hljs-number">170</span>]: a = a / a.mean()<br><br>In [<span class="hljs-number">171</span>]: a<br>Out[<span class="hljs-number">171</span>]:<br>array([[[<span class="hljs-number">0.</span>   ,<span class="hljs-number">0.08695652</span>,<span class="hljs-number">0.17391304</span>,<span class="hljs-number">0.26086957</span>],<br>    [<span class="hljs-number">0.34782609</span>,<span class="hljs-number">0.43478261</span>,<span class="hljs-number">0.52173913</span>,<span class="hljs-number">0.60869565</span>],<br>    [<span class="hljs-number">0.69565217</span>,<span class="hljs-number">0.7826087</span> ,<span class="hljs-number">0.86956522</span>,<span class="hljs-number">0.95652174</span>]],<br>    <br>   [[<span class="hljs-number">1.04347826</span>,<span class="hljs-number">1.13043478</span>,<span class="hljs-number">1.2173913</span> ,<span class="hljs-number">1.30434783</span>],<br>    [<span class="hljs-number">1.39130435</span>,<span class="hljs-number">1.47826087</span>,<span class="hljs-number">1.56521739</span>,<span class="hljs-number">1.65217391</span>],<br>    [<span class="hljs-number">1.73913043</span>,<span class="hljs-number">1.82608696</span>,<span class="hljs-number">1.91304348</span>,<span class="hljs-number">2.</span>    ]]])<br></code></pre></td></tr></table></figure><h3 id="NumPy一元函数"><a href="#NumPy一元函数" class="headerlink" title="NumPy一元函数"></a>NumPy一元函数</h3><p>对ndarray中的数据执行元素级运算的函数</p><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>np.abs(x)    np.fabs(x)</td><td>计算数组各元素的绝对值</td></tr><tr><td>np.sqrt(x)</td><td>计算数组个元素的平方根</td></tr><tr><td>np.square(x)</td><td>计算数组各元素的平方</td></tr><tr><td>np.log(x) np.log10(x) np.log2(x)</td><td>计算数组各元素的自然对数、10底对数和2底对数</td></tr><tr><td>np.ceil(x) np.floor(x)</td><td>计算数组各元素的ceiling值或floor值</td></tr><tr><td>np.rint(x)</td><td>计算数组各元素的四舍五入值</td></tr><tr><td>np.modf(x)</td><td>将数组各元素的小数和整数部分以两个独立数组形式返回</td></tr><tr><td>np.cos(x) np.cosh(x)<br />np.sin(x) np.sinh(x)<br />np.tan(x) np.tanh(x)</td><td>计算数组各元素的普通型和双曲型三角函数</td></tr><tr><td>np.exp(x)</td><td>计算数组各元素的指数值</td></tr><tr><td>np.sign(x)</td><td>计算数组各元素的符号值，1(+),0,-1(-)</td></tr></tbody></table></div><p><strong>注意数组是否被真实改变</strong></p><img src="/2024/04/30/20240430_numPy/image-20240509213311585.png" class="" title="image-20240509213311585"><h3 id="NumPy二元函数"><a href="#NumPy二元函数" class="headerlink" title="NumPy二元函数"></a>NumPy二元函数</h3><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>+ - <em> / *</em></td><td>两个数组各元素进行对应运算</td></tr><tr><td>np.maximum(x,y) np.fmax()<br />np.minimum(x,y) np.fmin()</td><td>元素级的最大值、最小值计算</td></tr><tr><td>np.mod(x,y)</td><td>元素级的模运算</td></tr><tr><td>np.copysign(x,y)</td><td>将数组y中各元素的符号赋值给数组x对应元素</td></tr><tr><td>&gt; &lt; &gt;= &lt;= == !=</td><td>算数比较，产生布尔型数组</td></tr></tbody></table></div><img src="/2024/04/30/20240430_numPy/image-20240509213328557.png" class="" title="image-20240509213328557"><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><img src="/2024/04/30/20240430_numPy/image-20240509213349887.png" class="" title="image-20240509213349887"><h1 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h1><h2 id="一维：CSV文件存取"><a href="#一维：CSV文件存取" class="headerlink" title="一维：CSV文件存取"></a>一维：CSV文件存取</h2><p>CSV是一种常见的文件格式，用来存储批量数据</p><p>局限性：只能有效存储一维和二维数组</p><img src="/2024/04/30/20240430_numPy/image-20240509220524222.png" class="" title="image-20240509220524222"><h3 id="savetxt"><a href="#savetxt" class="headerlink" title="savetxt"></a>savetxt</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">np.savetxt(frame,array,fmt=<span class="hljs-string">&#x27;%.18e&#x27;</span>,delimiter=<span class="hljs-literal">None</span>)<br><span class="hljs-comment">#frame: 文件、字符串或产生器，可以是.gz或.bz2的压缩文件</span><br><span class="hljs-comment">#array：存入文件的数组</span><br><span class="hljs-comment">#fmt: 写入文件的格式，例如：%d %.2f %.18e</span><br><span class="hljs-comment">#delimiter: 分割字符串，默认是任何空格</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">a = np.arange(<span class="hljs-number">100</span>).reshape(<span class="hljs-number">5</span>,<span class="hljs-number">20</span>)<br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240509222102454.png" class="" title="image-20240509222102454"><h3 id="loadtxt"><a href="#loadtxt" class="headerlink" title="loadtxt"></a>loadtxt</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">np.loadtxt(frame,dtype=np.<span class="hljs-built_in">float</span>,delimiter=<span class="hljs-literal">None</span>,unpack=<span class="hljs-literal">False</span>)<br><span class="hljs-comment">#frame: 文件、字符串或产生器，可以是.gz或.bz2的压缩文件</span><br><span class="hljs-comment">#dtype：数据类型，可选</span><br><span class="hljs-comment">#delimiter：分割字符串，默认是任何空格</span><br><span class="hljs-comment">#unpack：如果True，读入属性将分别写入不同变量</span><br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240509223340872.png" class="" title="image-20240509223340872"><h2 id="多维数据存取"><a href="#多维数据存取" class="headerlink" title="多维数据存取"></a>多维数据存取</h2><h3 id="tofile"><a href="#tofile" class="headerlink" title="tofile"></a>tofile</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">a.tofile(frame,sep=<span class="hljs-string">&#x27;&#x27;</span>,<span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%s&#x27;</span>)<br><br><span class="hljs-comment"># frame : 文件、字符串</span><br><span class="hljs-comment"># sep   ：数据分割字符串，如果是空串，写入文件为二进制</span><br><span class="hljs-comment"># format：写入数据的格式</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">125</span>]: a = np.arange(<span class="hljs-number">100</span>).reshape(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br>In [<span class="hljs-number">126</span>]: a.tofile(<span class="hljs-string">&quot;b.dat&quot;</span>,sep=<span class="hljs-string">&quot;,&quot;</span>,<span class="hljs-built_in">format</span>=<span class="hljs-string">&quot;%d&quot;</span>)<br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240510113434901.png" class="" title="image-20240510113434901"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">127</span>]: a = np.arange(<span class="hljs-number">100</span>).reshape(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br>In [<span class="hljs-number">128</span>]: a.tofile(<span class="hljs-string">&quot;b.dat&quot;</span>,<span class="hljs-built_in">format</span>=<span class="hljs-string">&quot;%d&quot;</span>)<br><span class="hljs-comment">#如果不知道分割符，则生成二进制文件，二进制文件占用更小的空间</span><br><span class="hljs-comment">#看不到内容，只能作为数据备份的一种方式</span><br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240510113721159.png" class="" title="image-20240510113721159"><h3 id="fromfile"><a href="#fromfile" class="headerlink" title="fromfile"></a>fromfile</h3><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">np.fromfile<span class="hljs-params">(frame,<span class="hljs-attr">dtype</span>=float,<span class="hljs-attr">cont</span>=-1,<span class="hljs-attr">sep</span>=&#x27;&#x27;)</span><br><span class="hljs-comment"># frame:文件、字符串</span><br><span class="hljs-comment"># dtype:读取的数据类型</span><br><span class="hljs-comment"># count:读入元素个数，-1表示读入整个文件</span><br><span class="hljs-comment"># sep:数据分割字符串，如果是空串，写入文件为二进制</span><br></code></pre></td></tr></table></figure><h4 id="文本文件"><a href="#文本文件" class="headerlink" title="文本文件"></a>文本文件</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">129</span>]: a = np.arange(<span class="hljs-number">100</span>).reshape(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br>In [<span class="hljs-number">130</span>]: a.tofile(<span class="hljs-string">&quot;b.dat&quot;</span>,sep=<span class="hljs-string">&quot;,&quot;</span>,<span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>In [<span class="hljs-number">131</span>]: c = np.fromfile(<span class="hljs-string">&quot;b.dat&quot;</span>,dtype=np.<span class="hljs-built_in">int</span>,sep=<span class="hljs-string">&quot;,&quot;</span>)<br>In [<span class="hljs-number">132</span>]: c<br>Out[<span class="hljs-number">132</span>]: array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,...,<span class="hljs-number">97</span>,<span class="hljs-number">98</span>,<span class="hljs-number">99</span>])<br>In [<span class="hljs-number">133</span>]: c = np.fromfile(<span class="hljs-string">&quot;b.dat&quot;</span>,dtype=np.<span class="hljs-built_in">int</span>,sep=<span class="hljs-string">&quot;,&quot;</span>).reshape(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br>In [<span class="hljs-number">134</span>]: c<br>Out[<span class="hljs-number">134</span>]:<br>array([[[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],<br>    [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>],<br>    ...,<br>    [<span class="hljs-number">14</span>,<span class="hljs-number">15</span>],<br>    [<span class="hljs-number">16</span>,<span class="hljs-number">17</span>],<br>    [<span class="hljs-number">18</span>,<span class="hljs-number">19</span>]],<br></code></pre></td></tr></table></figure><h4 id="二进制文件"><a href="#二进制文件" class="headerlink" title="二进制文件"></a>二进制文件</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus">In <span class="hljs-selector-attr">[125]</span>: <span class="hljs-selector-tag">a</span> = np<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">100</span>)<span class="hljs-selector-class">.reshape</span>(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br>In <span class="hljs-selector-attr">[136]</span>: <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.tofile</span>(<span class="hljs-string">&quot;b.dat&quot;</span>,format=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>In <span class="hljs-selector-attr">[137]</span>: c = np<span class="hljs-selector-class">.fromfile</span>(<span class="hljs-string">&quot;b.dat&quot;</span>,dtype=np.int)<span class="hljs-selector-class">.reshape</span>(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<br>In <span class="hljs-selector-attr">[138]</span>: c<br>Out<span class="hljs-selector-attr">[138]</span>:<br><span class="hljs-built_in">array</span>(<span class="hljs-selector-attr">[[[0,1]</span>,<br>    <span class="hljs-selector-attr">[2,3]</span>,<br>    <span class="hljs-selector-attr">[4,5]</span>,<br>    ...,<br>    <span class="hljs-selector-attr">[14,15]</span>,<br>    <span class="hljs-selector-attr">[16,17]</span>,<br>    <span class="hljs-selector-attr">[18,19]</span>],<br></code></pre></td></tr></table></figure><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ul><li>该方法需要读取时知道存入文件时数组的维度和元素类型</li><li>a.tofile()和np.fromfile()需要配合使用</li><li>可以通过元素据文件来存储额外信息</li></ul><h2 id="NumPy的便捷文件存取"><a href="#NumPy的便捷文件存取" class="headerlink" title="NumPy的便捷文件存取"></a>NumPy的便捷文件存取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">np.save(fname,array)或np.savez(fname,array)<br><span class="hljs-comment"># frame:文件名，以.npy为扩展名，压缩扩展名为.npz</span><br><span class="hljs-comment"># array:数组变量</span><br>np.load(fname)<br><span class="hljs-comment"># fname:文件名，以.npy为扩展名，压缩扩展名为.npz</span><br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240510120735787.png" class="" title="image-20240510120735787"><h1 id="NumPy函数"><a href="#NumPy函数" class="headerlink" title="NumPy函数"></a>NumPy函数</h1><h2 id="随机数函数子库"><a href="#随机数函数子库" class="headerlink" title="随机数函数子库"></a>随机数函数子库</h2><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>rand(d0,d1,..,dn)</td><td>根据d0-dn创建随机数数组，浮点数，[0,1)，均匀分布</td></tr><tr><td>randn(d0,d1,..,dn)</td><td>根据d0-d  n创建随机数数组，标准正态分布</td></tr><tr><td>randint(low[,high,shape])</td><td>根据shape创建随机整数或整数数组，范围时[low,high)</td></tr><tr><td>seed(s)</td><td>随机数种子，s时给定的种子值</td></tr></tbody></table></div><img src="/2024/04/30/20240430_numPy/image-20240510154944785.png" class="" title="image-20240510154944785"><img src="/2024/04/30/20240430_numPy/image-20240510155229646.png" class="" title="image-20240510155229646"><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>shuffle(a)</td><td>根据数组a的第1轴进行随排列，改变数组x</td></tr><tr><td>permutation(a)</td><td>根据数组a的第一轴产生一个新的乱序数组，不改变数组x</td></tr><tr><td>choice(a[,size,replace,p])</td><td>从一维数组中以概率p抽取元素，形成size形状新数组<br />replace表示是否可以重用元素，默认为False</td></tr></tbody></table></div><img src="/2024/04/30/20240430_numPy/image-20240513213509000.png" class="" title="image-20240513213509000"><img src="/2024/04/30/20240430_numPy/image-20240513213522365.png" class="" title="image-20240513213522365"><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>uniform(low,high,size)</td><td>产生具有均匀分布的数组，low起始值，high结束值，size形状</td></tr><tr><td>normal(loc,scale,size)</td><td>产生具有正态分布的数组，loc均值，scale标准差，size形状</td></tr><tr><td>poisson(lam,size)</td><td>产生具有泊松分布的数组，lam随机事件发生率，size形状</td></tr></tbody></table></div><img src="/2024/04/30/20240430_numPy/image-20240513214549045.png" class="" title="image-20240513214549045"><h2 id="统计函数"><a href="#统计函数" class="headerlink" title="统计函数"></a>统计函数</h2><p>NumPy直接提供的统计累函数，可以直接np.*使用</p><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>sum(a,axis=None)</td><td>根据给定轴axis计算数组a相关元素之和，axis整数或元组</td></tr><tr><td>mean(a,axis=None)</td><td>根据给定轴axis计算数组相关元素的期望，axis整数或元组</td></tr><tr><td>average(a,axis=None,weights=None)</td><td>根据给定轴axis计算数组a相关元素的加权平均值</td></tr><tr><td>std(a,axis=None)</td><td>根据给定轴axis计算数组a相关元素的标准差</td></tr><tr><td>var(a,axis=None)</td><td>根据给定轴axis计算数组a相关元素的方差</td></tr></tbody></table></div><img src="/2024/04/30/20240430_numPy/image-20240513220237680.png" class="" title="image-20240513220237680"><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>min(a) max(a)</td><td>计算数组a中元素的最小值、最大值</td></tr><tr><td>argmin(a) argmax(a)</td><td>计算数组a中元素最小值、最大值的降一维后下标</td></tr><tr><td>unravel_index(index,shape)</td><td>根据shape将一维下标index转换成多维下标</td></tr><tr><td>ptp(a)</td><td>计算数组a中元素最大值与最小值的差</td></tr><tr><td>median(a)</td><td>计算数组a中元素的中位数(中值)</td></tr></tbody></table></div> <img src="/2024/04/30/20240430_numPy/image-20240513221333288.png" class="" title="image-20240513221333288"><h2 id="梯度函数"><a href="#梯度函数" class="headerlink" title="梯度函数"></a>梯度函数</h2><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>np.gradient(f)</td><td>计算数组f中元素的梯度，当f为多维时，返回每个维度梯度</td></tr></tbody></table></div><p>梯度：连续值之间的变化率，即斜率</p><p>XY坐标轴连续三个X坐标对应的Y轴值：a,b,c，其中，b的梯度是：(c-a)/2</p><img src="/2024/04/30/20240430_numPy/image-20240513222346917.png" class="" title="image-20240513222346917"><p>如果数组是n维，的那么gradient生成n个数组</p><img src="/2024/04/30/20240430_numPy/image-20240513222627439.png" class="" title="image-20240513222627439"><h1 id="图像的手绘效果"><a href="#图像的手绘效果" class="headerlink" title="图像的手绘效果"></a>图像的手绘效果</h1><h2 id="图像的数组表示"><a href="#图像的数组表示" class="headerlink" title="图像的数组表示"></a>图像的数组表示</h2><p>图像一般使用RGB色彩模式，即每个像素点的颜色由红(R)、绿(G)、蓝(B)组成，其中每个通道的取值范围均为0-255，叠加起来色彩空间为255^3。RGB形成的颜色包括了人类视力所能感知的所有颜色。</p><h3 id="PIL库"><a href="#PIL库" class="headerlink" title="PIL库"></a>PIL库</h3><p>一个具有强大图像处理能力的第三方库。</p><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs capnproto">pip install pillow<span class="hljs-comment">#安装</span><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image <span class="hljs-comment">#Image是PIL库代表一个图像的类（对象）</span><br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240514210910331.png" class="" title="image-20240514210910331"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">64</span>]:<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br>In [<span class="hljs-number">65</span>]:<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>In [<span class="hljs-number">66</span>]:im = np.array(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;D:/pycodes/demo.jpg&quot;</span>))<br>In [<span class="hljs-number">67</span>]:<span class="hljs-built_in">print</span>(im.shape,im.dtype)<br>(<span class="hljs-number">669</span>,<span class="hljs-number">1012</span>,<span class="hljs-number">3</span>)uint8<br><span class="hljs-comment">###图像是一个三维数组，维度分别是高度、宽度和像素RGB值</span><br></code></pre></td></tr></table></figure><h2 id="图像的变换"><a href="#图像的变换" class="headerlink" title="图像的变换"></a>图像的变换</h2><p>读入图像后，获得像素RGB值，修改后保存为新的文件。</p><img src="/2024/04/30/20240430_numPy/image-20240514212717293.png" class="" title="image-20240514212717293"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">In [<span class="hljs-number">81</span>]:<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br>In [<span class="hljs-number">82</span>]:<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>In [<span class="hljs-number">83</span>]:a = np.array(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;D:/demo.jpg&quot;</span>))<br>In [<span class="hljs-number">84</span>]:<span class="hljs-built_in">print</span>(a.shape,a.dtype)<br>(<span class="hljs-number">669</span>,<span class="hljs-number">1012</span>,<span class="hljs-number">3</span>)uint8<br>In [<span class="hljs-number">85</span>]:b = [<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>]-a<br>In [<span class="hljs-number">86</span>]:im = Image.fromarray(b.astype(<span class="hljs-string">&#x27;uint8&#x27;</span>))<br>In [<span class="hljs-number">87</span>]:im.save(<span class="hljs-string">&quot;D:/demo1.jpg&quot;</span>)<br></code></pre></td></tr></table></figure><img src="/2024/04/30/20240430_numPy/image-20240514214108604.png" class="" title="image-20240514214108604"><img src="/2024/04/30/20240430_numPy/image-20240514214252567.png" class="" title="image-20240514214252567"><img src="/2024/04/30/20240430_numPy/image-20240514214352038.png" class="" title="image-20240514214352038"><h2 id="“图像手绘效果”实例分析"><a href="#“图像手绘效果”实例分析" class="headerlink" title="“图像手绘效果”实例分析"></a>“图像手绘效果”实例分析</h2><p>手绘效果几个特征：黑白灰色，线条比较重，相同或相近色彩趋于白色，略有光源效果</p><p>利用像素之间的梯度值和虚拟深度值对图像进行重构</p><p>根据灰度变化来模拟人类视觉明暗程度</p><img src="/2024/04/30/20240430_numPy/image-20240514220453292.png" class="" title="image-20240514220453292"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.asarray(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;G:/1.jpg&#x27;</span>).convert(<span class="hljs-string">&#x27;L&#x27;</span>)).astype(<span class="hljs-string">&#x27;float&#x27;</span>)<br><br>depth = <span class="hljs-number">10.</span><span class="hljs-comment">#预设深度值为10，取值范围(0-100)</span><br>grad = np.gradient(a) <span class="hljs-comment">#取图像灰度的梯度值，表示灰度的变化率</span><br>grad_x,grad_y = grad <span class="hljs-comment">#分别取横纵图像梯度值</span><br>grad_x = grad_x*depth/<span class="hljs-number">100.</span><br>grad_y = grad_y*depth/<span class="hljs-number">100.</span> <span class="hljs-comment">#根据深度调整x和y方向的梯度值</span><br><br>A = np.sqrt(grad_x**<span class="hljs-number">2</span> + grad_y**<span class="hljs-number">2</span> + <span class="hljs-number">1.</span>)  <span class="hljs-comment">#构造x和y轴梯度的三维归一单位坐标系</span><br><br>uni_x = grad_x/A<br>uni_y = grad_y/A<br>uni_z = <span class="hljs-number">1.</span>/A<br><br>vec_el = np.pi/<span class="hljs-number">2.2</span> <span class="hljs-comment">#光源的俯视角度，弧度值</span><br>vec_az = np.pi/<span class="hljs-number">4.</span> <span class="hljs-comment">#光源的方位角度，弧度值</span><br>dx = np.cos(vec_el)*np.cos(vec_az)   <span class="hljs-comment">#光源对x轴的影响，np.cos(vec_el)为单位光线在地平面的投影长度</span><br>dy = np.cos(vec_el)*np.sin(vec_az)   <span class="hljs-comment">#光源对y轴的影响</span><br>dz = np.sin(vec_el)  <span class="hljs-comment">#光源对z轴的影响</span><br><br>b = <span class="hljs-number">255</span>*(dx*uni_x +dy*uni_y +dz*uni_z)   <span class="hljs-comment">#光源归一化，梯度与光源相互作用，将梯度转化为灰度？？？？</span><br>b = b.clip(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>) <span class="hljs-comment">#为避免数据越界，将生成的灰度值裁剪至0-255区间</span><br><br>im = Image.fromarray(b.astype(<span class="hljs-string">&#x27;uint8&#x27;</span>))<span class="hljs-comment">#重构图像</span><br>im.save(<span class="hljs-string">&#x27;G:\\1hd.jpg&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>数据分析与展示</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据分析</tag>
      
      <tag>分析工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计划</title>
    <link href="/2024/04/29/20240429_daliylogs/"/>
    <url>/2024/04/29/20240429_daliylogs/</url>
    
    <content type="html"><![CDATA[<ul><li><p>Python及爬虫</p><ul><li>Python面向对象编程五部曲(上、中、下)</li></ul></li><li>数据分析与展示<ul><li>慕课北理工np，pandas…<ul><li><strong>240513 NumPu数据存储与函数</strong> <strong>240513</strong></li><li><strong>240514 图像的手绘效果</strong> <strong>240514</strong></li><li><strong>240516 Matplotlib入门</strong> <strong>240515</strong></li><li><strong>240518 Matploylib基础绘图函数示例 240516</strong></li><li><strong>240520 引力波的绘制 240516</strong></li><li><strong>240522 Pandas库入门 240518</strong></li><li><strong>240524 Pandas数据特征分析 240518</strong></li></ul></li></ul></li><li>光纤类课程<br>- </li><li>机器学习<ul><li>吴恩达Deeplearning.ai<ul><li>六月中下</li></ul></li><li>浙大胡浩基老师机器学习<ul><li><strong>240519 引言 240521</strong></li><li>240520 支持向量机</li><li>240525 人工神经网络</li><li>240530 深度学习</li><li>240605 强化学习</li><li>240610 传统机器学习</li></ul></li></ul></li><li>统计学习方法-李航+白板推导教程<ul><li>七月</li></ul></li><li>深度学习工具<ul><li>龙曲良TensorFlow2与Pytorch(多些)<ul><li>网易深度学习与PyTorch</li></ul></li><li>李沐动手学机器学习</li></ul></li><li>看论文改模型</li><li>学习标注自己的数据集</li><li>数据库</li><li>信号处理</li></ul><ul><li>唐宇迪opencv</li><li>跑一下YOLO、SSD、R-CNN传统目标检测模型</li></ul>]]></content>
    
    
    <categories>
      
      <category>不破不立</category>
      
    </categories>
    
    
    <tags>
      
      <tag>成长</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python与爬虫</title>
    <link href="/2024/04/22/20240422_crawler/"/>
    <url>/2024/04/22/20240422_crawler/</url>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>网络爬虫（又称为<a href="https://baike.baidu.com/item/网页蜘蛛/15696186?fromModule=lemma_inlink">网页蜘蛛</a>，网络机器人，在<a href="https://baike.baidu.com/item/FOAF/4916497?fromModule=lemma_inlink">FOAF</a>社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取<a href="https://baike.baidu.com/item/万维网/215515?fromModule=lemma_inlink">万维网</a>信息的<a href="https://baike.baidu.com/item/程序/13831935?fromModule=lemma_inlink">程序</a>或者<a href="https://baike.baidu.com/item/脚本/1697005?fromModule=lemma_inlink">脚本</a>。另外一些不常使用的名字还有蚂蚁、<a href="https://baike.baidu.com/item/自动索引/56622668?fromModule=lemma_inlink">自动索引</a>、<a href="https://baike.baidu.com/item/模拟程序/12726595?fromModule=lemma_inlink">模拟程序</a>或者蠕虫。</p><h2 id="场景分类"><a href="#场景分类" class="headerlink" title="场景分类"></a>场景分类</h2><ul><li>通用爬虫：抓取系统重要组成部分。抓取的是一整张页面数据。</li><li>聚焦爬虫：建立在通用爬虫基础上。抓取的是页面中特定的局部内容。</li><li>增量式爬虫：检测网站中数据更新的情况。只会抓取最新更新出来的数据。</li></ul><h1 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h1><h2 id="robots-txt协议"><a href="#robots-txt协议" class="headerlink" title="robots.txt协议"></a>robots.txt协议</h2><p>robots是告诉搜索引擎，你可以爬取收录我的什么页面，你不可以爬取和收录我的那些页面。robots很好的控制网站那些页面可以被爬取，那些页面不可以被爬取。</p><p><strong>主流的搜索引擎都会遵守robots协议</strong>。并且robots协议是爬虫爬取网站第一个需要爬取的文件。爬虫爬取robots文件后，会读取上面的协议，并准守协议爬取网站，收录网站。</p><p><strong>robots文件是一个纯文本文件，也就是常见的.txt文件</strong>。在这个文件中网站管理者可以声明该网站中不想被robots访问的部分，或者指定搜索引擎只收录指定的内容。因此，robots的优化会直接影响到搜索引擎对网站的收录情况。</p><img src="/2024/04/22/20240422_crawler/image-20240422170700595.png" class="" title="image-20240422170700595"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Crawl-delay: <span class="hljs-number">5</span> 指定爬虫访问间隔为<span class="hljs-number">5</span>秒<br></code></pre></td></tr></table></figure><p>注意事项</p><ol><li>不要禁止爬虫爬取网站的所有，因为从经验来看，如果屏蔽一次，解封后好一段时间爬虫都不会来你网站，收录成为问题。</li><li>代码后需要【冒号+空格+斜杆】 ，比如“Disallow: /<em>?</em> ”</li><li>当网站为静态路径时，需要屏蔽掉所有动态链接。网站中存在一种链接被收录即可，避免一个页面2个链接。代码如下“Disallow: /<em>?</em> ”表示禁止所有带 ?号的网址被爬取。通常动态网址带有“?”“=”等。</li><li>根据自己网站情况定，屏蔽不需要收录的网址。</li></ol><h1 id="伪装策略"><a href="#伪装策略" class="headerlink" title="伪装策略"></a>伪装策略</h1><p>我们知道即使是一些规模很小的网站通常也会对来访者的身份做一下检查，如验证请求 Headers，而对于那些上了一定规模的网站就更不用说了。因此，为了让我们的爬虫能够成功爬取所需数据信息，我们需要让爬虫进行伪装，简单来说就是让爬虫的行为变得像普通用户访问一样。</p><h2 id="Request-Headers问题"><a href="#Request-Headers问题" class="headerlink" title="Request Headers问题"></a>Request Headers问题</h2><img src="/2024/04/22/20240422_crawler/image-20240424001733029.png" class="" title="image-20240424001733029"><p>在上图中，我们可以看到 Request Headers 中包含 Referer 和 User-Agent 两个属性信息，Referer 的作用是告诉服务器该网页是从哪个页面链接过来的，User-Agent 中文是用户代理，它是一个特殊字符串头，作用是让服务器能够识别用户使用的操作系统、CPU 类型、浏览器等信息。通常的处理策略是：1）对于要检查 Referer 的网站就加上；2）对于每个 request 都添加 User-Agent。</p><h2 id="IP限制问题"><a href="#IP限制问题" class="headerlink" title="IP限制问题"></a>IP限制问题</h2><p>有时我们可能会对一些网站进行长期或大规模的爬取，而我们在爬取时基本不会变换 IP，有的网站可能会监控一个 IP 的访问频率和次数，一但超过这个阈值，就可能认作是爬虫，从而对其进行了屏蔽，对于这种情况，我们要采取间歇性访问的策略。</p><p>通常我们爬取是不会变换 IP 的，但有时可能会有一些特殊情况，要长时间不间断对某网站进行爬取，这时我们就可能需要采用 IP 代理的方式，但这种方式一般会增加我们开销，也就是可能要多花钱。</p><h1 id="Requests库"><a href="#Requests库" class="headerlink" title="Requests库"></a>Requests库</h1><p>所谓爬虫就是模拟客户端发送网络请求，获取网络响应，并按照一定的规则解析获取的数据并保存的程序。要说 Python 的爬虫必然绕不过 Requests 库。</p><h2 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h2><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey">Requests 唯一的一个非转基因的 Python HTTP 库，人类可以安全享用。警告：非专业使用其他 HTTP 库会导致危险的副作用，包括：安全缺陷症、冗余代码症、重新发明轮子症、啃文档症、抑郁、头疼、甚至死亡。<br>这个介绍还是比较生动形象的，便不再多说。安装使用终端命令 `pip install requests` 。<br></code></pre></td></tr></table></figure><h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><p>导入 Requests 模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br></code></pre></td></tr></table></figure><p>获取网页：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">r = requests.get(<span class="hljs-string">&#x27;http://xxx.xxx&#x27;</span>)<br></code></pre></td></tr></table></figure><p>此时，我们获取了 Response 对象 r，我们可以通过 r 获取所需信息。Requests 简便的 API 意味着所有 HTTP 请求类型都是显而易见的，我们来看一下使用常见 HTTP 请求类型 get、post、put、delete 的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">r = requests.head(<span class="hljs-string">&#x27;http://xxx.xxx/get&#x27;</span>)<br>r = requests.post(<span class="hljs-string">&#x27;http://xxx.xxx/post&#x27;</span>, data = &#123;<span class="hljs-string">&#x27;key&#x27;</span>:<span class="hljs-string">&#x27;value&#x27;</span>&#125;)<br>r = requests.put(<span class="hljs-string">&#x27;http://xxx.xxx/put&#x27;</span>, data = &#123;<span class="hljs-string">&#x27;key&#x27;</span>:<span class="hljs-string">&#x27;value&#x27;</span>&#125;)<br>r = requests.delete(<span class="hljs-string">&#x27;http://xxx.xxx/delete&#x27;</span>)<br></code></pre></td></tr></table></figure><p>通常我们会设置请求的超时时间，Requests 使用 <code>timeout</code> 参数来设置，单位是秒，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">r = requests.head(<span class="hljs-string">&#x27;http://xxx.xxx/get&#x27;</span>, timeout=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a>参数传递</h3><p>在使用 get 方式发送请求时，我们会将键值对形式参数放在 URL 中问号的后面，如：<code>http://xxx.xxx/get?key=val</code> ，Requests 通过 params 关键字，以一个字符串字典来提供这些参数。比如要传 <code>key1=val1</code> 和 <code>key2=val2</code> 到 <code>http://xxx.xxx/get</code>，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pms= &#123;<span class="hljs-string">&#x27;key1&#x27;</span>: <span class="hljs-string">&#x27;val1&#x27;</span>, <span class="hljs-string">&#x27;key2&#x27;</span>: <span class="hljs-string">&#x27;val2&#x27;</span>&#125;<br>r = requests.get(<span class="hljs-string">&quot;http://xxx.xxx/get&quot;</span>, params=pms)<br></code></pre></td></tr></table></figure><p>Requests 还允许将一个列表作为值传入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pms= &#123;<span class="hljs-string">&#x27;key1&#x27;</span>: <span class="hljs-string">&#x27;val1&#x27;</span>, <span class="hljs-string">&#x27;key2&#x27;</span>: [<span class="hljs-string">&#x27;val2&#x27;</span>, <span class="hljs-string">&#x27;val3&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure><p><strong><code>注</code></strong>：字典里值为 None 的键都不会被添加到 URL 的查询字符串里。</p><h3 id="响应内容"><a href="#响应内容" class="headerlink" title="响应内容"></a>响应内容</h3><p>我们来获取一下服务器的响应内容，这里地址 <code>https://api.github.com</code> 为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br>r = requests.get(<span class="hljs-string">&#x27;https://api.github.com&#x27;</span>)<br><span class="hljs-built_in">print</span>(r.text)<br><br><span class="hljs-comment"># 输出结果</span><br><span class="hljs-comment"># &#123;&quot;current_user_url&quot;:&quot;https://api.github.com/user&quot;,&quot;current_user...</span><br></code></pre></td></tr></table></figure><p>当访问 r.text 之时，Requests 会使用其推测的文本编码，我们可以使用 <code>r.encoding</code> 查看其编码，也可以修改编码，如：<code>r.encoding = &#39;GBK&#39;</code>，当改变了编码，再次访问 r.text 时，Request 都将会使用 r.encoding 的新值。</p><ol><li><p>二进制响应内容 比如当我们要获取一张图片的数据，会以二进制的方式获取响应数据，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO<br>r = requests.get(<span class="hljs-string">&#x27;https://mp.weixin.qq.com/mp/qrcode?scene=10000004&amp;size=102&amp;__biz=MzU3Mzk1ODA5OQ==&amp;mid=2247483907&amp;idx=1&amp;sn=0e2bcd8811313327582623246795a26e&amp;send_time=&#x27;</span>)<br>i = Image.<span class="hljs-built_in">open</span>(BytesIO(r.content))<br><span class="hljs-built_in">print</span>(i)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#&lt;PIL.BmpImagePlugin.BmpImageFile image mode=L size=129x129 at 0x22B7A7A8510&gt;</span><br></code></pre></td></tr></table></figure></li><li><p>JSON响应内容 Requests 中已经内置了 JSON 解码器，因此我们可以很容易的对 JSON 数据进行解析，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br>r = requests.get(<span class="hljs-string">&#x27;https://api.github.com&#x27;</span>)<br>r.json()<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#&#123;&#x27;current_user_url&#x27;: &#x27;https://api.github.com/user&#x27;, &#x27;current_user_authorizations_html_url&#x27;: &#x27;https://github.com/settings/connections/applications&#123;/client_id&#125;&#x27;, &#x27;authorizations_url&#x27;: &#x27;https://api.github.com/authorizations&#x27;, &#x27;code_search_url&#x27;: &#x27;https://api.github.com/search/code?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;&#x27;, &#x27;commit_search_url&#x27;: &#x27;https://api.github.com/search/commits?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;&#x27;,</span><br>......<br></code></pre></td></tr></table></figure><p><strong><code>注</code></strong>:成功调用 r.json() 并不一定响应成功，有的服务器会在失败的响应中包含一个 JSON 对象（比如 HTTP 500 的错误细节），这时我们就需要查看响应的状态码了 <code>r.status_code</code> 或 r.raise_for_status()，成功调用时 <code>r.status_code</code> 为 200，r.raise_for_status() 为 None。</p></li></ol><h3 id="自定义请求头"><a href="#自定义请求头" class="headerlink" title="自定义请求头"></a>自定义请求头</h3><p>当我们要给请求添加 headers 时，只需给 <code>headers</code> 参数传递一个字典即可，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">url = <span class="hljs-string">&#x27;http://xxx.xxx&#x27;</span><br>hds= &#123;<span class="hljs-string">&#x27;user-agent&#x27;</span>: <span class="hljs-string">&#x27;xxx&#x27;</span>&#125;<br>r = requests.get(url, headers=hds)<br></code></pre></td></tr></table></figure><p><code>注</code>：自定义 headers 优先级是低于一些特定的信息的，如：在 <code>.netrc</code> 中设置了用户认证信息，使用 headers 设置的授权就不会生效，而当设置了 <code>auth</code> 参数，<code>.netrc</code> 的设置会无效。所有的 headers 值必须是 string、bytestring 或者 unicode，通常不建议使用 unicode。</p><h3 id="重定向与历史"><a href="#重定向与历史" class="headerlink" title="重定向与历史"></a>重定向与历史</h3><p>默认情况下，Requests 会自动处理除了 HEAD 以外的所有重定向，可以使用响应对象的 <code>history</code> 属性来追踪重定向，其返回为响应对象列表，这个列表是按照请求由晚到早进行排序的，看一下示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br>r = requests.get(<span class="hljs-string">&#x27;http://github.com&#x27;</span>)<br><span class="hljs-built_in">print</span>(r.history)<br><br><span class="hljs-comment"># 输出结果</span><br><span class="hljs-comment"># [&lt;Response [301]&gt;]</span><br></code></pre></td></tr></table></figure><p>如果使用的是get、post、put、delete、options、patch 可以使用 <code>allow_redirects</code> 参数禁用重定向。示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">r = requests.get(<span class="hljs-string">&#x27;http://xxx.xxx&#x27;</span>, allow_redirects=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><h3 id="错误与异常"><a href="#错误与异常" class="headerlink" title="错误与异常"></a>错误与异常</h3><p>当遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出 ConnectionError 异常；在 HTTP 请求返回了不成功的状态码时， Response.raise_for_status() 会抛出 HTTPError 异常；请求超时，会抛出 Timeout 异常；请求超过了设定的最大重定向次数，会抛出 TooManyRedirects 异常。所有 Requests 显式抛出的异常都继承自 requests.exceptions.RequestException。</p><h1 id="BeautifulSoup库"><a href="#BeautifulSoup库" class="headerlink" title="BeautifulSoup库"></a>BeautifulSoup库</h1><p>BeautifulSoup 是一个可以从 HTML 或 XML 文件中提取数据的 Python 库，它能够将 HTML 或 XML 转化为可定位的树形结构，并提供了导航、查找、修改功能，它会自动将输入文档转换为 Unicode 编码，输出文档转换为 UTF-8 编码。</p><p>BeautifulSoup 支持 Python 标准库中的 HTML 解析器和一些第三方的解析器，默认使用 Python 标准库中的 HTML 解析器，默认解析器效率相对比较低，如果需要解析的数据量比较大或比较频繁，推荐使用更强、更快的 lxml 解析器。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="BeautifulSoup-安装"><a href="#BeautifulSoup-安装" class="headerlink" title="BeautifulSoup 安装"></a><strong>BeautifulSoup 安装</strong></h3><p>如果使用 Debain 或 ubuntu 系统，可以通过系统的软件包管理来安装：<code>apt-get install Python-bs4</code>，如果无法使用系统包管理安装，可以使用 <code>pip install beautifulsoup4</code> 来安装。</p><h3 id="第三方解析器安装"><a href="#第三方解析器安装" class="headerlink" title="第三方解析器安装"></a><strong>第三方解析器安装</strong></h3><p>如果需要使用第三方解释器 lxml 或 html5lib，可是使用如下命令进行安装：<code>apt-get install Python-lxml(html5lib)</code> 和 <code>pip install lxml(html5lib)</code>。</p><div class="table-container"><table><thead><tr><th style="text-align:center">解析器</th><th style="text-align:center"><strong>使用方法</strong></th><th style="text-align:center"><strong>优势</strong></th><th style="text-align:center"><strong>劣势</strong></th></tr></thead><tbody><tr><td style="text-align:center">Python标准库</td><td style="text-align:center">BeautifulSoup(markup,”html.parser”)</td><td style="text-align:center">Python的内置标准库；执行速度适中；文档容错能力强。</td><td style="text-align:center">Python 2.7.3 or 3.2.2前的版本中文档容错能力差。</td></tr><tr><td style="text-align:center">lxml HTML 解析器</td><td style="text-align:center">BeautifulSoup(markup,”lxml”)</td><td style="text-align:center">速度快；文档容错能力强。</td><td style="text-align:center">需要安装C语言库。</td></tr><tr><td style="text-align:center">lxml XML 解析器</td><td style="text-align:center"><code>BeautifulSoup(markup,[&quot;lxml-xml&quot;])``BeautifulSoup(markup,&quot;xml&quot;)</code></td><td style="text-align:center">速度快；唯一支持XML的解析器。</td><td style="text-align:center">需要安装C语言库</td></tr><tr><td style="text-align:center">html5lib</td><td style="text-align:center"><code>BeautifulSoup(markup,&quot;html5lib&quot;)</code></td><td style="text-align:center">最好的容错性；以浏览器的方式解析文档；生成HTML5格式的文档。</td><td style="text-align:center">速度慢；不依赖外部扩展。</td></tr></tbody></table></div><h2 id="快速上手-1"><a href="#快速上手-1" class="headerlink" title="快速上手"></a>快速上手</h2><p>将一段文档传入 BeautifulSoup 的构造方法，就能得到一个文档的对象，可以传入一段字符串或一个文件句柄，示例如下：</p><p><strong>index.html文件</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">html = <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">&lt;!DOCTYPE html&gt;</span><br><span class="hljs-string">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="hljs-string">&lt;head&gt;</span><br><span class="hljs-string">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="hljs-string">    &lt;title&gt;BeautifulSoup学习&lt;/title&gt;</span><br><span class="hljs-string">&lt;/head&gt;</span><br><span class="hljs-string">&lt;body&gt;</span><br><span class="hljs-string">Hello BeautifulSoup</span><br><span class="hljs-string">&lt;/body&gt;</span><br><span class="hljs-string">&lt;/html&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p><strong>使用示例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-comment">#使用默认解析器</span><br>soup = BeautifulSoup(html,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-comment">#使用 lxml 解析器</span><br>soup = BeautifulSoup(html,<span class="hljs-string">&#x27;lxml&#x27;</span>)<br></code></pre></td></tr></table></figure><p><strong>举例本地文件</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-comment">#使用默认解析器</span><br>soup = BeautifulSoup(html,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-comment">#使用 lxml 解析器</span><br>soup = BeautifulSoup(html,<span class="hljs-string">&#x27;lxml&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="对象的种类"><a href="#对象的种类" class="headerlink" title="对象的种类"></a>对象的种类</h2><p>BeautifulSoup 将 HTML 文档转换成一个树形结构，每个节点都是 Python 对象，所有对象可以归纳为4种：<code>Tag</code>，<code>NavigableString</code>，<code>BeautifulSoup</code>，<code>Comment</code>。</p><h3 id="Tag-对象"><a href="#Tag-对象" class="headerlink" title="Tag 对象"></a><strong>Tag 对象</strong></h3><p>Tag 对象与 HTML 或 XML 原生文档中的 tag 相同，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title&gt;BeautifulSoup学习&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;lxml&#x27;</span>)<br>tag = soup.title<br>tp =<span class="hljs-built_in">type</span>(tag)<br><span class="hljs-built_in">print</span>(tag)<br><span class="hljs-built_in">print</span>(tp)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">&lt;title&gt;BeautifulSoup学习&lt;/title&gt;</span><br><span class="hljs-string">&lt;class &#x27;bs4.element.Tag&#x27;&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>Tag 有很多方法和属性，这里先看一下它的的两种常用属性：<code>name</code> 和 <code>attributes</code>。</p><p>我们可以通过 <code>.name</code> 来获取 tag 的名字，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title&gt;BeautifulSoup学习&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;lxml&#x27;</span>)<br>tag = soup.title<br><span class="hljs-built_in">print</span>(tag.name)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#title</span><br></code></pre></td></tr></table></figure><p>我们还可以修改 tag 的 name，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tag.name = <span class="hljs-string">&#x27;title1&#x27;</span><br><span class="hljs-built_in">print</span>(tag)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#&lt;title1&gt;BeautifulSoup学习&lt;/title1&gt;</span><br></code></pre></td></tr></table></figure><p>一个 tag 可能有很多个属性，先看一它的 <code>class</code> 属性，其属性的操作方法与字典相同，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title class=&quot;tl&quot;&gt;BeautifulSoup学习&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;lxml&#x27;</span>)<br>tag = soup.title<br>cls = tag[<span class="hljs-string">&#x27;class&#x27;</span>]<br><span class="hljs-built_in">print</span>(cls)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#[&#x27;tl&#x27;]</span><br></code></pre></td></tr></table></figure><p>我们还可以使用 <code>.attrs</code> 来获取，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">ats = tag.attrs<br><span class="hljs-built_in">print</span>(ats)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#&#123;&#x27;class&#x27;: [&#x27;tl&#x27;]&#125;</span><br></code></pre></td></tr></table></figure><p>tag 的属性可以被添加、修改和删除，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#添加 id 属性</span><br>tag[<span class="hljs-string">&#x27;id&#x27;</span>] = <span class="hljs-number">1</span><br><br><span class="hljs-comment">#修改 class 属性</span><br>tag[<span class="hljs-string">&#x27;class&#x27;</span>] = <span class="hljs-string">&#x27;tl1&#x27;</span><br><br><span class="hljs-comment">#删除 class 属性</span><br><span class="hljs-keyword">del</span> tag[<span class="hljs-string">&#x27;class&#x27;</span>]<br></code></pre></td></tr></table></figure><h3 id="NavigableString-对象"><a href="#NavigableString-对象" class="headerlink" title="NavigableString 对象"></a><strong>NavigableString 对象</strong></h3><p>NavigableString 类是用来包装 tag 中的字符串内容的，使用 <code>.string</code> 来获取字符串内容，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">str</span> = tag.string<br></code></pre></td></tr></table></figure><p>可以使用 <code>replace_with()</code> 方法将原有字符串内容替换成其它内容 ，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tag.string.replace_with(<span class="hljs-string">&#x27;BeautifulSoup&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="BeautifulSoup-对象"><a href="#BeautifulSoup-对象" class="headerlink" title="BeautifulSoup 对象"></a><strong>BeautifulSoup 对象</strong></h3><p>BeautifulSoup 对象表示的是一个文档的全部内容，它并不是真正的 HTML 或 XML 的 tag，因此它没有 <code>name</code> 和 <code>attribute</code> 属性，为方便查看它的 <code>name</code> 属性，BeautifulSoup 对象包含了一个值为 <code>[document]</code> 的特殊属性 <code>.name</code>，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title class=&quot;tl&quot;&gt;BeautifulSoup学习&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;lxml&#x27;</span>)<br><span class="hljs-built_in">print</span>(soup.name)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#[document]</span><br></code></pre></td></tr></table></figure><h3 id="Comment-对象"><a href="#Comment-对象" class="headerlink" title="Comment 对象"></a><strong>Comment 对象</strong></h3><p>Comment 对象是一个特殊类型的 NavigableString 对象，它会使用特殊的格式输出，看一下例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title class=&quot;tl&quot;&gt;Hello BeautifulSoup&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>comment = soup.title.prettify()<br><span class="hljs-built_in">print</span>(comment)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">&lt;title class=&quot;tl&quot;&gt;</span><br><span class="hljs-string"> Hello BeautifulSoup</span><br><span class="hljs-string">&lt;/title&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>我们前面看的例子中 tag 中的字符串内容都不是注释内容，现在将字符串内容换成注释内容，我们来看一下效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title class=&quot;tl&quot;&gt;&lt;!--Hello BeautifulSoup--&gt;&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-built_in">str</span> = soup.title.string<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">str</span>)<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#Hello BeautifulSoup</span><br></code></pre></td></tr></table></figure><p>通过结果我们发现注释符号 <code>&lt;!----&gt;</code> 被自动去除了，这一点我们要注意一下。</p><h2 id="搜索文档树"><a href="#搜索文档树" class="headerlink" title="搜索文档树"></a><strong>搜索文档树</strong></h2><p>BeautifulSoup 定义了很多搜索方法。</p><p><strong>find_all()</strong></p><p>find_all() 方法搜索当前 tag 的所有 tag 子节点，方法详细如下：<code>find_all(name=None, attrs=&#123;&#125;, recursive=True, text=None,limit=None, **kwargs)</code>，来具体看一下各个参数。</p><p><code>name</code> 参数可以查找所有名字为 <code>name</code> 的 tag，字符串对象会被自动忽略掉，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title class=&quot;tl&quot;&gt;Hello BeautifulSoup&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-built_in">print</span>(soup.find_all(<span class="hljs-string">&#x27;title&#x27;</span>))<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#[&lt;title class=&quot;tl&quot;&gt;Hello BeautifulSoup&lt;/title&gt;]</span><br></code></pre></td></tr></table></figure><p><code>attrs</code> 参数定义一个字典参数来搜索包含特殊属性的 tag，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;title class=&quot;tl&quot;&gt;Hello BeautifulSoup&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>soup.find_all(attrs=&#123;<span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;tl&quot;</span>&#125;)<br></code></pre></td></tr></table></figure><p>调用 find_all() 方法时，默认会检索当前 tag 的所有子孙节点，通过设置参数 <code>recursive=False</code>，可以只搜索 tag 的直接子节点，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;html&gt;&lt;head&gt;&lt;title&gt;Hello BeautifulSoup&lt;/title&gt;&lt;/head&gt;&lt;/html&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-built_in">print</span>(soup.find_all(<span class="hljs-string">&#x27;title&#x27;</span>,recursive=<span class="hljs-literal">False</span>))<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#[]</span><br></code></pre></td></tr></table></figure><p>通过 <code>text</code> 参数可以搜搜文档中的字符串内容，它接受字符串、正则表达式、列表、True，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> re<br><br>soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;head&gt;myHead&lt;/head&gt;&lt;title&gt;BeautifulSoup&lt;/title&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-comment">#字符串</span><br>soup.find_all(text=<span class="hljs-string">&#x27;BeautifulSoup&#x27;</span>)<br><span class="hljs-comment">#[&#x27;BeautifulSoup&#x27;]</span><br><br><span class="hljs-comment">#正则表达式</span><br>soup.find_all(soup.find_all(text=re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">&#x27;title&#x27;</span>)))<br><span class="hljs-comment">#[&lt;head&gt;myHead&lt;/head&gt;, &lt;title&gt;BeautifulSoup&lt;/title&gt;]</span><br><br><span class="hljs-comment">#列表</span><br>soup.find_all(soup.find_all(text=[<span class="hljs-string">&#x27;head&#x27;</span>,<span class="hljs-string">&#x27;title&#x27;</span>]))<br><span class="hljs-comment">#[&lt;head&gt;myHead&lt;/head&gt;, &lt;title&gt;BeautifulSoup&lt;/title&gt;]</span><br><br><span class="hljs-comment">#True</span><br>soup.find_all(text=<span class="hljs-literal">True</span>)<br><span class="hljs-comment">#[&#x27;myHead&#x27;, &#x27;BeautifulSoup&#x27;]</span><br></code></pre></td></tr></table></figure><p><code>limit</code> 参数与 SQL 中的 <code>limit</code> 关键字类似，用来限制搜索的数据，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;a id=&quot;link1&quot; href=&quot;http://example.com/elsie&quot;&gt;Elsie&lt;/a&gt;&lt;a id=&quot;link2&quot; href=&quot;http://example.com/elsie&quot;&gt;Elsie&lt;/a&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>soup.find_all(<span class="hljs-string">&#x27;a&#x27;</span>, limit=<span class="hljs-number">1</span>)<br><span class="hljs-comment">#[&lt;a href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]</span><br></code></pre></td></tr></table></figure><p>我们经常见到 Python 中 <code>*arg</code> 和 <code>**kwargs</code> 这两种可变参数，<code>*arg</code> 表示非键值对的可变数量的参数，将参数打包为 tuple 传递给函数；<code>**kwargs</code> 表示关键字参数，参数是键值对形式的，将参数打包为 dict 传递给函数。</p><p>使用多个指定名字的参数可以同时过滤 tag 的多个属性，如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;a id=&quot;link1&quot; href=&quot;http://example.com/elsie&quot;&gt;Elsie&lt;/a&gt;&lt;a id=&quot;link2&quot; href=&quot;http://example.com/elsie&quot;&gt;Elsie&lt;/a&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>soup.find_all(href=re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">&quot;elsie&quot;</span>),<span class="hljs-built_in">id</span>=<span class="hljs-string">&#x27;link1&#x27;</span>)<br><span class="hljs-comment">#[&lt;a href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]</span><br></code></pre></td></tr></table></figure><p>有些 tag 属性在搜索不能使用，如 HTML5 中的 <code>data-*</code> 属性，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;div data-foo=&quot;value&quot;&gt;foo!&lt;/div&gt;&#x27;</span>)<br>soup.find_all(data-foo=<span class="hljs-string">&#x27;value&#x27;</span>)<br></code></pre></td></tr></table></figure><p>首先当我在 Pycharm 中输入 <code>data-foo=&#39;value&#39;</code> 便提示语法错误了，然后我不管提示直接执行提示 <code>SyntaxError: keyword can&#39;t be an expression</code> 这个结果也验证了 <code>data-*</code> 属性在搜索中不能使用。我们可以通过 find_all() 方法的 <code>attrs</code> 参数定义一个字典参数来搜索包含特殊属性的 tag，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(soup.find_all(attrs=&#123;<span class="hljs-string">&#x27;data-foo&#x27;</span>: <span class="hljs-string">&#x27;value&#x27;</span>&#125;))<br><span class="hljs-comment"># [&lt;div data-foo=&quot;value&quot;&gt;foo!&lt;/div&gt;]</span><br></code></pre></td></tr></table></figure><h3 id="find"><a href="#find" class="headerlink" title="find()"></a><strong>find()</strong></h3><p>方法详细如下：<code>find(name=None, attrs=&#123;&#125;, recursive=True, text=None,**kwargs)</code>，我们可以看出除了少了 <code>limit</code> 参数，其它参数与方法 <code>find_all</code> 一样，不同之处在于：find_all() 方法的返回结果是一个列表，find() 方法返回的是第一个节点，find_all() 方法没有找到目标是返回空列表，find() 方法找不到目标时，返回 None。来看个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;a id=&quot;link1&quot; href=&quot;http://example.com/elsie&quot;&gt;Elsie&lt;/a&gt;&lt;a id=&quot;link2&quot; href=&quot;http://example.com/elsie&quot;&gt;Elsie&lt;/a&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-built_in">print</span>(soup.find_all(<span class="hljs-string">&#x27;a&#x27;</span>, limit=<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(soup.find(<span class="hljs-string">&#x27;a&#x27;</span>))<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">[&lt;a href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]</span><br><span class="hljs-string">&lt;a href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>从示例中我们也可以看出，find() 方法返回的是找到的第一个节点。</p><h3 id="find-parents-和-find-parent"><a href="#find-parents-和-find-parent" class="headerlink" title="find_parents() 和 find_parent()"></a><strong>find_parents() 和 find_parent()</strong></h3><p>find_all() 和 find() 用来搜索当前节点的所有子节点，find_parents() 和 find_parent() 则用来搜索当前节点的父辈节点。</p><h3 id="find-next-siblings-和-find-next-sibling"><a href="#find-next-siblings-和-find-next-sibling" class="headerlink" title="find_next_siblings() 和 find_next_sibling()"></a><strong>find_next_siblings() 和 find_next_sibling()</strong></h3><p>这两个方法通过 .next_siblings 属性对当前 tag 所有后面解析的兄弟 tag 节点进行迭代，find_next_siblings() 方法返回所有符合条件的后面的兄弟节点，find_next_sibling() 只返回符合条件的后面的第一个tag节点。</p><h3 id="find-previous-siblings-和-find-previous-sibling"><a href="#find-previous-siblings-和-find-previous-sibling" class="headerlink" title="find_previous_siblings() 和 find_previous_sibling()"></a><strong>find_previous_siblings() 和 find_previous_sibling()</strong></h3><p>这两个方法通过 .previous_siblings 属性对当前 tag 前面解析的兄弟 tag 节点进行迭代，find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点，find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点。</p><h3 id="find-all-next-和-find-next"><a href="#find-all-next-和-find-next" class="headerlink" title="find_all_next() 和 find_next()"></a><strong>find_all_next() 和 find_next()</strong></h3><p>这两个方法通过 .next_elements 属性对当前 tag 之后的 tag 和字符串进行迭代，find_all_next() 方法返回所有符合条件的节点，find_next() 方法返回第一个符合条件的节点。</p><h3 id="find-all-previous-和-find-previous"><a href="#find-all-previous-和-find-previous" class="headerlink" title="find_all_previous() 和 find_previous()"></a><strong>find_all_previous() 和 find_previous()</strong></h3><p>这两个方法通过 .previous_elements 属性对当前节点前面的 tag 和字符串进行迭代，find_all_previous() 方法返回所有符合条件的节点，find_previous() 方法返回第一个符合条件的节点。</p><h2 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a><strong>CSS选择器</strong></h2><p>BeautifulSoup 支持大部分的 CSS 选择器，在 Tag 或 BeautifulSoup 对象的 .select() 方法中传入字符串参数，即可使用 CSS 选择器的语法找到 tag，返回类型为列表。示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">&#x27;&lt;body&gt;&lt;a id=&quot;link1&quot; class=&quot;elsie&quot;&gt;Elsie&lt;/a&gt;&lt;a id=&quot;link2&quot; class=&quot;elsie&quot;&gt;Elsie&lt;/a&gt;&lt;/body&gt;&#x27;</span>,<span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><span class="hljs-built_in">print</span>(soup.select(<span class="hljs-string">&#x27;a&#x27;</span>))<br><br><span class="hljs-comment">#输出结果</span><br><span class="hljs-comment">#[&lt;a clss=&quot;elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a clss=&quot;elsie&quot; id=&quot;link2&quot;&gt;Elsie&lt;/a&gt;]</span><br></code></pre></td></tr></table></figure><p>通过标签逐层查找</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;body a&#x27;</span>)<br></code></pre></td></tr></table></figure><p>找到某个 tag 标签下的直接子标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;body &gt; a&#x27;</span>)<br></code></pre></td></tr></table></figure><p>通过类名查找</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;.elsie&#x27;</span>)<br>soup.select(<span class="hljs-string">&#x27;[class~=elsie]&#x27;</span>)<br></code></pre></td></tr></table></figure><p>通过 id 查找</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;#link1&#x27;</span>)<br></code></pre></td></tr></table></figure><p>使用多个选择器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;#link1,#link2&#x27;</span>)<br></code></pre></td></tr></table></figure><p>通过属性查找</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;a[class]&#x27;</span>)<br></code></pre></td></tr></table></figure><p>通过属性的值来查找</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select(<span class="hljs-string">&#x27;a[class=&quot;elsie&quot;]&#x27;</span>)<br></code></pre></td></tr></table></figure><p>查找元素的第一个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">soup.select_one(<span class="hljs-string">&#x27;.elsie&#x27;</span>)<br></code></pre></td></tr></table></figure><p>查找兄弟节点标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#查找所有</span><br>soup.select(<span class="hljs-string">&#x27;#link1 ~ .elsie&#x27;</span>)<br><span class="hljs-comment">#查找第一个</span><br>soup.select(<span class="hljs-string">&#x27;#link1 + .elsie&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>数据获取</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
      <tag>数据分析</tag>
      
      <tag>小甲鱼</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何在博客中渲染数学公式</title>
    <link href="/2024/04/12/20240412_AddMathToBlogs/"/>
    <url>/2024/04/12/20240412_AddMathToBlogs/</url>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>​        在博客写作过程中，经常需要往文章中插入数学公式，对于不熟悉LaTex语法的人来说，我们自然希望能使用<code>MathType</code>编辑公式，然后往文章中插入<code>LaTex</code>语法的公式即可。然而，如果使用<code>Hexo</code>部署博客，<code>Hexo</code>自带的默认渲染引擎<a href="https://link.zhihu.com/?target=https%3A//github.com/hexojs/hexo-renderer-marked">hexo-renderer-marked</a>无法渲染<code>LaTex</code>公式。</p><p>​        <a href="https://www.latexlive.com/##">在线LaTeX公式编辑器</a></p><h1 id="安装与配置"><a href="#安装与配置" class="headerlink" title="安装与配置"></a>安装与配置</h1><h2 id="hexo-math插件"><a href="#hexo-math插件" class="headerlink" title="hexo-math插件"></a>hexo-math插件</h2><p>​    首先，安装<a href="https://link.zhihu.com/?target=https%3A//github.com/hexojs/hexo-math">hexo-math</a>插件，该插件使用<code>MathJax/KaTex</code>来渲染数学公式:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">npm <span class="hljs-keyword">install</span> hexo-<span class="hljs-keyword">math</span> --save<br></code></pre></td></tr></table></figure><p>​    安装完成后，配置目录下的<code>_config.yml</code>，加入下面配置信息：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">math</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">engine</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&#x27;mathjax&#x27;</span><br>  <span class="hljs-attribute">mathjax</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">src</span><span class="hljs-punctuation">:</span> <span class="hljs-string">custom_mathjax_source</span><br>    <span class="hljs-attribute">config</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-comment"># MathJax config</span><br></code></pre></td></tr></table></figure><p>​    我在_config.主题.yml下还加了下面配置信息：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">mathjax:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">per_page:</span> <span class="hljs-literal">false</span><br>  <span class="hljs-attr">cdn:</span> <span class="hljs-string">//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML</span><br></code></pre></td></tr></table></figure><h2 id="更改Hexo渲染引擎"><a href="#更改Hexo渲染引擎" class="headerlink" title="更改Hexo渲染引擎"></a>更改Hexo渲染引擎</h2><p>​    更改<code>Hexo</code>的渲染引擎。将<code>Hexo</code>的默认渲染引擎是<code>hexo-renderer-marked</code>替换为<a href="https://link.zhihu.com/?target=https%3A//github.com/sun11/hexo-renderer-kramed">hexo-renderer-kramed</a>。之所以这么做，是因为<code>Hexo</code>默认渲染引擎会将$$$$之间的下划线 <code>_</code> 解析成<code>HTML</code>中的<code>&lt;i&gt;</code>。然而，在<code>LaTex</code>公式中，经常用下划线 <code>_</code> 表示下标，这就导致冲突。而<code>hexo-renderer-kramed</code>在<code>hexo-renderer-marked</code>基础上修改了这个Bug。在安装<code>hexo-renderer-kramed</code>之前，需要卸载<code>hexo-renderer-marked</code>，顺序执行以下两行命令完成卸载与安装：</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm uninstall hexo-renderer-marked <span class="hljs-comment">--save</span><br>npm install hexo-renderer-kramed <span class="hljs-comment">--save</span><br></code></pre></td></tr></table></figure><h2 id="解决语义冲突"><a href="#解决语义冲突" class="headerlink" title="解决语义冲突"></a>解决语义冲突</h2><p>​    在markdown中，斜体用下划线<code>_</code>或星号<code>*</code>表示，而在<code>LaTex</code>中，下划线<code>_</code>表示下标。为了解决这个冲突，需要修改两处。在博客根目录下，进入<code>node_modules\kramed\lib\rules\inline.js</code>，修改第11行escape变量的值（这一步是在原基础上对<code>,&#123;,&#125;</code>的<code>转义(escape)</code>）：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs r">修改前：escape<span class="hljs-operator">:</span> <span class="hljs-operator">/</span><span class="hljs-operator">^</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">\</span>`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,<br>修改后：escape: /^\\([`<span class="hljs-operator">*</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-comment">#$+\-.!_&gt;])/,</span><br></code></pre></td></tr></table></figure><p>​    同时，把第20行的<code>em</code>变量也做相应的修改：</p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">修改前：em: /^\b_((?:<span class="hljs-emphasis">__|[\s\S])+?)_</span>\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,<br>修改后：em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,<br></code></pre></td></tr></table></figure><h2 id="博客开头mathjax开关"><a href="#博客开头mathjax开关" class="headerlink" title="博客开头mathjax开关"></a>博客开头mathjax开关</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br>  <span class="hljs-attr">title:</span> <span class="hljs-string">xxxxxxxxxxxxxxx</span><br>  <span class="hljs-attr">tags:</span> <span class="hljs-string">xxx</span><br>  <span class="hljs-attr">mathjax:</span> <span class="hljs-literal">true</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><h2 id="公式单行居中"><a href="#公式单行居中" class="headerlink" title="公式单行居中"></a>公式单行居中</h2><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dust"><span class="hljs-template-variable">&#123;%raw%&#125;</span><span class="language-xml"> $$evidence_</span><span class="hljs-template-variable">&#123;i&#125;</span><span class="language-xml">=\sum_</span><span class="hljs-template-variable">&#123;j&#125;</span><span class="language-xml">W_</span><span class="hljs-template-variable">&#123;ij&#125;</span><span class="language-xml">x_</span><span class="hljs-template-variable">&#123;j&#125;</span><span class="language-xml">+b_</span><span class="hljs-template-variable">&#123;i&#125;</span><span class="language-xml"> $$</span><span class="hljs-template-variable">&#123;% endraw %&#125;</span><br></code></pre></td></tr></table></figure> $$evidence_{i}=\sum_{j}W_{ij}x_{j}+b_{i} $$<h2 id="公式嵌入到句子中"><a href="#公式嵌入到句子中" class="headerlink" title="公式嵌入到句子中"></a><strong>公式嵌入到句子中</strong></h2><p>若想在一句话中<code>嵌入公式</code>，则只需要在<code>LaTex</code>公式两端用一个<code>$</code>，如：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crystal">在公式<span class="hljs-variable">$ </span>evidence_&#123;i&#125;=\sum_&#123;j&#125;W_&#123;ij&#125;x_&#123;j&#125;+b_&#123;i&#125; <span class="hljs-variable">$中</span>，<span class="hljs-variable">$W</span>_i<span class="hljs-variable">$和</span><span class="hljs-variable">$b</span>_i<span class="hljs-variable">$分</span>别为类别的权值和偏置。<br></code></pre></td></tr></table></figure><p>在公式$evidence_{i}=\sum_{j}W_{ij}x_{j}+b_{i}$中，$W_i$和$b_i$分别为类别的权值和偏置。</p><h1 id="与MathType结合使用"><a href="#与MathType结合使用" class="headerlink" title="与MathType结合使用"></a><strong>与MathType结合使用</strong></h1><p>​    对于比较复杂的公式，如果不熟悉<code>LaTex</code>语法，直接写起来很麻烦，所以我尝试先使用<code>MathType</code>将公式写好，再复制公式，并以<code>LaTex</code>格式粘贴到markdown中。按照MathType<a href="https://link.zhihu.com/?target=https%3A//docs.wiris.com/en/mathtype/mathtype_desktop/mathjax%23write_equations_for_a_mathjax-enabled_website">官方教程</a>，对<code>Preferences</code>下的<code>Cut and Copy Preferences</code>进行设置。如下图：</p><img src="/2024/04/12/20240412_AddMathToBlogs/image-20240412012449378.png" class="" title="image-20240412012449378"><p>粘贴出现错误</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">INFO  [hexo-math] <span class="hljs-keyword">Using</span> engine <span class="hljs-comment">&#x27;mathjax&#x27;</span><br>INFO  Start processing<br>FATAL Something<span class="hljs-comment">&#x27;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br>Template render <span class="hljs-keyword">error</span>: (unknown path) [Line <span class="hljs-number">52</span>, Column <span class="hljs-number">56</span>]<br>  expected variable <span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>​    解决，参考<a href="https://www.jianshu.com/p/738ebe02029b">Hexo的一个小BUG</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 、">在公式的前后分别加上&#123;% raw%&#125;和&#123;% endraw %&#125;:&#123;% raw%&#125; 数学公式 &#123;% endraw %&#125;<br></code></pre></td></tr></table></figure><p>​    具体地，如下所示：</p><ul><li><p>以<code>LaTex2.09 and later</code>或<code>MathJax:LaTex</code>方式粘贴:</p><figure class="highlight handlebars"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs handlebars"><span class="language-xml">&#123;% raw%&#125; \[&#123;x_&#123;1,2&#125;&#125; = \frac</span><span class="hljs-template-variable">&#123;&#123; <span class="hljs-name">-</span> b \pm \sqrt &#123;&#123;b^<span class="hljs-number">2</span>&#125; - <span class="hljs-number">4</span>ac&#125; &#125;&#125;</span><span class="hljs-template-variable">&#123;&#123;<span class="hljs-name">2a</span>&#125;&#125;</span><span class="language-xml">\] &#123;% endraw %&#125;</span><br></code></pre></td></tr></table></figure><p>效果为：</p> \[{x_{1,2}} = \frac{{ - b \pm \sqrt {{b^2} - 4ac} }}{{2a}}\] </li><li><p>以Plain Tex方式粘贴：</p><figure class="highlight handlebars"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs handlebars"><span class="language-xml">&#123;% raw%&#125; $$&#123;x_&#123;1,2&#125;&#125; = </span><span class="hljs-template-variable">&#123;&#123; <span class="hljs-name">-</span> b \pm \sqrt &#123;&#123;b^<span class="hljs-number">2</span>&#125; - <span class="hljs-number">4</span>ac&#125; &#125; \over &#123;<span class="hljs-number">2</span>a&#125;&#125;</span><span class="language-xml">$$ &#123;% endraw %&#125;</span><br></code></pre></td></tr></table></figure><p>效果为：</p> $${x_{1,2}} = {{ - b \pm \sqrt {{b^2} - 4ac} } \over {2a}}$$ </li><li><p>在句子中间粘贴：</p><figure class="highlight handlebars"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs handlebars"><span class="language-xml">公式在句子中显示：&#123;% raw%&#125; $&#123;x_&#123;1,2&#125;&#125; = </span><span class="hljs-template-variable">&#123;&#123; <span class="hljs-name">-</span> b \pm \sqrt &#123;&#123;b^<span class="hljs-number">2</span>&#125; - <span class="hljs-number">4</span>ac&#125; &#125; \over &#123;<span class="hljs-number">2</span>a&#125;&#125;</span><span class="language-xml">$ &#123;% endraw %&#125;。</span><br></code></pre></td></tr></table></figure><p>效果为：</p><p>公式在句子中显示： ${x_{1,2}} = {{ - b \pm \sqrt {{b^2} - 4ac} } \over {2a}}$ 。</p></li></ul><h1 id="鸣谢博文"><a href="#鸣谢博文" class="headerlink" title="鸣谢博文"></a>鸣谢博文</h1><p><a href="https://zhuanlan.zhihu.com/p/108766968">结合MathType和MathJax在Hexo博客中插入数学公式 </a></p>]]></content>
    
    
    <categories>
      
      <category>搭建网站</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学公式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归</title>
    <link href="/2024/04/10/20240411_linearRegression/"/>
    <url>/2024/04/10/20240411_linearRegression/</url>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>&emsp;&emsp;一个事物唯一由另一个事物决定</p><h2 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h2><p>&emsp;&emsp;类似二元直角坐标系，描出关系图形是一条直线，称为线性关系</p><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p>&emsp;&emsp;回归分析是一种统计方法,于对具有一个或多个自变量的因变量(目标变量)和自变量(预测变量)之间的关系进行建模。具体地说，回归分析有助于我们理解在其他自变量保持固定的情况下，自变量的值对应于自变量的变化方式。它可以预测连续/实际值,例如温度,年龄,工资,价格等。</p><p>&emsp;&emsp;回归是一种<strong>有监督</strong>的学习技术，有助于<strong>发现变量之间的相关性</strong>,并使我们能够基于一个或多个预测变量来预测连续输出变量。它主要用于<strong>预测，时间序列建模以及确定变量之间的因果关系</strong>。</p><h1 id="简单线性回归模型"><a href="#简单线性回归模型" class="headerlink" title="简单线性回归模型"></a><strong>简单线性回归模型</strong></h1> $$\hat{y}= h(x) = w*x +b  $$<p>&emsp;&emsp;其中$w$叫权重参数，$b$叫偏置或者截距。当求解得到未知参数$w$，$b$之后，也就意味着我们得到了这个预测模型。假设给定一个房屋面积$x$，就能够预测出其对应的房价。</p><h2 id="求解线性回归模型"><a href="#求解线性回归模型" class="headerlink" title="求解线性回归模型"></a><strong>求解线性回归模型</strong></h2><p>&emsp;&emsp;当建立好一个模型后，自然而然想到的就是如何通过给定的数据，也叫训练集（Training Data），来对模型$h(x)$进行求解。在中学时期我们倒是学过如何通过两个坐标点来求解过这两点的直线，可在上述的场景中这种做法显然行不通的（因为所有的点并不在一条直线上），那有没有什么好的解决的办法呢？</p><p>&emsp;&emsp;此时就需要我们转换一下思路了，既然不能直接来进行求解那就换一种间接的方式。现在来想象一下，当$h(x)$满足一个什么样的条件时，它才能称得上是一个好的$h(x)$? 回想一下求解$h(x)$的目的是什么，不就是希望输入面积$x$后能够输出”准确”的房价$h(x)$吗 ？既然直接求解$h(x)$不好入手，那么我们就从“准确”来入手。</p><p>&emsp;&emsp;可又怎么来定义准确呢？在这里，我们可以通过计算每个样本的真实房价与预测房价之间的均方误差来对“准确”进行刻画</p> $$ J(w,b) = {1 \over 2m}  \sum_{i=1}^{m} \left ( y^{(i)} - \hat{y^(i)} \right ) ^2  $$ $$\hat{y}^{(i)} = h(x^{(i)}) = wx^{(i)}+b$$ <p>&emsp;&emsp;其中，$m$表示样本数数量$x^{(i)}$表示第$i$个样本的，也就是第$i$个房屋的面积；$y^{(i)}$表示第$i$个房屋的真实价格；$\hat{y}^{(i)}$表示第$i$个房屋的预测价格。</p><p>&emsp;&emsp;由式可知，当函数$J(w,b)$取最小值时的参数$\hat{w},\hat{b}$，就是要求的目标参数。为什么？因为当$J(w,b)$取最小值就意味着此时所有样本的预测值与真实值之间的误差（Error）最小。如果极端一点，那就是所有预测值都等同于真实值，此时的$J(w,b)$就是0了。</p><h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>&emsp;&emsp;因此，对于如何求解模型$h(x)$的问题就转换成了如何最小化函数$J(w,b)$的问题。而$J(w,b)$也有一个专门的术语叫目标函（Objective Function）或者是代价函数（Cost Function）亦或是<a href="https://www.zhihu.com/search?q=损失函数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A2183691849}">损失函数</a>。</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><img src="/2024/04/10/20240411_linearRegression/image-20240412221504247.png" class="" title="image-20240412221504247"><p><a href="https://zhuanlan.zhihu.com/p/80887841">图片来源</a></p><h1 id="样例与代码"><a href="#样例与代码" class="headerlink" title="样例与代码"></a>样例与代码</h1>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用Hexo+GitHub搭建个人免费博客</title>
    <link href="/2024/04/09/20240409_github&amp;hexo/"/>
    <url>/2024/04/09/20240409_github&amp;hexo/</url>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="GitHub-Pages与Hexo"><a href="#GitHub-Pages与Hexo" class="headerlink" title="GitHub Pages与Hexo"></a>GitHub Pages与Hexo</h2><ul><li><p>GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让我们可以在 GitHub 仓库里托管和发布自己的静态网站页面。</p></li><li><p>Hexo 是一个快速、简洁且高效的静态博客框架，它基于 Node.js 运行，可以将我们撰写的 Markdown 文档解析渲染成静态的 HTML 网页。</p></li><li><p>在本地撰写 Markdown 格式文章后，通过 Hexo 解析文档，渲染生成具有主题样式的 HTML 静态网页，再推送到 GitHub 上完成博文的发布。（注意，在GitHub上没有存储你的md文件）</p><img src="/2024/04/09/20240409_github&hexo/image-20240409225733759.png" class="" title="image-20240409225733759"></li></ul><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>输入代码时，核对准确，最好切换成英文输入法；</li><li>将文中的 “用户名” 和 “邮箱” 替换为自己的 GitHub 账户名和绑定的邮箱；</li><li>统一使用 Git Bash 进行操作（其实vscode控制台也可以，但是这样子真的好方便，以后就用typora写完直接hexo clean和hexo d就可以了）；</li><li>hhh小白请严格按步骤进行，不要跳！</li></ul><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>Hexo 基于 Node.js，搭建过程中还需要使用 npm（Node.js 已带） 和 git，因此先搭建本地操作环境，安装 Node.js 和 Git</p><ul><li><a href="https://nodejs.org/zh-cn">Node.js</a></li><li><a href="https://git-scm.com/downloads">Git</a></li></ul><p>下载 Node.js 和 Git 程序并安装，一路点 “下一步” 按默认配置完成安装。</p><p>安装完成后，Win+R 输入 cmd 并打开，依次输入 node -v、npm -v 和 git —version 并回车，如下图出现程序版本号即可。</p><h1 id="连接GitHub"><a href="#连接GitHub" class="headerlink" title="连接GitHub"></a>连接GitHub</h1><ol><li><p>使用邮箱注册<a href="https://github.com/">GitHub</a>账户(在github官网)</p></li><li><p>右键 -&gt; Git Bash Here , 设置_用户名和邮箱_（在自己电脑，随便找个地方，因为是全局的）</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.name</span> <span class="hljs-string">&quot;GitHub 用户名&quot;</span><br>git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.email</span> <span class="hljs-string">&quot;GitHub 邮箱&quot;</span><br></code></pre></td></tr></table></figure></li><li><p><strong>创建 SSH 密匙</strong>：输入 <code>ssh-keygen -t rsa -C &quot;GitHub 邮箱&quot;</code>，然后一路回车。获取生成了密钥。</p><p>（注意，如果不一直回车，自定义名称，则后面需要在。ssh后添加一个config文件，且内容为</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># github</span><br>Host github.com<br>HostName github.com<br>PreferredAuthentications publickey<br>IdentityFile ~<span class="hljs-regexp">/.ssh/</span>你的自定义名称<br></code></pre></td></tr></table></figure><p>）</p></li><li><p><strong>添加密匙：</strong></p><p>进入 [C:\Users\用户名.ssh] 目录（要勾选显示“隐藏的项目”），用记事本打开公钥 id_rsa.pub 文件并复制里面的内容。</p><p>登陆 GitHub ，进入 Settings 页面，选择左边栏的 SSH and GPG keys，点击 New SSH key。</p><p>Title 随便取个名字，粘贴复制的 id_rsa.pub 内容到 Key 中，点击 Add SSH key 完成添加。</p><img src="/2024/04/09/20240409_github&hexo/image-20240409232327677-1712911016461.png" class="" title="image-20240409232327677"></li><li><p><strong>验证连接：</strong></p><p>打开 Git Bash，输入 <code>ssh -T git@github.com</code> 出现 “Are you sure……”，输入 yes 回车确认</p></li></ol><h1 id="创建Github-Pages仓库"><a href="#创建Github-Pages仓库" class="headerlink" title="创建Github Pages仓库"></a>创建Github Pages仓库</h1><p>创建后默认自动启用 HTTPS，博客地址为：<code>https://用户名.github.io</code></p><img src="/2024/04/09/20240409_github&hexo/image-20240409232820900.png" class="" title="image-20240409232820900"><h2 id="本地安装-Hexo-博客程序"><a href="#本地安装-Hexo-博客程序" class="headerlink" title="本地安装 Hexo 博客程序"></a>本地安装 Hexo 博客程序</h2><p> <a href="https://hexo.io/zh-cn/docs/">Hexo 官方文档</a></p><p><a href="https://huangzxuan.github.io/2024/04/09/blog01/">如何选主题更换主题呀，例如我的fluid</a></p><h1 id="部署Hexo到GitHub-Pages"><a href="#部署Hexo到GitHub-Pages" class="headerlink" title="部署Hexo到GitHub Pages"></a>部署Hexo到GitHub Pages</h1><p>本地博客测试成功后，就是上传到 GitHub 进行部署，使其能够在网络上访问。</p><p>首先<strong>安装 hexo-deployer-git</strong>：</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm install hexo-deployer-git <span class="hljs-comment">--save</span><br></code></pre></td></tr></table></figure><p>然后<strong>修改 _config.yml</strong> 文件末尾的 Deployment 部分，修改成如下：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">deploy:</span><br><span class="hljs-symbol">  type:</span> git<br><span class="hljs-symbol">  repository:</span> git@github.com:用户名/用户名.github.io.git<br><span class="hljs-symbol">  branch:</span> master（这里可能是main，看你github仓库的主要分支）<br></code></pre></td></tr></table></figure><p>完成后运行 <code>hexo d</code> 将网站上传部署到 GitHub Pages。</p><p>完成！这时访问我们的 GitHub 域名 <code>https://用户名.github.io</code> 就可以看到 Hexo 网站了。</p>]]></content>
    
    
    <categories>
      
      <category>搭建网站</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>fluid主题</title>
    <link href="/2024/04/09/20240410_hexo/"/>
    <url>/2024/04/09/20240410_hexo/</url>
    
    <content type="html"><![CDATA[<p>一款 Material Design 风格的主题</p><h1 id="搭建-Hexo-博客"><a href="#搭建-Hexo-博客" class="headerlink" title="搭建 Hexo 博客"></a>搭建 Hexo 博客</h1><p>如果你还没有 Hexo 博客，请按照 <a href="https://hexo.io/zh-cn/docs/">Hexo 官方文档</a> 进行安装、建站。</p><h1 id="获取主题最新版本"><a href="#获取主题最新版本" class="headerlink" title="获取主题最新版本"></a>获取主题最新版本</h1><p>方式一：<br>Hexo 5.0.0 版本以上，推荐通过 npm 直接安装，进入博客目录执行命令：<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm install <span class="hljs-comment">--save hexo-theme-fluid</span><br></code></pre></td></tr></table></figure><br>然后在博客目录下创建 _config.fluid.yml，将主题的<a href="https://github.com/fluid-dev/hexo-theme-fluid/blob/master/_config.yml">_config.yml</a>内容复制进去<br>方式二：<br>下载<a href="https://github.com/fluid-dev/hexo-theme-fluid/releases">最新release</a>解压导themes目录，并解压出的文件夹命名为fluid</p><h1 id="指定主题"><a href="#指定主题" class="headerlink" title="指定主题"></a>指定主题</h1><p>如下修改 Hexo 博客目录中的 _config.yml：<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">theme:</span> fluid  <span class="hljs-meta"># 指定主题</span><br><br><span class="hljs-symbol">language:</span> <span class="hljs-built_in">zh</span>-CN  <span class="hljs-meta"># 指定语言，会影响主题显示的语言，按需修改</span><br></code></pre></td></tr></table></figure></p><h1 id="创建关于页"><a href="#创建关于页" class="headerlink" title="创建关于页"></a>创建关于页</h1><p>首次使用主题的「关于页」需要手动创建：<br><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haxe">hexo <span class="hljs-keyword">new</span> <span class="hljs-type">page</span> about<br></code></pre></td></tr></table></figure><br>创建成功后，编辑博客目录下 /source/about/index.md，添加 layout 属性。<br>修改后的文件示例如下：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">about</span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">about</span><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-string">这里写关于页的正文，支持</span> <span class="hljs-string">Markdown,</span> <span class="hljs-string">HTML</span><br></code></pre></td></tr></table></figure></p><h1 id="更新主题"><a href="#更新主题" class="headerlink" title="更新主题"></a><a href="https://hexo.fluid-dev.com/docs/start/#%E6%9B%B4%E6%96%B0%E4%B8%BB%E9%A2%98">更新主题</a></h1><h1 id="功能特性"><a href="#功能特性" class="headerlink" title="功能特性"></a>功能特性</h1><img src="/2024/04/09/20240410_hexo/image-20240410180425918.png" class="" title="image-20240410180425918">]]></content>
    
    
    <categories>
      
      <category>搭建网站</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fluid</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
