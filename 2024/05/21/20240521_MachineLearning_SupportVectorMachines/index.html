

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="XuanYa">
  <meta name="keywords" content="">
  
    <meta name="description" content="线性可分定义​    二维平面中，存在一条直线可以把圆圈和叉分开；三维平面中，存在一个面可以把圆圈和叉分开；四维及以上，超平面。 .nbymusdbgfin{zoom:67%;} 假设​    我们有N个训练样本和他们的标签${(X_1,y_1),(X_2,y_2),…,(X_N,y_N)}$， ​    其中$X_i &#x3D; [x_{i1},x_{i2}]^T$，$y_i &#x3D; {+1,-1}$，这样">
<meta property="og:type" content="article">
<meta property="og:title" content="支持向量机">
<meta property="og:url" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/index.html">
<meta property="og:site_name" content="冯宝宝">
<meta property="og:description" content="线性可分定义​    二维平面中，存在一条直线可以把圆圈和叉分开；三维平面中，存在一个面可以把圆圈和叉分开；四维及以上，超平面。 .nbymusdbgfin{zoom:67%;} 假设​    我们有N个训练样本和他们的标签${(X_1,y_1),(X_2,y_2),…,(X_N,y_N)}$， ​    其中$X_i &#x3D; [x_{i1},x_{i2}]^T$，$y_i &#x3D; {+1,-1}$，这样">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240521231920803.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240522000808394.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240522001428124.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528121654953.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528171356369.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528171415612.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531112604943.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531113517531.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531113702251.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150013897.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150401228.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150540767.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150706444.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531151519887.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531151548140.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531154748128.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153113219.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153414510.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153902859.png">
<meta property="og:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531154142917.png">
<meta property="article:published_time" content="2024-05-21T15:07:09.686Z">
<meta property="article:modified_time" content="2024-06-02T14:41:31.867Z">
<meta property="article:author" content="XuanYa">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="算法">
<meta property="article:tag" content="SVM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240521231920803.png">
  
  
  
  <title>支持向量机 - 冯宝宝</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>轩的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="支持向量机"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-05-21 23:07" pubdate>
          2024年5月21日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          37 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">支持向量机</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="线性可分定义"><a href="#线性可分定义" class="headerlink" title="线性可分定义"></a>线性可分定义</h1><p>​    二维平面中，<strong>存在一条直线</strong>可以把圆圈和叉分开；三维平面中，<strong>存在一个面</strong>可以把圆圈和叉分开；四维及以上，<strong>超平面</strong>。</p>
<p><style>.nbymusdbgfin{zoom:67%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240521231920803.png" srcset="/img/loading.gif" lazyload class="nbymusdbgfin" alt="image-20240521231920803"></p>
<h2 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h2><p>​    我们有N个训练样本和他们的标签${(X_1,y_1),(X_2,y_2),…,(X_N,y_N)}$，</p>
<p>​    其中$X_i = [x_{i1},x_{i2}]^T$，$y_i = {+1,-1}$，这样，$y_i = +1$时，$X_1$属于$C_1$</p>
<h2 id="数学定义"><a href="#数学定义" class="headerlink" title="数学定义"></a>数学定义</h2><p>线性可分的严格定义：一个训练样本集${(X_i,y_i),…,(X_N,y_N)}$，在i=1~N线性可分，是指存在$(w_1,w_2,b)$，使得对i = 1~N，有：</p>
<ul>
<li>若$y_i = +1$，则$\omega_1x_{i1}+\omega_2x_{i2}+b &gt; 0$</li>
<li>若$y_i = -1$，则$\omega_1x_{i1}+\omega_2x_{i2}+b &lt; 0$</li>
</ul>
<h2 id="向量形式定义"><a href="#向量形式定义" class="headerlink" title="向量形式定义"></a>向量形式定义</h2><p>假设：$X_i={\begin{bmatrix}X_{i1}\\X_{i2}\end{bmatrix}}^T  \omega={\begin{bmatrix}\omega_{1}\\\omega_{2}\end{bmatrix}}^T$</p>
<ul>
<li>若$y_i = +1$，则$\omega^TX_{i}+b &gt; 0$</li>
<li>若$y_i = -1$，则$\omega^TX_{i}+b &lt; 0$</li>
</ul>
<h2 id="最简化形式"><a href="#最简化形式" class="headerlink" title="最简化形式"></a>最简化形式</h2><p>如果    $y_i=+1$或-1</p>
<p>一个训练样本集${(X_i,y_i)}$，在i = 1~N线性可分，是指存在(\omega，b)，使得对i = 1~N，有：</p>
 $$y_i(\omega^TX_i+b)>0 $$
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><h3 id="解决线性可分问题"><a href="#解决线性可分问题" class="headerlink" title="解决线性可分问题"></a>解决线性可分问题</h3><ul>
<li><p>在无数多个分开各个类别的超平面中，到底哪一个最好？</p>
<p><style>.itclwthwciio{zoom:50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240522000808394.png" srcset="/img/loading.gif" lazyload class="itclwthwciio" alt="image-20240522000808394"></p>
<p>基于对训练样本先验分布有一定假设，如假设训练样本的位置在特征空间上有测量误差，图中二号线对训练样本误差的容忍程度是最高的，相比1号线和3号线更能抵御训练样本位置的误差</p>
</li>
<li><p>2号线是怎么画出来的？</p>
<p>基于最优化理论，间隔最大的是2号线，(确定唯一)取上下两个平行线中间</p>
<p><style>.xpprbaijfysj{zoom:50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240522001428124.png" srcset="/img/loading.gif" lazyload class="xpprbaijfysj" alt="image-20240522001428124"></p>
<ol>
<li>该直线分开了两类</li>
<li>该直线最大化间隔</li>
<li>该直线处于间隔的中间，到所有支持向量距离相等</li>
</ol>
</li>
</ul>
<h3 id="再将线性可分问题中获得的结论推广到线性不可分情况"><a href="#再将线性可分问题中获得的结论推广到线性不可分情况" class="headerlink" title="再将线性可分问题中获得的结论推广到线性不可分情况"></a>再将线性可分问题中获得的结论推广到线性不可分情况</h3><h1 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h1><p><strong>如何用严格的数学，寻找最有分类超平面的过程，写成一个最优化的问题</strong></p>
<p>假定训练样本集是线性可分的,支持向量机需要的是最大化间隔(MARGIN)的超平面(离两边所有支持向量的距离相等)</p>
<h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p>已知：训练样本集{(x_i,y_i)},i=1到N；</p>
<p>待求：(w,b)</p>
<h2 id="最小化"><a href="#最小化" class="headerlink" title="最小化"></a>最小化</h2><p>${1/over 2}||\omega||^2$</p>
<p><style>.tqfurosmbihg{zoom:67%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528121654953.png" srcset="/img/loading.gif" lazyload class="tqfurosmbihg" alt="image-20240528121654953"></p>
<h2 id="限制条件"><a href="#限制条件" class="headerlink" title="限制条件"></a>限制条件</h2><p><strong>$y_i(w^Tx_i+b)&gt;=1,(i=1 ~ N)$</strong></p>
<p>在支持向量机（Support Vector Machine, SVM）中，约束条件$y_i (\omega^T x_i + b) \geq 1 ) （其中 (i = 1, 2, \ldots, N)$是用于确保数据点被正确分类并且在超平面边界以外有一定的间隔。具体解释如下：</p>
<ol>
<li><p><strong>定义符号</strong>：</p>
<ul>
<li>$\omega$是超平面的法向量。</li>
<li>$x_i$是第 $i$ 个样本点。</li>
<li>$b$是超平面的偏置项。</li>
<li>$y_i$ 是第$i$个样本点的类别标签，取值为$\pm1$。</li>
</ul>
</li>
<li><p><strong>支持向量机的目标</strong>：<br>SVM的目标是找到一个能够最大化分类间隔（Margin）的超平面。分类间隔定义为到最近数据点的距离。</p>
</li>
<li><p><strong>约束条件解释</strong>：<br>约束条件$y_i (\omega^T x_i + b) \geq 1$用于确保所有训练样本点被正确分类，并且离超平面至少有一个单位的距离。$y_i$协调超平面的左右。详细解释如下：</p>
<ul>
<li>当 $y_i = 1$ 时，约束条件为$\omega^T x_i + b \geq 1$。这意味着正类样本点$x_i $应该位于超平面的正侧并且到超平面的距离至少为 1。</li>
<li>当 $y_i = -1 $时，约束条件为$\omega^T x_i + b \leq -1$。这意味着负类样本点$x_i$应该位于超平面的负侧并且到超平面的距离至少为 1。</li>
</ul>
</li>
<li><p><strong>最大化间隔</strong>：<br>通过这些约束条件，我们确保了最小间隔为 1 的正确分类，同时目标是最大化此间隔。在优化过程中，我们会最小化 $\frac{1}{2} |\omega|^2$，等价于最大化间隔，因为间隔与$|\omega|$成反比。</p>
</li>
<li><p><strong>几何解释</strong>：<br>通过添加这个约束条件，我们可以确保找到的超平面不仅能正确分类所有样本点，还能最大化分类的鲁棒性，即使数据点在决策边界附近有少量扰动，也能保证分类的准确性。</p>
</li>
</ol>
<p>综上所述，约束条件$y_i (\omega^T x_i + b) \geq 1$是支持向量机的重要组成部分，它保证了正确分类并且尽可能地增大分类间隔，从而提高模型的泛化能力。</p>
<h2 id="事实"><a href="#事实" class="headerlink" title="事实"></a>事实</h2><h3 id="事实1"><a href="#事实1" class="headerlink" title="事实1"></a>事实1</h3><p>$\omega^Tx+b = b$与(a\omega^T)x+(ab)=0是同一个超平面。($a \neq 0$)</p>
<h3 id="事实2"><a href="#事实2" class="headerlink" title="事实2"></a>事实2</h3><p><strong>一个点$X_0$到超平面$\omega^Tx+b = 0$的距离$d = {|\omega^Tx_0+b| \over ||\omega||}$</strong></p>
<p><strong>一个点$(x_0,y_0)$到超平面$\omega_1x+\omega_2y+b = 0 $的距离$d = {|\omega_1x_0 + \omega_2y_0 + b| \over  \sqrt {\omega_1^2 + \omega_2^2}}$</strong></p>
<ol>
<li><p><strong>平面方程</strong>：给定平面$ \alpha $的方程为：<br>$Ax + By + Cz + D = 0 $</p>
</li>
<li><p><strong>点和法向量</strong>：点  $P_0(x_0, y_0, z_0) $是要计算到平面距离的点，平面的法向量为 $\vec{n} = (A, B, C) $。</p>
</li>
<li><p><strong>距离公式的推导</strong>：</p>
<ol>
<li>选择平面上的一点 $P_1(x_1, y_1, z_1)$  作为参考点。</li>
<li>向量 $\vec{P_1P_0} $表示从点 $ P_1 $ 到点 $ P_0 $的向量，其表示为：<br>$\vec{P_1P_0} = (x_0 - x_1, y_0 - y_1, z_0 - z_1) $</li>
<li>点 $P_0 $到平面的距离 $d$等于向量$\vec{P_1P_0}$ 在法向量 $\vec{n} $上的投影的绝对值，公式为：<br>$d = \frac{|\vec{P_1P_0} \cdot \vec{n}|}{|\vec{n}|}$</li>
<li>计算向量点积$\vec{P_1P_0} \cdot \vec{n}$：<br>$ \vec{P_1P_0} \cdot \vec{n} = A(x_0 - x_1) + B(y_0 - y_1) + C(z_0 - z_1)$</li>
<li>计算法向量$\vec{n}$的模长：<br>$ |\vec{n}| = \sqrt{A^2 + B^2 + C^2}$</li>
</ol>
</li>
<li><p><strong>化简距离公式</strong>：</p>
<ol>
<li>由于点$P_1$在平面上，所以 $Ax_1 + By_1 + Cz_1 + D = 0$，因此$D = -(Ax_1 + By_1 + Cz_1)$。</li>
<li>将上面的结果代入到公式中，得到：<br>$d = \frac{|A(x_0 - x_1) + B(y_0 - y_1) + C(z_0 - z_1)|}{\sqrt{A^2 + B^2 + C^2}}$</li>
<li>将 ( P_1(x_1, y_1, z_1) ) 替换成点 ( P_0(x_0, y_0, z_0) ) 的坐标，公式变为：<br>$d = \frac{|Ax_0 + By_0 + Cz_0 + D|}{\sqrt{A^2 + B^2 + C^2}}$</li>
</ol>
</li>
</ol>
<p>因此，点 $P_0(x_0, y_0, z_0)$到平面$Ax + By + Cz + D = 0$的距离公式为：</p>
<p>$d = \frac{|Ax_0 + By_0 + Cz_0 + D|}{\sqrt{A^2 + B^2 + C^2}}$</p>
<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><ul>
<li>用a去缩放$/omega b$</li>
<li>$(/omega , b)-&gt;(a/omega , ab)$</li>
<li>最终使在支持向量x_0上有$|/omega^Tx_0 + b| = 1$，而在非支持向量上$ |/omega^Tx_0 + b| &gt; 1$</li>
<li>根据事实2，支持向量机x_0到超平面距离将会变为：$d = \frac{|\omega^T x_0 + b|}{|\omega|} = \frac{1}{|\omega|}$</li>
<li>最大化支持向量到超平面的距离等价于最小化||/omega||</li>
</ul>
<h2 id="二次规划"><a href="#二次规划" class="headerlink" title="二次规划"></a>二次规划</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul>
<li><p>目标函数是二次项</p>
<img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528171356369.png" srcset="/img/loading.gif" lazyload class="" title="image-20240528171356369">
</li>
<li><p>限制条件是一次项</p>
<p><style>.ydvcjrbirrsn{zoom: 50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240528171415612.png" srcset="/img/loading.gif" lazyload class="ydvcjrbirrsn" alt="image-20240528171415612"></p>
</li>
<li><p>这种凸优化问题要么无解，要么只有唯一的最小值解，可以应用梯度算法来解</p>
</li>
</ul>
<h1 id="线性不可分情况"><a href="#线性不可分情况" class="headerlink" title="线性不可分情况"></a>线性不可分情况</h1><ul>
<li><p>不存在$/omega$和$b$满足上面所有N个限制条件</p>
</li>
<li><p>需要放松限制条件(基本思路)</p>
<ul>
<li>对每个训练样本及标签$(X_i,Y_i)$</li>
<li>松弛变量$\delta_i$</li>
<li>限制条件改写：$y_i(\omega^TX_i + b) \ge 1 - \delta_i (i = 1\sim N)$</li>
</ul>
</li>
<li><p>改造后的支持向量机优化版本</p>
<p><style>.lssmiflitdbv{zoom: 33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531112604943.png" srcset="/img/loading.gif" lazyload class="lssmiflitdbv" alt="image-20240531112604943"></p>
</li>
<li><p>人为实现设定的参数叫做算法的超参数，不断变化C的值，同时测试算法的识别率，选取超参数C</p>
</li>
<li><p>支持向量机是超参数很少的算法模型</p>
</li>
</ul>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p><style>.orxfhugymnjl{zoom:33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531113517531.png" srcset="/img/loading.gif" lazyload class="orxfhugymnjl" alt="image-20240531113517531"></p>
<p><strong>C很大</strong>，会迫使所有的$\delta_i$趋于0，<strong>超平面和线性可分情况保持基本一致</strong></p>
<p><style>.smkeeywigtod{zoom:50%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531113702251.png" srcset="/img/loading.gif" lazyload class="smkeeywigtod" alt="image-20240531113702251"></p>
<p>未达到求解目的(类型:所有的圆圈被所有的叉包围了)，这个解远远不能让人满意，分错了一半训练样本</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我们是假设分开两类的函数是线性的，线性模型的表现力是不够的，无论我们如何取直线，都是不好的，应该扩大可选函数范围，使得其超越线性</p>
<h2 id="课后思考"><a href="#课后思考" class="headerlink" title="课后思考"></a>课后思考</h2><p>请问：在这个例子中，你能否设计出一个这样的非线性变换，将这个分类问题转化为线性可分？</p>
<p>要将这个非线性可分的分类问题转化为线性可分，可以考虑使用核函数或特征变换。一个常见的非线性变换方法是将输入空间映射到一个更高维的特征空间</p>
<p>对于这个例子，可以使用径向基函数(BRF)核函数或多项式核函数来进行非线性变换</p>
<h3 id="特征变换的示例"><a href="#特征变换的示例" class="headerlink" title="特征变换的示例"></a>特征变换的示例</h3><p>假设我们有两个特征$x_1$和$x_2$，可以将其转换为新的特征z，例如：</p>
<p>$ z_1 = x_1^2$</p>
<p>$ z_2 = x_2^2$</p>
<p>$ z_3 = x_1 \cdot x_2$</p>
<p>这种变换可以将原始的二维非线性可分数据映射到三维空间，使得在这个新空间中变得线性可分</p>
<h3 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h3><p>另一种方法是使用核函数，例如径向基函数核(RBF核)：</p>
<p>$K(x_i,x_j) = exp(\gamma||x_i - x_j||^2)$</p>
<p>通过这种方法，可以隐式地将数据映射到一个高维空间，而无需显示地计算特征变换</p>
<h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np	<span class="hljs-comment"># 导入Numpy库，用于数值计算</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt	<span class="hljs-comment"># 导入Matplotlib库，用于绘图</span><br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC	<span class="hljs-comment"># 从Scikit-learn库中导入支持向量分类器</span><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_circles	<span class="hljs-comment"># 从Scikit-learn库中导入make_circles函数，用于生成示例数据集</span><br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D	<span class="hljs-comment"># 从Matplotlib库中导入3D绘图工具</span><br><br><span class="hljs-comment"># 生成非线性可分的数据</span><br>X, y = make_circles(n_samples=<span class="hljs-number">100</span>, factor=<span class="hljs-number">.3</span>, noise=<span class="hljs-number">.05</span>)<br><span class="hljs-comment"># factor的值是介于0和1之间的小数，表示内圈半径与外圈半径的比例。这里表示内圈是外圈的30%</span><br><span class="hljs-comment"># noise参数控制数据点的随机扰动或噪声的量。表示生成数据点加入的高斯噪声的标准差。这里noise=.05表示数据点会有一定程度的随机偏移，以增加数据的真实感和复杂性</span><br><span class="hljs-comment"># x：形状为(n_samples,2)的Numpy数组，其中每一行表示二维数据点。具体来说，x的每一行包含一个数据点的两个特征</span><br><span class="hljs-comment"># y：形状为(n_samples,)的Numpy数组，包含每一个数据点的类别标签。类别标签为二进制的（0或1），表示数据点的外圈和内圈</span><br><br><span class="hljs-comment"># 绘制原始数据</span><br>plt.scatter(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>], c=y, cmap=plt.cm.Paired)<br>plt.title(<span class="hljs-string">&quot;Original Data&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;$x_1$&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;$x_2$&#x27;</span>)<br>plt.show()<br><br><span class="hljs-comment"># 特征变换，变换后新特征矩阵Z具有三个特征列</span><br>Z = np.array([X[:, <span class="hljs-number">0</span>]**<span class="hljs-number">2</span>, <br>              X[:, <span class="hljs-number">1</span>]**<span class="hljs-number">2</span>, <br>              X[:, <span class="hljs-number">0</span>] * X[:, <span class="hljs-number">1</span>]]).T<br><br><br><span class="hljs-comment"># 绘制变换后的数据</span><br>fig = plt.figure()<br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br>ax.scatter(Z[:, <span class="hljs-number">0</span>], Z[:, <span class="hljs-number">1</span>], Z[:, <span class="hljs-number">2</span>], c=y, cmap=plt.cm.Paired)<br>plt.title(<span class="hljs-string">&quot;Transformed Data&quot;</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;$z_1$&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;$z_2$&#x27;</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;$z_3$&#x27;</span>)<br>plt.show()<br><br><span class="hljs-comment"># 使用RBF核进行SVM分类</span><br>clf = SVC(kernel=<span class="hljs-string">&#x27;rbf&#x27;</span>)<br>clf.fit(X, y)<br><br><span class="hljs-comment"># 绘制决策边界</span><br>xx, yy = np.meshgrid(np.linspace(-<span class="hljs-number">1.5</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">500</span>), np.linspace(-<span class="hljs-number">1.5</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">500</span>))<br>Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])<br>Z = Z.reshape(xx.shape)<br><br>plt.scatter(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>], c=y, cmap=plt.cm.Paired)<br>plt.contour(xx, yy, Z, levels=[<span class="hljs-number">0</span>], linewidths=<span class="hljs-number">2</span>, colors=<span class="hljs-string">&#x27;black&#x27;</span>)<br>plt.title(<span class="hljs-string">&quot;Decision Boundary with RBF Kernel&quot;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;$x_1$&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;$x_2$&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
<h3 id="思维方式"><a href="#思维方式" class="headerlink" title="思维方式"></a>思维方式</h3><ol>
<li><p>观察数据分布</p>
<p>首先，我们需要仔细观察数据的分布。通过可视化数据（如散点图），我们可以识别出数据的结构和模式。在你的例子中，数据呈现出同心圆的分布，明显不是线性可分的。</p>
</li>
<li><p>找到适合的特征变换</p>
<p>为了使数据变得线性可分，我们需要找到一种变换方式，使得数据在新的特征空间中分布更适合线性分类。常见的思路包括：</p>
<ul>
<li><strong>多项式变换</strong>：对于同心圆分布的数据，平方或交叉项（如$x_1^2 、x_2^2 和x_1 \cdot x_2$）可能会有帮助，因为这些变换可以捕捉到数据的非线性关系。</li>
<li><strong>非线性变换</strong>：使用核方法（如RBF核）来隐式地将数据映射到高维空间，其中数据可能会变得线性可分。</li>
</ul>
</li>
<li><p>数学和几何直觉</p>
<p>通过数学和几何直觉，我们可以推断出一些变换可能会使数据线性可分。例如，考虑二次多项式变换。对于同心圆数据，使用平方项可以将圆形分布的数据转换为线性可分的数据。这是因为平方变换会放大远离原点的数据点的特征，使得数据点在新的空间中分布得更加分散。</p>
</li>
<li><p>实验和验证</p>
<p>即使有数学和几何直觉的支持，我们仍然需要通过实验和验证来确认选择的特征变换是否有效。这可以通过以下步骤实现：</p>
<ul>
<li><strong>选择变换</strong>：选定一种或几种可能的特征变换。</li>
<li><strong>应用变换</strong>：将原始数据应用选定的变换。</li>
<li><strong>训练模型</strong>：在变换后的特征空间中训练线性分类模型。</li>
<li><strong>验证结果</strong>：评估模型的表现，查看其是否能够有效分类数据。</li>
</ul>
</li>
</ol>
<h1 id="低维到高维的映射"><a href="#低维到高维的映射" class="headerlink" title="低维到高维的映射"></a>低维到高维的映射</h1><ul>
<li><p>在扩大可选函数范围方面独树一帜</p>
</li>
<li><p>特征空间由低维映射到高维，用线性超平面对数据进行分类</p>
</li>
<li><p><style>.arpltxxshsdc{zoom: 33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150013897.png" srcset="/img/loading.gif" lazyload class="arpltxxshsdc" alt="image-20240531150013897"></p>
</li>
<li><p>构造一个二维到五维的映射$\varphi(x)$</p>
<ul>
<li><style>.qlrevvcyyssw{zoom: 33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150401228.png" srcset="/img/loading.gif" lazyload class="qlrevvcyyssw" alt="image-20240531150401228"></li>
<li><style>.znbmqjdejvag{zoom:33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150540767.png" srcset="/img/loading.gif" lazyload class="znbmqjdejvag" alt="image-20240531150540767"></li>
<li>此时线性可分</li>
<li><style>.jyxmrghoecwh{zoom:33%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531150706444.png" srcset="/img/loading.gif" lazyload class="jyxmrghoecwh" alt="image-20240531150706444"></li>
</ul>
</li>
<li><p>假设：</p>
<p>在一个<strong>M维空间</strong>上随机取N个训练样本</p>
<p>随机的对每个训练样本赋予标签<strong>+1或-1</strong></p>
<p><strong>假设</strong>：</p>
<p>这些训练样本线性可分的概率为<strong>P(M)</strong></p>
<p><strong>当M趋于无穷大时    P(M)=1</strong></p>
</li>
</ul>
<h2 id="优化问题-1"><a href="#优化问题-1" class="headerlink" title="优化问题"></a>优化问题</h2><p>前$\omega维度与X_i$维度相同    $\omega$维度与$\varphi(x_i)$相同</p>
<p>高维情况下优化问题的解法和低维情况下是完全类似的</p>
<p><style>.hcpqskmbfcii{zoom:67%;}</style><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531151519887.png" srcset="/img/loading.gif" lazyload class="hcpqskmbfcii" alt="image-20240531151519887"></p>
<img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531151548140.png" srcset="/img/loading.gif" lazyload class="" title="image-20240531151548140">
<h2 id="优化问题的凸性"><a href="#优化问题的凸性" class="headerlink" title="优化问题的凸性"></a>优化问题的凸性</h2><h3 id="凸优化问题的定义"><a href="#凸优化问题的定义" class="headerlink" title="凸优化问题的定义"></a>凸优化问题的定义</h3><ul>
<li>一个优化问题是凸的，如果其目标函数是凸函数，并且约束条件也定义了一个凸集</li>
<li>凸函数的一个重要性质是其任意局部最优解也是全局最优解，这使得优化问题易于求解</li>
</ul>
<h3 id="SVM优化目标"><a href="#SVM优化目标" class="headerlink" title="SVM优化目标"></a>SVM优化目标</h3><ul>
<li><p>支持向量机的目标是找到一个分离超平面，使得两个类别的间隔最大化。对于线性 SVM，其优化问题可以表示为： </p>
<p>$\min_{w,b}{1\over2}||w||^2 $</p>
<p>其中 <strong>w</strong> 是权重向量，b* 是偏置。这个目标函数是凸的。</p>
</li>
</ul>
<h1 id="核函数的定义"><a href="#核函数的定义" class="headerlink" title="核函数的定义"></a>核函数的定义</h1><p>$K(X_1,X_2) = \varphi(X_1)^T\varphi(X_2)$完成对测试样本类别的预测</p>
<h2 id="核方法和核矩阵"><a href="#核方法和核矩阵" class="headerlink" title="核方法和核矩阵"></a>核方法和核矩阵</h2><h3 id="核函数的引入"><a href="#核函数的引入" class="headerlink" title="核函数的引入"></a>核函数的引入</h3><ul>
<li>在处理非线性可分问题时，SVM使用核函数$K(X_i,X_j)$将数据映射到高维特征空间，以实现线性可分</li>
<li>核函数K计算两个输入数据点$X_i和X_j$在高维空间中的内积，而不需要显示地进行高维映射</li>
</ul>
<h3 id="核矩阵"><a href="#核矩阵" class="headerlink" title="核矩阵"></a>核矩阵</h3><ul>
<li>$K_{ij} = K(X_i,X_j)$</li>
<li>核矩阵K是一个对称矩阵，其元素是核函数在数据点间计算的值</li>
</ul>
<h2 id="半正定性的重要性"><a href="#半正定性的重要性" class="headerlink" title="半正定性的重要性"></a>半正定性的重要性</h2><h3 id="半正定性定义"><a href="#半正定性定义" class="headerlink" title="半正定性定义"></a>半正定性定义</h3><ul>
<li>一个对称矩阵K是半正定的，如果对于任何向量z，都有$z^TKz \ge 0$</li>
</ul>
<h3 id="核矩阵的半正定性与凸性"><a href="#核矩阵的半正定性与凸性" class="headerlink" title="核矩阵的半正定性与凸性"></a>核矩阵的半正定性与凸性</h3><ul>
<li>对于SVM的优化问题，目标函数包含核矩阵K。如果K是半正定的，那么相应的二次规划问题也是凸的</li>
<li>半正定性保证了目标函数在所有方向上的二次型都是非负的，即目标函数是凸函数</li>
</ul>
<h3 id="唯一解的存在性"><a href="#唯一解的存在性" class="headerlink" title="唯一解的存在性"></a>唯一解的存在性</h3><ul>
<li>在凸优化问题中，目标函数的任何局部最优解也是全局最优解。因此，确保核矩阵是半正定的，能保证SVM优化问题有唯一解。</li>
</ul>
<h2 id="核函数与-varphi-x-的关系"><a href="#核函数与-varphi-x-的关系" class="headerlink" title="核函数与$\varphi(x)$的关系"></a>核函数与$\varphi(x)$的关系</h2><p>核函数K和映射$\varphi$是一一对应的，核函数的形式不能随意取，需满足为一定条件才能分解为两个$\varphi$内积的形式</p>
<h3 id="Mercer’s-Theorem定理"><a href="#Mercer’s-Theorem定理" class="headerlink" title="Mercer’s Theorem定理"></a>Mercer’s Theorem定理</h3><img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531154748128.png" srcset="/img/loading.gif" lazyload class="" title="image-20240531154748128">
<h3 id="已知-varphi-求K"><a href="#已知-varphi-求K" class="headerlink" title="已知$\varphi$求K"></a>已知$\varphi$求K</h3><p>假设：$\varphi(x)$是一个将二维向量映射为三维向量的映射</p>
<img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153113219.png" srcset="/img/loading.gif" lazyload class="" title="image-20240531153113219">
<p>假设有两个二维向量</p>
<img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153414510.png" srcset="/img/loading.gif" lazyload class="" title="image-20240531153414510">
<h3 id="已知K求-varphi"><a href="#已知K求-varphi" class="headerlink" title="已知K求$\varphi()$"></a>已知K求$\varphi()$</h3><p>假设：</p>
<img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531153902859.png" srcset="/img/loading.gif" lazyload class="" title="image-20240531153902859">
<p>假设：</p>
<p>$X = [x_1,x_2]^T$</p>
<img src="/2024/05/21/20240521_MachineLearning_SupportVectorMachines/image-20240531154142917.png" srcset="/img/loading.gif" lazyload class="" title="image-20240531154142917">
<p><strong>$K(X_1,X_2)$就是前面那个形式</strong></p>
<h1 id="原问题和对偶问题"><a href="#原问题和对偶问题" class="headerlink" title="原问题和对偶问题"></a>原问题和对偶问题</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><ol>
<li><p>原问题</p>
<ul>
<li>最小化：$f(\omega)$</li>
<li>限制条件<ul>
<li>$g_i(\omega) \le 0    i = 1 \sim K$</li>
<li>$h_i(\omega) = 0     i = 1 \sim m$</li>
</ul>
</li>
</ul>
</li>
<li><p>对偶问题</p>
<ul>
<li><p>$ L(\omega, \alpha, \beta) = f(\omega) + \sum_{i=1}^{K} \alpha_i g_i(\omega) + \sum_{i=1}^{K} \beta_i h_i(\omega) $</p>
<p> $ = f(\omega) + \alpha^T g(\omega) + \beta^T h(\omega) $</p>
</li>
<li><p>其中</p>
<p>$ \alpha = \begin{bmatrix} \alpha_1, \alpha_2, \ldots, \alpha_K \end{bmatrix}^T $</p>
<p>$ \beta = \begin{bmatrix} \beta_1, \beta_2, \ldots, \beta_M \end{bmatrix}^T $</p>
<p>$ g(\omega) = \begin{bmatrix} g_1(\omega), g_2(\omega), \ldots, g_k(\omega) \end{bmatrix}^T $</p>
<p>$ h(\omega) = \begin{bmatrix} h_1(\omega), h_2(\omega), \ldots, h_m(\omega) \end{bmatrix}^T $</p>
</li>
<li><p>最大化：$\theta(\alpha,\beta) = \inf   L(\omega,\alpha,\beta)$，所有定义域内的\omega , 使得L最小</p>
</li>
<li><p>限制条件：$\alpha_i \ge 0, i =  1 \sim K$</p>
</li>
</ul>
</li>
<li><p>定理一</p>
<p>如果$\omega$是原问题的解，$(\alpha^\ast,\beta^\ast)$是对偶问题的解则有：</p>
<p><strong>$f(\omega^\ast) \ge \theta(\alpha^\ast,\beta^\ast)$</strong></p>
<p>证明：$\theta(\alpha^\ast, \beta^\ast) = \inf L(\omega, \alpha^\ast, \beta^\ast)$</p>
<p>​           $\leq L(\omega^\ast, \alpha^\ast, \beta^\ast)$</p>
<p>​           $= f(\omega^\ast) + \alpha^{\ast T} g(\omega^\ast) + \beta^{\ast T} h(\omega^\ast)$</p>
<p>​           $\leq f(\omega^\ast)$</p>
<ul>
<li><p>原问题的解总是大于对偶问题的解</p>
</li>
<li><p>对偶差距: $ f(\omega^\ast) - \theta(\alpha^\ast, \beta^\ast)}$</p>
<p>对偶差距为大于等于零的函数</p>
</li>
</ul>
</li>
<li><p>强对偶定理</p>
<p>如果$g(\omega)=A\omega+b,h(\omega)=C\omega+d$,f(\omega)为凸函数，则有$f(\omega^\ast) = \theta(\alpha^\ast,\beta^\ast)$,</p>
<p>则对偶差距为0。</p>
<ul>
<li>原问题的目标函数是凸函数，限制条件是线性函数，那么$f(\omega^\ast) = \theta(\alpha^\ast,\beta^\ast)$</li>
</ul>
</li>
<li><p>KKT条件</p>
<p>若$$</p>
</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  
    <span>></span>
    
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="print-no-link">#机器学习</a>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/%E7%AE%97%E6%B3%95/" class="print-no-link">#算法</a>
      
        <a href="/tags/SVM/" class="print-no-link">#SVM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>支持向量机</div>
      <div>http://example.com/2024/05/21/20240521_MachineLearning_SupportVectorMachines/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>XuanYa</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年5月21日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/05/31/20240531_ConvexOptimization/" title="凸优化">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">凸优化</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/05/19/20240519_MachineLearning_Introduction/" title="机器学习引言">
                        <span class="hidden-mobile">机器学习引言</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      

    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
